&&&& RUNNING TensorRT.trtexec [TensorRT v8200] # trtexec --onnx=model/centerpoint_rpn.onnx --saveEngine=model/centerpoint_rpn.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
[10/24/2023-13:02:28] [I] === Model Options ===
[10/24/2023-13:02:28] [I] Format: ONNX
[10/24/2023-13:02:28] [I] Model: model/centerpoint_rpn.onnx
[10/24/2023-13:02:28] [I] Output:
[10/24/2023-13:02:28] [I] === Build Options ===
[10/24/2023-13:02:28] [I] Max batch: explicit batch
[10/24/2023-13:02:28] [I] Workspace: 4096 MiB
[10/24/2023-13:02:28] [I] minTiming: 1
[10/24/2023-13:02:28] [I] avgTiming: 8
[10/24/2023-13:02:28] [I] Precision: FP32+FP16
[10/24/2023-13:02:28] [I] Calibration: 
[10/24/2023-13:02:28] [I] Refit: Disabled
[10/24/2023-13:02:28] [I] Sparsity: Disabled
[10/24/2023-13:02:28] [I] Safe mode: Disabled
[10/24/2023-13:02:28] [I] Strict mode: Disabled
[10/24/2023-13:02:28] [I] Restricted mode: Disabled
[10/24/2023-13:02:28] [I] Save engine: model/centerpoint_rpn.plan.8503
[10/24/2023-13:02:28] [I] Load engine: 
[10/24/2023-13:02:28] [I] Profiling verbosity: 2
[10/24/2023-13:02:28] [I] Tactic sources: Using default tactic sources
[10/24/2023-13:02:28] [I] timingCacheMode: local
[10/24/2023-13:02:28] [I] timingCacheFile: 
[10/24/2023-13:02:28] [I] Input(s): fp16:chw
[10/24/2023-13:02:28] [I] Output(s): fp16:chw
[10/24/2023-13:02:28] [I] Input build shapes: model
[10/24/2023-13:02:28] [I] Input calibration shapes: model
[10/24/2023-13:02:28] [I] === System Options ===
[10/24/2023-13:02:28] [I] Device: 0
[10/24/2023-13:02:28] [I] DLACore: 
[10/24/2023-13:02:28] [I] Plugins:
[10/24/2023-13:02:28] [I] === Inference Options ===
[10/24/2023-13:02:28] [I] Batch: Explicit
[10/24/2023-13:02:28] [I] Input inference shapes: model
[10/24/2023-13:02:28] [I] Iterations: 10
[10/24/2023-13:02:28] [I] Duration: 3s (+ 200ms warm up)
[10/24/2023-13:02:28] [I] Sleep time: 0ms
[10/24/2023-13:02:28] [I] Streams: 1
[10/24/2023-13:02:28] [I] ExposeDMA: Disabled
[10/24/2023-13:02:28] [I] Data transfers: Enabled
[10/24/2023-13:02:28] [I] Spin-wait: Disabled
[10/24/2023-13:02:28] [I] Multithreading: Disabled
[10/24/2023-13:02:28] [I] CUDA Graph: Disabled
[10/24/2023-13:02:28] [I] Separate profiling: Enabled
[10/24/2023-13:02:28] [I] Time Deserialize: Disabled
[10/24/2023-13:02:28] [I] Time Refit: Disabled
[10/24/2023-13:02:28] [I] Skip inference: Disabled
[10/24/2023-13:02:28] [I] Inputs:
[10/24/2023-13:02:28] [I] === Reporting Options ===
[10/24/2023-13:02:28] [I] Verbose: Enabled
[10/24/2023-13:02:28] [I] Averages: 10 inferences
[10/24/2023-13:02:28] [I] Percentile: 99
[10/24/2023-13:02:28] [I] Dump refittable layers:Disabled
[10/24/2023-13:02:28] [I] Dump output: Disabled
[10/24/2023-13:02:28] [I] Profile: Enabled
[10/24/2023-13:02:28] [I] Export timing to JSON file: 
[10/24/2023-13:02:28] [I] Export output to JSON file: 
[10/24/2023-13:02:28] [I] Export profile to JSON file: 
[10/24/2023-13:02:28] [I] 
[10/24/2023-13:02:29] [I] === Device Information ===
[10/24/2023-13:02:29] [I] Selected Device: NVIDIA A40
[10/24/2023-13:02:29] [I] Compute Capability: 8.6
[10/24/2023-13:02:29] [I] SMs: 84
[10/24/2023-13:02:29] [I] Compute Clock Rate: 1.74 GHz
[10/24/2023-13:02:29] [I] Device Global Memory: 45449 MiB
[10/24/2023-13:02:29] [I] Shared Memory per SM: 100 KiB
[10/24/2023-13:02:29] [I] Memory Bus Width: 384 bits (ECC enabled)
[10/24/2023-13:02:29] [I] Memory Clock Rate: 7.251 GHz
[10/24/2023-13:02:29] [I] 
[10/24/2023-13:02:29] [I] TensorRT version: 8200
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Proposal version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::Split version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[10/24/2023-13:02:29] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[10/24/2023-13:02:32] [I] [TRT] [MemUsageChange] Init CUDA: CPU +446, GPU +0, now: CPU 458, GPU 29429 (MiB)
[10/24/2023-13:02:32] [I] Start parsing network model
[10/24/2023-13:02:32] [I] [TRT] ----------------------------------------------------------------
[10/24/2023-13:02:32] [I] [TRT] Input filename:   model/centerpoint_rpn.onnx
[10/24/2023-13:02:32] [I] [TRT] ONNX IR version:  0.0.6
[10/24/2023-13:02:32] [I] [TRT] Opset version:    11
[10/24/2023-13:02:32] [I] [TRT] Producer name:    pytorch
[10/24/2023-13:02:32] [I] [TRT] Producer version: 2.0.1
[10/24/2023-13:02:32] [I] [TRT] Domain:           
[10/24/2023-13:02:32] [I] [TRT] Model version:    0
[10/24/2023-13:02:32] [I] [TRT] Doc string:       
[10/24/2023-13:02:32] [I] [TRT] ----------------------------------------------------------------
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::Split version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[10/24/2023-13:02:32] [V] [TRT] Adding network input: input with dtype: float16, dimensions: (1, 256, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: input for ONNX tensor: input
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.0.0.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.0.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.0.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.0.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.0.1.running_var
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.1.0.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.1.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.1.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.1.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.backbone_2d.deblocks.1.1.running_var
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.0.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.1.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.2.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.3.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.4.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: model.dense_head.heads_list.5.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_797
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_798
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_800
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_801
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_803
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_804
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_806
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_807
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_809
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_810
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_812
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_813
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_815
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_816
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_818
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_819
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_821
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_822
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_824
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_825
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_827
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_828
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_830
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_831
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_833
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_834
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_836
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_837
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_839
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_840
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_842
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_843
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_845
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_846
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_848
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_849
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_851
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_852
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_854
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_855
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_857
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_858
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_860
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_861
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_863
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_864
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_866
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_867
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_869
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_870
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_872
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_873
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_875
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_876
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_878
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_879
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_881
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_882
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_884
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_885
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_887
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_888
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_890
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_891
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_893
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_894
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_896
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_897
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_899
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_900
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_902
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_903
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_905
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_906
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_908
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_909
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_911
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_912
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_914
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_915
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_917
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_918
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_920
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_921
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_923
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_924
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_926
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_927
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_929
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_930
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_932
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_933
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_935
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_936
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_938
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_939
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_941
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: onnx::Conv_942
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: /backbone_2d/blocks.0/blocks.0.0/Constant_8_output_0
[10/24/2023-13:02:32] [V] [TRT] Importing initializer: /backbone_2d/blocks.0/blocks.0.0/Reshape_1_output_0
[10/24/2023-13:02:32] [W] [TRT] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.0/Pad [Pad]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: input
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.0/Reshape_1_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.0/Constant_8_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad [Pad] inputs: [input -> (1, 256, 128, 128)[HALF]], [/backbone_2d/blocks.0/blocks.0.0/Reshape_1_output_0 -> (8)[INT32]], [/backbone_2d/blocks.0/blocks.0.0/Constant_8_output_0 -> ()[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.0/Pad for ONNX node: /backbone_2d/blocks.0/blocks.0.0/Pad
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.0/Pad_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.0/Pad_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad [Pad] outputs: [/backbone_2d/blocks.0/blocks.0.0/Pad_output_0 -> (1, 256, 130, 130)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.0/Pad_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_797
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_798
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.1/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.0/Pad_output_0 -> (1, 256, 130, 130)[HALF]], [onnx::Conv_797 -> (128, 256, 3, 3)[HALF]], [onnx::Conv_798 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 130, 130)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.1/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.1/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.1/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.1/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.1/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.3/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.1/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.3/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.1/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.3/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.3/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.3/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.3/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.3/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.4/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.3/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_800
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_801
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [onnx::Conv_800 -> (128, 128, 3, 3)[HALF]], [onnx::Conv_801 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.4/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.4/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.4/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.4/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.4/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.6/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.4/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.6/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.4/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.6/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.6/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.6/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.6/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.6/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.6/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.7/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.6/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_803
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_804
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.7/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.6/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [onnx::Conv_803 -> (128, 128, 3, 3)[HALF]], [onnx::Conv_804 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.7/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.7/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.7/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.7/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.7/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.7/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.9/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.7/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.9/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.7/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.9/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.9/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.9/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.9/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.9/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.9/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.10/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.9/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_806
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_807
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.10/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.9/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [onnx::Conv_806 -> (128, 128, 3, 3)[HALF]], [onnx::Conv_807 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.10/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.10/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.10/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.10/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.10/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.10/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.12/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.10/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.12/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.10/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.12/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.12/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.12/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.12/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.12/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.12/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.13/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.12/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_809
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_810
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.13/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.12/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [onnx::Conv_809 -> (128, 128, 3, 3)[HALF]], [onnx::Conv_810 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.13/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.13/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.13/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.13/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.13/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.13/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.15/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.13/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.15/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.13/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.15/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.15/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.15/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.15/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.15/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.15/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.16/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.15/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_812
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_813
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.16/Conv [Conv] inputs: [/backbone_2d/blocks.0/blocks.0.15/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [onnx::Conv_812 -> (128, 128, 3, 3)[HALF]], [onnx::Conv_813 -> (128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.16/Conv for ONNX node: /backbone_2d/blocks.0/blocks.0.16/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 128, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.16/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.16/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.16/Conv [Conv] outputs: [/backbone_2d/blocks.0/blocks.0.16/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.0/blocks.0.18/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.16/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.18/Relu [Relu] inputs: [/backbone_2d/blocks.0/blocks.0.16/Conv_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.0/blocks.0.18/Relu for ONNX node: /backbone_2d/blocks.0/blocks.0.18/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.0/blocks.0.18/Relu [Relu] outputs: [/backbone_2d/blocks.0/blocks.0.18/Relu_output_0 -> (1, 128, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose [ConvTranspose]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.0.0.weight
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose [ConvTranspose] inputs: [/backbone_2d/blocks.0/blocks.0.18/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [model.backbone_2d.deblocks.0.0.weight -> (128, 256, 1, 1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Running deconvolution with: 
Padding mode: NOTSET
Pre-padding: (0, 0)
Post-padding: (0, 0)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose for ONNX node: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 for ONNX tensor: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose [ConvTranspose] outputs: [/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization [BatchNormalization]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.0.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.0.1.bias
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.0.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.0.1.running_var
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization [BatchNormalization] inputs: [/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> (1, 256, 128, 128)[HALF]], [model.backbone_2d.deblocks.0.1.weight -> (256)[HALF]], [model.backbone_2d.deblocks.0.1.bias -> (256)[HALF]], [model.backbone_2d.deblocks.0.1.running_mean -> (256)[HALF]], [model.backbone_2d.deblocks.0.1.running_var -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.0.1.weight for ONNX node: model.backbone_2d.deblocks.0.1.weight
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.0.1.bias for ONNX node: model.backbone_2d.deblocks.0.1.bias
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.0.1.running_mean for ONNX node: model.backbone_2d.deblocks.0.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.0.1.running_var for ONNX node: model.backbone_2d.deblocks.0.1.running_var
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization for ONNX node: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization_output_0 for ONNX tensor: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization [BatchNormalization] outputs: [/backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.0/deblocks.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.2/Relu [Relu] inputs: [/backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.0/deblocks.0.2/Relu for ONNX node: /backbone_2d/deblocks.0/deblocks.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0 for ONNX tensor: /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.0/deblocks.0.2/Relu [Relu] outputs: [/backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.0/Pad [Pad]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.0/Reshape_1_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.0/blocks.0.0/Constant_8_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad [Pad] inputs: [/backbone_2d/blocks.0/blocks.0.18/Relu_output_0 -> (1, 128, 128, 128)[HALF]], [/backbone_2d/blocks.0/blocks.0.0/Reshape_1_output_0 -> (8)[INT32]], [/backbone_2d/blocks.0/blocks.0.0/Constant_8_output_0 -> ()[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.0/Pad for ONNX node: /backbone_2d/blocks.1/blocks.1.0/Pad
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.0/Pad_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.0/Pad_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad [Pad] outputs: [/backbone_2d/blocks.1/blocks.1.0/Pad_output_0 -> (1, 128, 130, 130)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.0/Pad_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_815
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_816
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.1/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.0/Pad_output_0 -> (1, 128, 130, 130)[HALF]], [onnx::Conv_815 -> (256, 128, 3, 3)[HALF]], [onnx::Conv_816 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 128, 130, 130)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.1/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.1/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.1/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.1/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.1/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.3/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.1/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.3/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.1/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.3/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.3/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.3/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.3/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.3/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.4/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.3/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_818
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_819
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [onnx::Conv_818 -> (256, 256, 3, 3)[HALF]], [onnx::Conv_819 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.4/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.4/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.4/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.4/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.4/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.6/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.4/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.6/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.4/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.6/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.6/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.6/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.6/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.6/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.6/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.7/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.6/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_821
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_822
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.7/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.6/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [onnx::Conv_821 -> (256, 256, 3, 3)[HALF]], [onnx::Conv_822 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.7/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.7/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.7/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.7/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.7/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.7/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.9/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.7/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.9/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.7/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.9/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.9/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.9/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.9/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.9/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.9/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.10/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.9/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_824
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_825
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.10/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.9/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [onnx::Conv_824 -> (256, 256, 3, 3)[HALF]], [onnx::Conv_825 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.10/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.10/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.10/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.10/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.10/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.10/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.12/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.10/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.12/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.10/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.12/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.12/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.12/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.12/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.12/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.12/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.13/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.12/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_827
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_828
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.13/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.12/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [onnx::Conv_827 -> (256, 256, 3, 3)[HALF]], [onnx::Conv_828 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.13/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.13/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.13/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.13/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.13/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.13/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.15/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.13/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.15/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.13/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.15/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.15/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.15/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.15/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.15/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.15/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.16/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.15/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_830
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_831
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.16/Conv [Conv] inputs: [/backbone_2d/blocks.1/blocks.1.15/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [onnx::Conv_830 -> (256, 256, 3, 3)[HALF]], [onnx::Conv_831 -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.16/Conv for ONNX node: /backbone_2d/blocks.1/blocks.1.16/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 256, 64, 64)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.16/Conv_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.16/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.16/Conv [Conv] outputs: [/backbone_2d/blocks.1/blocks.1.16/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/blocks.1/blocks.1.18/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.16/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.18/Relu [Relu] inputs: [/backbone_2d/blocks.1/blocks.1.16/Conv_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/blocks.1/blocks.1.18/Relu for ONNX node: /backbone_2d/blocks.1/blocks.1.18/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/blocks.1/blocks.1.18/Relu_output_0 for ONNX tensor: /backbone_2d/blocks.1/blocks.1.18/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/blocks.1/blocks.1.18/Relu [Relu] outputs: [/backbone_2d/blocks.1/blocks.1.18/Relu_output_0 -> (1, 256, 64, 64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose [ConvTranspose]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/blocks.1/blocks.1.18/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.1.0.weight
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose [ConvTranspose] inputs: [/backbone_2d/blocks.1/blocks.1.18/Relu_output_0 -> (1, 256, 64, 64)[HALF]], [model.backbone_2d.deblocks.1.0.weight -> (256, 256, 2, 2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Running deconvolution with: 
Padding mode: NOTSET
Pre-padding: (0, 0)
Post-padding: (0, 0)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose for ONNX node: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0 for ONNX tensor: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose [ConvTranspose] outputs: [/backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization [BatchNormalization]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.1.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.1.1.bias
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.1.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.backbone_2d.deblocks.1.1.running_var
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization [BatchNormalization] inputs: [/backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0 -> (1, 256, 128, 128)[HALF]], [model.backbone_2d.deblocks.1.1.weight -> (256)[HALF]], [model.backbone_2d.deblocks.1.1.bias -> (256)[HALF]], [model.backbone_2d.deblocks.1.1.running_mean -> (256)[HALF]], [model.backbone_2d.deblocks.1.1.running_var -> (256)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.1.1.weight for ONNX node: model.backbone_2d.deblocks.1.1.weight
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.1.1.bias for ONNX node: model.backbone_2d.deblocks.1.1.bias
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.1.1.running_mean for ONNX node: model.backbone_2d.deblocks.1.1.running_mean
[10/24/2023-13:02:32] [V] [TRT] Registering layer: model.backbone_2d.deblocks.1.1.running_var for ONNX node: model.backbone_2d.deblocks.1.1.running_var
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Original shape: (256,), unsqueezing to: (1, 256, 1, 1)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization for ONNX node: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization_output_0 for ONNX tensor: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization [BatchNormalization] outputs: [/backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/deblocks.1/deblocks.1.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.2/Relu [Relu] inputs: [/backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/deblocks.1/deblocks.1.2/Relu for ONNX node: /backbone_2d/deblocks.1/deblocks.1.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0 for ONNX tensor: /backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/deblocks.1/deblocks.1.2/Relu [Relu] outputs: [/backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /backbone_2d/Concat [Concat]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/Concat [Concat] inputs: [/backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0 -> (1, 256, 128, 128)[HALF]], [/backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0 -> (1, 256, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /backbone_2d/Concat for ONNX node: /backbone_2d/Concat
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /backbone_2d/Concat_output_0 for ONNX tensor: /backbone_2d/Concat_output_0
[10/24/2023-13:02:32] [V] [TRT] /backbone_2d/Concat [Concat] outputs: [/backbone_2d/Concat_output_0 -> (1, 512, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /shared_conv/shared_conv.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /backbone_2d/Concat_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_833
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_834
[10/24/2023-13:02:32] [V] [TRT] /shared_conv/shared_conv.0/Conv [Conv] inputs: [/backbone_2d/Concat_output_0 -> (1, 512, 128, 128)[HALF]], [onnx::Conv_833 -> (64, 512, 3, 3)[HALF]], [onnx::Conv_834 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 512, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /shared_conv/shared_conv.0/Conv for ONNX node: /shared_conv/shared_conv.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /shared_conv/shared_conv.0/Conv_output_0 for ONNX tensor: /shared_conv/shared_conv.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /shared_conv/shared_conv.0/Conv [Conv] outputs: [/shared_conv/shared_conv.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /shared_conv/shared_conv.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /shared_conv/shared_conv.2/Relu [Relu] inputs: [/shared_conv/shared_conv.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /shared_conv/shared_conv.2/Relu for ONNX node: /shared_conv/shared_conv.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /shared_conv/shared_conv.2/Relu_output_0 for ONNX tensor: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /shared_conv/shared_conv.2/Relu [Relu] outputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_836
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_837
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_836 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_837 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center/center.0/center.0.0/Conv for ONNX node: /heads_list.0/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.0/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.0/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center/center.0/center.0.2/Relu for ONNX node: /heads_list.0/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.1/Conv [Conv] inputs: [/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center/center.1/Conv for ONNX node: /heads_list.0/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_0_0 for ONNX tensor: reg_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center/center.1/Conv [Conv] outputs: [reg_0 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_839
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_840
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_839 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_840 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.0/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.0/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.0/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.0/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/center_z/center_z.1/Conv for ONNX node: /heads_list.0/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_0_1 for ONNX tensor: height_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv [Conv] outputs: [height_0 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_842
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_843
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_842 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_843 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.0/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.0/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.0/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.0/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.0/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.1/Conv [Conv] inputs: [/heads_list.0/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/dim/dim.1/Conv for ONNX node: /heads_list.0/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_0_2 for ONNX tensor: dim_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/dim/dim.1/Conv [Conv] outputs: [dim_0 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_845
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_846
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_845 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_846 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.0/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.0/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.0/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.0/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.0/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.1/Conv [Conv] inputs: [/heads_list.0/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/rot/rot.1/Conv for ONNX node: /heads_list.0/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_0_3 for ONNX tensor: rot_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/rot/rot.1/Conv [Conv] outputs: [rot_0 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_848
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_849
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_848 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_849 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.0/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.0/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.0/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.0/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.0/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.1/Conv [Conv] inputs: [/heads_list.0/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/vel/vel.1/Conv for ONNX node: /heads_list.0/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_0_4 for ONNX tensor: vel_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/vel/vel.1/Conv [Conv] outputs: [vel_0 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_851
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_852
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_851 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_852 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.0/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.0/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.0/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.0/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.0/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.0/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.0/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.0/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.0/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.0/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.1/Conv [Conv] inputs: [/heads_list.0/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.0.hm.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.hm.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.0/hm/hm.1/Conv for ONNX node: /heads_list.0/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_0_5 for ONNX tensor: hm_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.0/hm/hm.1/Conv [Conv] outputs: [hm_0 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_854
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_855
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_854 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_855 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center/center.0/center.0.0/Conv for ONNX node: /heads_list.1/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.1/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.1/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center/center.0/center.0.2/Relu for ONNX node: /heads_list.1/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.1/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.1/Conv [Conv] inputs: [/heads_list.1/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.1.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center/center.1/Conv for ONNX node: /heads_list.1/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_1_6 for ONNX tensor: reg_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center/center.1/Conv [Conv] outputs: [reg_1 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_857
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_858
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_857 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_858 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.1/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.1/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.1/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.1/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.1.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/center_z/center_z.1/Conv for ONNX node: /heads_list.1/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_1_7 for ONNX tensor: height_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/center_z/center_z.1/Conv [Conv] outputs: [height_1 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_860
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_861
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_860 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_861 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.1/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.1/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.1/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.1/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.1/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.1/Conv [Conv] inputs: [/heads_list.1/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.1.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/dim/dim.1/Conv for ONNX node: /heads_list.1/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_1_8 for ONNX tensor: dim_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/dim/dim.1/Conv [Conv] outputs: [dim_1 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_863
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_864
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_863 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_864 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.1/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.1/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.1/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.1/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.1/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.1/Conv [Conv] inputs: [/heads_list.1/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.1.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/rot/rot.1/Conv for ONNX node: /heads_list.1/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_1_9 for ONNX tensor: rot_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/rot/rot.1/Conv [Conv] outputs: [rot_1 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_866
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_867
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_866 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_867 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.1/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.1/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.1/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.1/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.1/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.1/Conv [Conv] inputs: [/heads_list.1/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/vel/vel.1/Conv for ONNX node: /heads_list.1/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_1_10 for ONNX tensor: vel_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/vel/vel.1/Conv [Conv] outputs: [vel_1 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_869
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_870
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_869 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_870 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.1/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.1/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.1/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.1/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.1/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.1/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.1/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.1/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.1/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.1/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.1.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.1/Conv [Conv] inputs: [/heads_list.1/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.1.hm.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.1.hm.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.1/hm/hm.1/Conv for ONNX node: /heads_list.1/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_1_11 for ONNX tensor: hm_1
[10/24/2023-13:02:32] [V] [TRT] /heads_list.1/hm/hm.1/Conv [Conv] outputs: [hm_1 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_872
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_873
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_872 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_873 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center/center.0/center.0.0/Conv for ONNX node: /heads_list.2/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.2/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.2/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center/center.0/center.0.2/Relu for ONNX node: /heads_list.2/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.2/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.1/Conv [Conv] inputs: [/heads_list.2/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.2.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center/center.1/Conv for ONNX node: /heads_list.2/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_2_12 for ONNX tensor: reg_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center/center.1/Conv [Conv] outputs: [reg_2 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_875
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_876
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_875 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_876 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.2/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.2/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.2/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.2/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.2.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/center_z/center_z.1/Conv for ONNX node: /heads_list.2/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_2_13 for ONNX tensor: height_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/center_z/center_z.1/Conv [Conv] outputs: [height_2 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_878
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_879
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_878 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_879 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.2/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.2/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.2/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.2/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.2/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.1/Conv [Conv] inputs: [/heads_list.2/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.2.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/dim/dim.1/Conv for ONNX node: /heads_list.2/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_2_14 for ONNX tensor: dim_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/dim/dim.1/Conv [Conv] outputs: [dim_2 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_881
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_882
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_881 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_882 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.2/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.2/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.2/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.2/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.2/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.1/Conv [Conv] inputs: [/heads_list.2/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.2.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/rot/rot.1/Conv for ONNX node: /heads_list.2/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_2_15 for ONNX tensor: rot_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/rot/rot.1/Conv [Conv] outputs: [rot_2 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_884
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_885
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_884 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_885 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.2/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.2/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.2/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.2/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.2/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.1/Conv [Conv] inputs: [/heads_list.2/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/vel/vel.1/Conv for ONNX node: /heads_list.2/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_2_16 for ONNX tensor: vel_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/vel/vel.1/Conv [Conv] outputs: [vel_2 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_887
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_888
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_887 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_888 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.2/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.2/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.2/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.2/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.2/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.2/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.2/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.2/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.2/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.2/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.2.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.1/Conv [Conv] inputs: [/heads_list.2/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.2.hm.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.2.hm.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.2/hm/hm.1/Conv for ONNX node: /heads_list.2/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_2_17 for ONNX tensor: hm_2
[10/24/2023-13:02:32] [V] [TRT] /heads_list.2/hm/hm.1/Conv [Conv] outputs: [hm_2 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_890
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_891
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_890 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_891 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center/center.0/center.0.0/Conv for ONNX node: /heads_list.3/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.3/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.3/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center/center.0/center.0.2/Relu for ONNX node: /heads_list.3/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.3/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.1/Conv [Conv] inputs: [/heads_list.3/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.3.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center/center.1/Conv for ONNX node: /heads_list.3/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_3_18 for ONNX tensor: reg_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center/center.1/Conv [Conv] outputs: [reg_3 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_893
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_894
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_893 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_894 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.3/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.3/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.3/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.3/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.3.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/center_z/center_z.1/Conv for ONNX node: /heads_list.3/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_3_19 for ONNX tensor: height_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/center_z/center_z.1/Conv [Conv] outputs: [height_3 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_896
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_897
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_896 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_897 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.3/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.3/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.3/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.3/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.3/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.1/Conv [Conv] inputs: [/heads_list.3/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.3.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/dim/dim.1/Conv for ONNX node: /heads_list.3/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_3_20 for ONNX tensor: dim_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/dim/dim.1/Conv [Conv] outputs: [dim_3 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_899
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_900
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_899 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_900 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.3/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.3/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.3/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.3/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.3/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.1/Conv [Conv] inputs: [/heads_list.3/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.3.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/rot/rot.1/Conv for ONNX node: /heads_list.3/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_3_21 for ONNX tensor: rot_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/rot/rot.1/Conv [Conv] outputs: [rot_3 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_902
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_903
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_902 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_903 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.3/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.3/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.3/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.3/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.3/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.1/Conv [Conv] inputs: [/heads_list.3/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/vel/vel.1/Conv for ONNX node: /heads_list.3/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_3_22 for ONNX tensor: vel_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/vel/vel.1/Conv [Conv] outputs: [vel_3 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_905
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_906
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_905 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_906 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.3/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.3/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.3/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.3/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.3/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.3/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.3/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.3/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.3/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.3/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.3.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.1/Conv [Conv] inputs: [/heads_list.3/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.3.hm.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.3.hm.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.3/hm/hm.1/Conv for ONNX node: /heads_list.3/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_3_23 for ONNX tensor: hm_3
[10/24/2023-13:02:32] [V] [TRT] /heads_list.3/hm/hm.1/Conv [Conv] outputs: [hm_3 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_908
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_909
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_908 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_909 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center/center.0/center.0.0/Conv for ONNX node: /heads_list.4/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.4/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.4/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center/center.0/center.0.2/Relu for ONNX node: /heads_list.4/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.4/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.1/Conv [Conv] inputs: [/heads_list.4/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.4.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center/center.1/Conv for ONNX node: /heads_list.4/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_4_24 for ONNX tensor: reg_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center/center.1/Conv [Conv] outputs: [reg_4 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_911
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_912
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_911 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_912 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.4/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.4/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.4/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.4/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.4.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/center_z/center_z.1/Conv for ONNX node: /heads_list.4/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_4_25 for ONNX tensor: height_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/center_z/center_z.1/Conv [Conv] outputs: [height_4 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_914
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_915
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_914 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_915 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.4/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.4/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.4/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.4/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.4/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.1/Conv [Conv] inputs: [/heads_list.4/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.4.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/dim/dim.1/Conv for ONNX node: /heads_list.4/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_4_26 for ONNX tensor: dim_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/dim/dim.1/Conv [Conv] outputs: [dim_4 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_917
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_918
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_917 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_918 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.4/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.4/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.4/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.4/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.4/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.1/Conv [Conv] inputs: [/heads_list.4/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.4.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/rot/rot.1/Conv for ONNX node: /heads_list.4/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_4_27 for ONNX tensor: rot_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/rot/rot.1/Conv [Conv] outputs: [rot_4 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_920
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_921
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_920 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_921 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.4/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.4/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.4/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.4/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.4/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.1/Conv [Conv] inputs: [/heads_list.4/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/vel/vel.1/Conv for ONNX node: /heads_list.4/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_4_28 for ONNX tensor: vel_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/vel/vel.1/Conv [Conv] outputs: [vel_4 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_923
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_924
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_923 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_924 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.4/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.4/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.4/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.4/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.4/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.4/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.4/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.4/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.4/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.4/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.4.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.1/Conv [Conv] inputs: [/heads_list.4/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.4.hm.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.4.hm.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.4/hm/hm.1/Conv for ONNX node: /heads_list.4/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_4_29 for ONNX tensor: hm_4
[10/24/2023-13:02:32] [V] [TRT] /heads_list.4/hm/hm.1/Conv [Conv] outputs: [hm_4 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center/center.0/center.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_926
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_927
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.0/center.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_926 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_927 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center/center.0/center.0.0/Conv for ONNX node: /heads_list.5/center/center.0/center.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/center/center.0/center.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.0/center.0.0/Conv [Conv] outputs: [/heads_list.5/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center/center.0/center.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/center/center.0/center.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.0/center.0.2/Relu [Relu] inputs: [/heads_list.5/center/center.0/center.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center/center.0/center.0.2/Relu for ONNX node: /heads_list.5/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/center/center.0/center.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.0/center.0.2/Relu [Relu] outputs: [/heads_list.5/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center/center.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/center/center.0/center.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.center.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.center.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.1/Conv [Conv] inputs: [/heads_list.5/center/center.0/center.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.center.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.5.center.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center/center.1/Conv for ONNX node: /heads_list.5/center/center.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: reg_5_30 for ONNX tensor: reg_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center/center.1/Conv [Conv] outputs: [reg_5 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_929
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_930
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.0/center_z.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_929 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_930 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv for ONNX node: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.0/center_z.0.0/Conv [Conv] outputs: [/heads_list.5/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/center_z/center_z.0/center_z.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.0/center_z.0.2/Relu [Relu] inputs: [/heads_list.5/center_z/center_z.0/center_z.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu for ONNX node: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.0/center_z.0.2/Relu [Relu] outputs: [/heads_list.5/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/center_z/center_z.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/center_z/center_z.0/center_z.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.center_z.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.center_z.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.1/Conv [Conv] inputs: [/heads_list.5/center_z/center_z.0/center_z.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.center_z.1.weight -> (1, 64, 3, 3)[HALF]], [model.dense_head.heads_list.5.center_z.1.bias -> (1)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/center_z/center_z.1/Conv for ONNX node: /heads_list.5/center_z/center_z.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 1, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: height_5_31 for ONNX tensor: height_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/center_z/center_z.1/Conv [Conv] outputs: [height_5 -> (1, 1, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/dim/dim.0/dim.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_932
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_933
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_932 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_933 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/dim/dim.0/dim.0.0/Conv for ONNX node: /heads_list.5/dim/dim.0/dim.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/dim/dim.0/dim.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv [Conv] outputs: [/heads_list.5/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/dim/dim.0/dim.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/dim/dim.0/dim.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.2/Relu [Relu] inputs: [/heads_list.5/dim/dim.0/dim.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/dim/dim.0/dim.0.2/Relu for ONNX node: /heads_list.5/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.2/Relu [Relu] outputs: [/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/dim/dim.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/dim/dim.0/dim.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.dim.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.dim.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.1/Conv [Conv] inputs: [/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.dim.1.weight -> (3, 64, 3, 3)[HALF]], [model.dense_head.heads_list.5.dim.1.bias -> (3)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/dim/dim.1/Conv for ONNX node: /heads_list.5/dim/dim.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 3, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: dim_5_32 for ONNX tensor: dim_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/dim/dim.1/Conv [Conv] outputs: [dim_5 -> (1, 3, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/rot/rot.0/rot.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_935
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_936
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.0/rot.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_935 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_936 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/rot/rot.0/rot.0.0/Conv for ONNX node: /heads_list.5/rot/rot.0/rot.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/rot/rot.0/rot.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.0/rot.0.0/Conv [Conv] outputs: [/heads_list.5/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/rot/rot.0/rot.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/rot/rot.0/rot.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.0/rot.0.2/Relu [Relu] inputs: [/heads_list.5/rot/rot.0/rot.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/rot/rot.0/rot.0.2/Relu for ONNX node: /heads_list.5/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/rot/rot.0/rot.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.0/rot.0.2/Relu [Relu] outputs: [/heads_list.5/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/rot/rot.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/rot/rot.0/rot.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.rot.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.rot.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.1/Conv [Conv] inputs: [/heads_list.5/rot/rot.0/rot.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.rot.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.5.rot.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/rot/rot.1/Conv for ONNX node: /heads_list.5/rot/rot.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: rot_5_33 for ONNX tensor: rot_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/rot/rot.1/Conv [Conv] outputs: [rot_5 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/vel/vel.0/vel.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_938
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_939
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.0/vel.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_938 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_939 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/vel/vel.0/vel.0.0/Conv for ONNX node: /heads_list.5/vel/vel.0/vel.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/vel/vel.0/vel.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.0/vel.0.0/Conv [Conv] outputs: [/heads_list.5/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/vel/vel.0/vel.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/vel/vel.0/vel.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.0/vel.0.2/Relu [Relu] inputs: [/heads_list.5/vel/vel.0/vel.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/vel/vel.0/vel.0.2/Relu for ONNX node: /heads_list.5/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/vel/vel.0/vel.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.0/vel.0.2/Relu [Relu] outputs: [/heads_list.5/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/vel/vel.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/vel/vel.0/vel.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.vel.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.0.vel.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.1/Conv [Conv] inputs: [/heads_list.5/vel/vel.0/vel.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.vel.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.0.vel.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/vel/vel.1/Conv for ONNX node: /heads_list.5/vel/vel.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: vel_5_34 for ONNX tensor: vel_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/vel/vel.1/Conv [Conv] outputs: [vel_5 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/hm/hm.0/hm.0.0/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /shared_conv/shared_conv.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_941
[10/24/2023-13:02:32] [V] [TRT] Searching for input: onnx::Conv_942
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.0/hm.0.0/Conv [Conv] inputs: [/shared_conv/shared_conv.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [onnx::Conv_941 -> (64, 64, 3, 3)[HALF]], [onnx::Conv_942 -> (64)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/hm/hm.0/hm.0.0/Conv for ONNX node: /heads_list.5/hm/hm.0/hm.0.0/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/hm/hm.0/hm.0.0/Conv_output_0 for ONNX tensor: /heads_list.5/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.0/hm.0.0/Conv [Conv] outputs: [/heads_list.5/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/hm/hm.0/hm.0.2/Relu [Relu]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/hm/hm.0/hm.0.0/Conv_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.0/hm.0.2/Relu [Relu] inputs: [/heads_list.5/hm/hm.0/hm.0.0/Conv_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/hm/hm.0/hm.0.2/Relu for ONNX node: /heads_list.5/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: /heads_list.5/hm/hm.0/hm.0.2/Relu_output_0 for ONNX tensor: /heads_list.5/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.0/hm.0.2/Relu [Relu] outputs: [/heads_list.5/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Parsing node: /heads_list.5/hm/hm.1/Conv [Conv]
[10/24/2023-13:02:32] [V] [TRT] Searching for input: /heads_list.5/hm/hm.0/hm.0.2/Relu_output_0
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.hm.1.weight
[10/24/2023-13:02:32] [V] [TRT] Searching for input: model.dense_head.heads_list.5.hm.1.bias
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.1/Conv [Conv] inputs: [/heads_list.5/hm/hm.0/hm.0.2/Relu_output_0 -> (1, 64, 128, 128)[HALF]], [model.dense_head.heads_list.5.hm.1.weight -> (2, 64, 3, 3)[HALF]], [model.dense_head.heads_list.5.hm.1.bias -> (2)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Convolution input dimensions: (1, 64, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering layer: /heads_list.5/hm/hm.1/Conv for ONNX node: /heads_list.5/hm/hm.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[10/24/2023-13:02:32] [V] [TRT] Convolution output dimensions: (1, 2, 128, 128)
[10/24/2023-13:02:32] [V] [TRT] Registering tensor: hm_5_35 for ONNX tensor: hm_5
[10/24/2023-13:02:32] [V] [TRT] /heads_list.5/hm/hm.1/Conv [Conv] outputs: [hm_5 -> (1, 2, 128, 128)[HALF]], 
[10/24/2023-13:02:32] [V] [TRT] Marking reg_0_0 as output: reg_0
[10/24/2023-13:02:32] [V] [TRT] Marking height_0_1 as output: height_0
[10/24/2023-13:02:32] [V] [TRT] Marking dim_0_2 as output: dim_0
[10/24/2023-13:02:32] [V] [TRT] Marking rot_0_3 as output: rot_0
[10/24/2023-13:02:32] [V] [TRT] Marking vel_0_4 as output: vel_0
[10/24/2023-13:02:32] [V] [TRT] Marking hm_0_5 as output: hm_0
[10/24/2023-13:02:32] [V] [TRT] Marking reg_1_6 as output: reg_1
[10/24/2023-13:02:32] [V] [TRT] Marking height_1_7 as output: height_1
[10/24/2023-13:02:32] [V] [TRT] Marking dim_1_8 as output: dim_1
[10/24/2023-13:02:32] [V] [TRT] Marking rot_1_9 as output: rot_1
[10/24/2023-13:02:32] [V] [TRT] Marking vel_1_10 as output: vel_1
[10/24/2023-13:02:32] [V] [TRT] Marking hm_1_11 as output: hm_1
[10/24/2023-13:02:32] [V] [TRT] Marking reg_2_12 as output: reg_2
[10/24/2023-13:02:32] [V] [TRT] Marking height_2_13 as output: height_2
[10/24/2023-13:02:32] [V] [TRT] Marking dim_2_14 as output: dim_2
[10/24/2023-13:02:32] [V] [TRT] Marking rot_2_15 as output: rot_2
[10/24/2023-13:02:32] [V] [TRT] Marking vel_2_16 as output: vel_2
[10/24/2023-13:02:32] [V] [TRT] Marking hm_2_17 as output: hm_2
[10/24/2023-13:02:32] [V] [TRT] Marking reg_3_18 as output: reg_3
[10/24/2023-13:02:32] [V] [TRT] Marking height_3_19 as output: height_3
[10/24/2023-13:02:32] [V] [TRT] Marking dim_3_20 as output: dim_3
[10/24/2023-13:02:32] [V] [TRT] Marking rot_3_21 as output: rot_3
[10/24/2023-13:02:32] [V] [TRT] Marking vel_3_22 as output: vel_3
[10/24/2023-13:02:32] [V] [TRT] Marking hm_3_23 as output: hm_3
[10/24/2023-13:02:32] [V] [TRT] Marking reg_4_24 as output: reg_4
[10/24/2023-13:02:32] [V] [TRT] Marking height_4_25 as output: height_4
[10/24/2023-13:02:32] [V] [TRT] Marking dim_4_26 as output: dim_4
[10/24/2023-13:02:32] [V] [TRT] Marking rot_4_27 as output: rot_4
[10/24/2023-13:02:32] [V] [TRT] Marking vel_4_28 as output: vel_4
[10/24/2023-13:02:32] [V] [TRT] Marking hm_4_29 as output: hm_4
[10/24/2023-13:02:32] [V] [TRT] Marking reg_5_30 as output: reg_5
[10/24/2023-13:02:32] [V] [TRT] Marking height_5_31 as output: height_5
[10/24/2023-13:02:32] [V] [TRT] Marking dim_5_32 as output: dim_5
[10/24/2023-13:02:32] [V] [TRT] Marking rot_5_33 as output: rot_5
[10/24/2023-13:02:32] [V] [TRT] Marking vel_5_34 as output: vel_5
[10/24/2023-13:02:32] [V] [TRT] Marking hm_5_35 as output: hm_5
[10/24/2023-13:02:32] [I] Finish parsing network model
[10/24/2023-13:02:32] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 698 MiB, GPU 29509 MiB
[10/24/2023-13:02:32] [V] [TRT] Applying generic optimizations to the graph for inference.
[10/24/2023-13:02:32] [V] [TRT] Original: 171 layers
[10/24/2023-13:02:32] [V] [TRT] After dead-layer removal: 171 layers
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.0.1.weight with (Unnamed Layer* 22) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.0.1.bias with (Unnamed Layer* 23) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.0.1.running_mean with (Unnamed Layer* 24) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.0.1.running_var with (Unnamed Layer* 25) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.1.1.weight with (Unnamed Layer* 56) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.1.1.bias with (Unnamed Layer* 57) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.1.1.running_mean with (Unnamed Layer* 58) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstShuffleFusion
[10/24/2023-13:02:32] [V] [TRT] ConstShuffleFusion: Fusing model.backbone_2d.deblocks.1.1.running_var with (Unnamed Layer* 59) [Shuffle]
[10/24/2023-13:02:32] [V] [TRT] After Myelin optimization: 163 layers
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] with (Unnamed Layer* 31) [ElementWise]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] with /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing (Unnamed Layer* 26) [Constant] with (Unnamed Layer* 27) [ElementWise]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] with (Unnamed Layer* 65) [ElementWise]
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] with /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Running: ConstEltFusion
[10/24/2023-13:02:32] [V] [TRT] ConstEltFusion: Fusing (Unnamed Layer* 60) [Constant] with (Unnamed Layer* 61) [ElementWise]
[10/24/2023-13:02:32] [V] [TRT] After scale fusion: 157 layers
[10/24/2023-13:02:32] [V] [TRT] Running: SliceConvolutionFusion
[10/24/2023-13:02:32] [V] [TRT] SliceConvolutionFusion: Fusing /backbone_2d/blocks.0/blocks.0.0/Pad with /backbone_2d/blocks.0/blocks.0.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv with /backbone_2d/blocks.0/blocks.0.3/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.4/Conv with /backbone_2d/blocks.0/blocks.0.6/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.7/Conv with /backbone_2d/blocks.0/blocks.0.9/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.10/Conv with /backbone_2d/blocks.0/blocks.0.12/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.13/Conv with /backbone_2d/blocks.0/blocks.0.15/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.0/blocks.0.16/Conv with /backbone_2d/blocks.0/blocks.0.18/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: SliceConvolutionFusion
[10/24/2023-13:02:32] [V] [TRT] SliceConvolutionFusion: Fusing /backbone_2d/blocks.1/blocks.1.0/Pad with /backbone_2d/blocks.1/blocks.1.1/Conv
[10/24/2023-13:02:32] [V] [TRT] Running: ScaleScaleFusion
[10/24/2023-13:02:32] [V] [TRT] ScaleScaleFusion: Fusing model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] with model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Running: ScaleActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ScaleActivationFusion: Fusing model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization with /backbone_2d/deblocks.0/deblocks.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv with /backbone_2d/blocks.1/blocks.1.3/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.4/Conv with /backbone_2d/blocks.1/blocks.1.6/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.7/Conv with /backbone_2d/blocks.1/blocks.1.9/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.10/Conv with /backbone_2d/blocks.1/blocks.1.12/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.13/Conv with /backbone_2d/blocks.1/blocks.1.15/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /backbone_2d/blocks.1/blocks.1.16/Conv with /backbone_2d/blocks.1/blocks.1.18/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ScaleScaleFusion
[10/24/2023-13:02:32] [V] [TRT] ScaleScaleFusion: Fusing model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] with model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization
[10/24/2023-13:02:32] [V] [TRT] Running: ScaleActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ScaleActivationFusion: Fusing model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization with /backbone_2d/deblocks.1/deblocks.1.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /shared_conv/shared_conv.0/Conv with /shared_conv/shared_conv.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/center/center.0/center.0.0/Conv with /heads_list.0/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/center_z/center_z.0/center_z.0.0/Conv with /heads_list.0/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/dim/dim.0/dim.0.0/Conv with /heads_list.0/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/rot/rot.0/rot.0.0/Conv with /heads_list.0/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/vel/vel.0/vel.0.0/Conv with /heads_list.0/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.0/hm/hm.0/hm.0.0/Conv with /heads_list.0/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/center/center.0/center.0.0/Conv with /heads_list.1/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/center_z/center_z.0/center_z.0.0/Conv with /heads_list.1/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/dim/dim.0/dim.0.0/Conv with /heads_list.1/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/rot/rot.0/rot.0.0/Conv with /heads_list.1/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/vel/vel.0/vel.0.0/Conv with /heads_list.1/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.1/hm/hm.0/hm.0.0/Conv with /heads_list.1/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/center/center.0/center.0.0/Conv with /heads_list.2/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/center_z/center_z.0/center_z.0.0/Conv with /heads_list.2/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/dim/dim.0/dim.0.0/Conv with /heads_list.2/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/rot/rot.0/rot.0.0/Conv with /heads_list.2/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/vel/vel.0/vel.0.0/Conv with /heads_list.2/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.2/hm/hm.0/hm.0.0/Conv with /heads_list.2/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/center/center.0/center.0.0/Conv with /heads_list.3/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/center_z/center_z.0/center_z.0.0/Conv with /heads_list.3/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/dim/dim.0/dim.0.0/Conv with /heads_list.3/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/rot/rot.0/rot.0.0/Conv with /heads_list.3/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/vel/vel.0/vel.0.0/Conv with /heads_list.3/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.3/hm/hm.0/hm.0.0/Conv with /heads_list.3/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/center/center.0/center.0.0/Conv with /heads_list.4/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/center_z/center_z.0/center_z.0.0/Conv with /heads_list.4/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/dim/dim.0/dim.0.0/Conv with /heads_list.4/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/rot/rot.0/rot.0.0/Conv with /heads_list.4/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/vel/vel.0/vel.0.0/Conv with /heads_list.4/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.4/hm/hm.0/hm.0.0/Conv with /heads_list.4/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/center/center.0/center.0.0/Conv with /heads_list.5/center/center.0/center.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/center_z/center_z.0/center_z.0.0/Conv with /heads_list.5/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/dim/dim.0/dim.0.0/Conv with /heads_list.5/dim/dim.0/dim.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/rot/rot.0/rot.0.0/Conv with /heads_list.5/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/vel/vel.0/vel.0.0/Conv with /heads_list.5/vel/vel.0/vel.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: ConvActivationFusion
[10/24/2023-13:02:32] [V] [TRT] ConvActivationFusion: Fusing /heads_list.5/hm/hm.0/hm.0.0/Conv with /heads_list.5/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:32] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:32] [V] [TRT] PointWiseFusion: Fusing (Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise] with (Unnamed Layer* 28) [Unary]
[10/24/2023-13:02:32] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:32] [V] [TRT] PointWiseFusion: Fusing PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]) with (Unnamed Layer* 30) [ElementWise]
[10/24/2023-13:02:32] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:32] [V] [TRT] PointWiseFusion: Fusing (Unnamed Layer* 29) [ElementWise] with PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])
[10/24/2023-13:02:32] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:32] [V] [TRT] PointWiseFusion: Fusing (Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise] with (Unnamed Layer* 62) [Unary]
[10/24/2023-13:02:33] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:33] [V] [TRT] PointWiseFusion: Fusing PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]) with (Unnamed Layer* 64) [ElementWise]
[10/24/2023-13:02:33] [V] [TRT] Running: PointWiseFusion
[10/24/2023-13:02:33] [V] [TRT] PointWiseFusion: Fusing (Unnamed Layer* 63) [ElementWise] with PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])
[10/24/2023-13:02:33] [V] [TRT] After vertical fusions: 96 layers
[10/24/2023-13:02:33] [V] [TRT] After dupe layer removal: 96 layers
[10/24/2023-13:02:33] [V] [TRT] After final dead-layer removal: 96 layers
[10/24/2023-13:02:33] [V] [TRT] Merging layers: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:33] [V] [TRT] Merging layers: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu
[10/24/2023-13:02:33] [V] [TRT] Merging layers: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:33] [V] [TRT] Merging layers: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu
[10/24/2023-13:02:33] [V] [TRT] Merging layers: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu
[10/24/2023-13:02:33] [V] [TRT] After tensor merging: 65 layers
[10/24/2023-13:02:33] [V] [TRT] Eliminating concatenation /backbone_2d/Concat
[10/24/2023-13:02:33] [V] [TRT] Retargeting /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0 to /backbone_2d/Concat_output_0
[10/24/2023-13:02:33] [V] [TRT] Retargeting /backbone_2d/deblocks.1/deblocks.1.2/Relu_output_0 to /backbone_2d/Concat_output_0
[10/24/2023-13:02:33] [V] [TRT] After concat removal: 64 layers
[10/24/2023-13:02:33] [V] [TRT] Graph construction and optimization completed in 0.882171 seconds.
[10/24/2023-13:02:34] [V] [TRT] Using cublasLt as a tactic source
[10/24/2023-13:02:34] [W] [TRT] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.1 but loaded cuBLAS/cuBLAS LT 11.5.2
[10/24/2023-13:02:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +750, GPU +318, now: CPU 1450, GPU 29827 (MiB)
[10/24/2023-13:02:34] [V] [TRT] Using cuDNN as a tactic source
[10/24/2023-13:02:35] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +194, GPU +324, now: CPU 1644, GPU 30151 (MiB)
[10/24/2023-13:02:35] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[10/24/2023-13:02:35] [V] [TRT] Constructing optimization profile number 0 [1/1].
[10/24/2023-13:02:35] [V] [TRT] Reserving memory for activation tensors. Host: 0 bytes Device: 21364736 bytes
[10/24/2023-13:02:35] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.050192
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.072192
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.050192
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.052256
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.07298
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.052256
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.052608
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.073216
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.052608
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.036628
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.034944
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.034944
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.038388
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.03702
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.03702
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.038528
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.06558
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.038528
[10/24/2023-13:02:35] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.036136
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.038404
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.036136
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.036224
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.03904
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.036224
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.02654
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.036992
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.02654
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.029204
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.0256
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0256
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.027648
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.0273
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0273
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.02752
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.036096
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.037376
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.048128
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.037376
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.036224
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.035584
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.035584
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.0288
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.043392
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.030208
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.043904
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.030208
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.027136
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.027136
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.027136
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.027008
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.02728
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.027008
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.037544
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.04864
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.037544
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.036096
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.03574
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.03574
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.028812
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.043776
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.028812
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.043932
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.02716
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.027904
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.02716
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.02714
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.027924
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.02714
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.028672
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.038416
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.029832
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.038656
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.029832
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.029824
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.03892
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.029824
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.021248
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.020352
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.020352
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.020656
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.021896
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.020656
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.02066
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.03584
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.02066
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.030748
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.026008
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.026008
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:35] [V] [TRT] Tactic: 1002 Time: 0.030984
[10/24/2023-13:02:35] [V] [TRT] Tactic: 0 Time: 0.030976
[10/24/2023-13:02:35] [V] [TRT] Fastest Tactic: 0 Time: 0.030976
[10/24/2023-13:02:35] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.03072
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.031744
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.03072
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.04864
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.020096
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.020096
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.021636
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.02112
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.02112
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.021772
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027664
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.021772
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030496
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027532
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.027532
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.029184
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027952
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.027952
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.029184
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.043648
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.018452
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.018452
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.022656
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.018304
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.018304
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.018944
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.025856
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.018944
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.039064
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.029064
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027916
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.027916
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.04416
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.033032
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.033032
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.022528
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.03304
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.0/blocks.0.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.018964
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.02588
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.018964
[10/24/2023-13:02:36] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.036864
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.039056
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.036864
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.036992
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.03932
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.036992
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.02688
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.03712
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.02688
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.029312
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.025756
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.025756
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.02754
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027264
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.027264
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.02752
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.036104
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.037776
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.048016
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.037776
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.036224
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.035584
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.035584
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.043392
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.03036
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.04352
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.03036
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.027136
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.02704
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.02704
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.027024
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027264
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.027024
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.038016
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.048652
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.038016
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.036224
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.035716
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.035716
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.028808
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.043648
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.028808
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.043676
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.030592
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.027276
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027904
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.027276
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.027136
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027908
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.027136
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.038032
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.03008
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.038796
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.03008
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.0297
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.03904
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.0297
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.021376
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.020352
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.020352
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.02088
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.02176
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.02088
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.020736
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.035844
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.020736
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.03048
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.026112
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.026112
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030976
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.031012
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.030976
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030864
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.031616
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.030864
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.048408
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.020096
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.020096
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.021632
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.021004
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.021004
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.021392
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027776
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 0.021392
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:36] [V] [TRT] Tactic: 1002 Time: 0.030208
[10/24/2023-13:02:36] [V] [TRT] Tactic: 0 Time: 0.027528
[10/24/2023-13:02:36] [V] [TRT] Fastest Tactic: 0 Time: 0.027528
[10/24/2023-13:02:36] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.029184
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.027908
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.027908
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.029184
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.02892
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.02892
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.043904
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.018324
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.018324
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.022528
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.018176
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.018176
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.01884
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.025896
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.01884
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.030236
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.039168
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.030236
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.02906
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.027908
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.027908
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.029312
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.028928
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.028928
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.043648
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.033292
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.033292
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.022528
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.033036
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.01884
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.025984
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.01884
[10/24/2023-13:02:37] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066836
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.075904
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.066836
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066712
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.076288
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.066712
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066816
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.155904
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.066816
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.1526
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.559232
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.1526
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050816
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.069888
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.050816
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.05598
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.046592
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.046592
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050848
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.050944
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.050848
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050688
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.069248
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.050688
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.155648
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.155392
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.155392
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.06978
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.099712
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.06978
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066048
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.064652
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.064652
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.06592
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.204288
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.06592
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.0544
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.089728
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.0544
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.056484
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.089728
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.056484
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050688
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.048384
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.048384
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050824
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.048384
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.048384
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.069524
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.099852
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.069524
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.06632
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.06464
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.06464
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066192
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.203776
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.066192
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.0544
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.087824
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.0544
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.08872
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.05056
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.049792
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.049792
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050984
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.049684
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.049684
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.069248
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.08192
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.069248
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066176
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.065536
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.065536
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.066328
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.065664
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.065664
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.05096
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.075776
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.05096
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.055168
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.075176
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.055168
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050304
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.0512
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.050304
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.050176
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.051456
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.050176
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 1.44614
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.142096
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.142096
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.669444
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.127636
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.127636
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.71706
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.626824
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.626824
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.052608
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.152088
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.052608
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.686336
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.541832
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.541832
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.147744
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.141208
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.141208
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.05532
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.047872
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.047872
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.057344
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.055552
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.057984
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.055552
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.054656
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.152192
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.054656
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.086012
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.034816
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.034816
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.038912
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.036752
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.036752
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.038912
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.050552
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 0.038912
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:37] [V] [TRT] Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:37] [V] [TRT] Tactic: 0 Time: 0.050944
[10/24/2023-13:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.050944
[10/24/2023-13:02:37] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.052116
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.050048
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.050048
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.052376
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.051328
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.051328
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.052112
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.190468
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.052112
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.076304
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.034836
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.034836
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.041088
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.035712
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.035712
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.036116
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.045696
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.036116
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.076032
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.052016
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.050204
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.050204
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.052352
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.051456
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.051456
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.051864
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.190592
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.051864
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.076288
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.07092
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.07092
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.041112
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.071808
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.041112
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.03612
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.04574
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 0.03612
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.664576
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.140928
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.140928
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.747776
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.63504
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.63504
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 2.11853
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.126976
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.126976
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:38] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006148
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.00832
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.005104
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.005104
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008196
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006816
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006528
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.0064
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.004988
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.004988
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.0064
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.004864
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.004864
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006528
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006392
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.005108
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.005108
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006428
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006408
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.005112
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.005112
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.005112
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.005112
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006152
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008576
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006428
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006308
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.00832
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:38] [V] [TRT] Tactic: 1002 Time: 0.006304
[10/24/2023-13:02:38] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:38] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006324
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006272
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005248
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006528
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.009196
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00704
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.007152
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.0064
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00716
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006912
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005108
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005108
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.007052
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005112
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005112
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.007156
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.0064
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004736
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004736
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006892
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006924
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006272
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005112
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005112
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006272
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004716
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004716
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006792
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00668
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00704
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.0064
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.0068
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00656
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00704
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005116
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006676
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006932
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004976
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004976
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006912
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006936
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006952
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006936
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006952
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.005136
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.005136
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.00704
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.007168
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 24) [Shuffle]_output -> <out>) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.007216
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:39] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:39] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.066944
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.075904
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 1002 Time: 0.066944
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.06684
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.076544
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 1002 Time: 0.06684
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.050972
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.047676
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.047676
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.05568
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.046608
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.046608
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:39] [V] [TRT] Tactic: 1002 Time: 0.051456
[10/24/2023-13:02:39] [V] [TRT] Tactic: 0 Time: 0.051328
[10/24/2023-13:02:39] [V] [TRT] Fastest Tactic: 0 Time: 0.051328
[10/24/2023-13:02:39] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.051328
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.068864
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.051328
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.069632
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.099456
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.069632
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.06644
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.064648
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.064648
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.054292
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.090496
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.054292
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.0896
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.05122
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.048768
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.048768
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.050836
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.048792
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.048792
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.070016
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.09984
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.070016
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.066712
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.064768
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.064768
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.054532
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.087552
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.054532
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.05696
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.089344
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.05696
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.050944
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.050432
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.050432
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.050944
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.050304
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.050304
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.051216
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.04928
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.04928
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.053632
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.073364
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.053632
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.053512
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.074012
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.053512
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.037888
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.035584
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.035584
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.040192
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.03802
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.03802
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.040336
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.066304
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.040336
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.055076
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.049408
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.049408
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.055936
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.057508
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.055936
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.055692
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.058496
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.055692
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.086416
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.038156
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.038156
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.039168
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.03776
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.03776
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.0393
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.050688
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.0393
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.05568
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.076048
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.05568
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.052352
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.050304
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.050304
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.05248
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.051456
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.051456
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.076416
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.071052
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.071052
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.041096
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.035072
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.035072
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.035996
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.045952
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.035996
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.05546
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.07616
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.05546
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.052376
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.050312
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.050312
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.052864
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.051456
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.051456
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.076164
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.071076
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.071076
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.041216
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.071576
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.041216
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /backbone_2d/deblocks.0/deblocks.0.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.036244
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.04608
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.036244
[10/24/2023-13:02:40] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1,16384,128) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(524288,1:4,4096,32) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384:2,128,1) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:8,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:16,1024,8) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:02:40] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.017716
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.024064
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.017716
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.01782
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.024192
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.01782
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.0128
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.016256
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.0128
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.013952
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.010752
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.010752
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.01154
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.011392
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 0 Time: 0.011392
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.011544
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.02176
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.011544
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.019968
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.025344
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.019968
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.018588
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.013572
[10/24/2023-13:02:40] [V] [TRT] Tactic: 0 Time: 0.019992
[10/24/2023-13:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.013572
[10/24/2023-13:02:40] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:40] [V] [TRT] Tactic: 1002 Time: 0.010884
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.010884
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.010776
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.010776
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.019968
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.025344
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.019968
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.017664
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.018704
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.017664
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013724
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.02012
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013724
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01116
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.016256
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.01116
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.010752
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.016512
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.010752
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.014208
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.014736
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.014208
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013184
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.021764
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013184
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.021936
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.0114
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.01024
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01166
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.00974
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.00974
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.011648
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.021376
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.011648
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01408
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.012948
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.016664
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.012948
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.017536
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.026752
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.010244
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.010244
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01116
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.015376
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.01116
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013612
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.011008
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.011008
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.015488
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.016512
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.023584
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.008228
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.008228
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01336
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.010264
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.015232
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.010264
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013576
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013576
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.01498
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.016512
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.023592
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/blocks.1/blocks.1.3/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,16384,256) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,4096,64) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,4096,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,4096:2,64,1) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,2048,32) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,1024,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(256,1,256,256) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(64,1:4,64,64) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8,1:32,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(256,1,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(128,1:2,1,1) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(32,1:8,32,32) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(16,1:16,16,16) -> Half(1:8,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(256,1,256,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(64,1:4,64,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(8,1:32,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Float(1:4,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(256,1,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(128,1:2,1,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(32,1:8,32,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,1,1,1) -> Half(16,1:16,16,16) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(131072,16384:32,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(1:4,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1:8,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.126752
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.1493
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.126752
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.149376
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.094976
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.131072
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.094976
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.107284
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.087808
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.087808
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.09678
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.096512
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.096512
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.096384
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.133648
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.096384
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.211328
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.125712
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.123032
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.123032
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.102544
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.187816
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.102544
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.107776
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.191104
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.107776
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.09576
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.090496
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.090496
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.095504
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.090624
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.090624
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.131736
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.210688
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.131736
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.125824
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.122752
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 0 Time: 0.122752
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.102272
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.18816
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.102272
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:41] [V] [TRT] Tactic: 1002 Time: 0.108308
[10/24/2023-13:02:41] [V] [TRT] Tactic: 0 Time: 0.190736
[10/24/2023-13:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.108308
[10/24/2023-13:02:41] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.095624
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.09344
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.09344
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.095636
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.09344
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.09344
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.09524
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.140928
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.09524
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.100736
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.138624
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.100736
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.10024
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.137728
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.10024
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0704
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.06528
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.06528
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.08256
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.069632
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.069632
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0832
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.121984
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.0832
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.104192
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.09152
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.09152
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.103808
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.109976
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.103808
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.10368
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.111236
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.10368
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.161408
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.064512
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.064512
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.071552
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.070024
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.070024
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.071552
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.096812
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.071552
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.108428
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.098332
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.098332
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0992
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.094096
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.094096
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.099084
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.096512
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.096512
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.139664
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.066944
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.066944
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.076684
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.067512
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.067512
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.066688
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.085248
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.066688
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.108672
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.16244
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.108672
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.099328
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.094336
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.094336
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.099328
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.096512
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.096512
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.139264
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.148516
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.139264
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.077312
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.152832
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.077312
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/backbone_2d/Concat_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.066432
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.085248
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.066432
[10/24/2023-13:02:42] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.017664
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.02112
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.017664
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0177
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.021252
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.0177
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.012728
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.015888
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.012728
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.014464
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.011032
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.011032
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011668
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.011416
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 0 Time: 0.011416
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011648
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.015872
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.011648
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.019728
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.02292
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.019728
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.018052
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.019076
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.018052
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011916
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.011916
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0137
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.0137
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.010632
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.010632
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.01088
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.014336
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.01088
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.020224
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.023304
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.020224
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.018176
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.01896
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.018176
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011664
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.011664
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.013572
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.013572
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.010776
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.016128
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.010776
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011024
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.016164
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.011024
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.0141
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.0141
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.013188
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.016656
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.013188
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.01308
[10/24/2023-13:02:42] [V] [TRT] Tactic: 0 Time: 0.016916
[10/24/2023-13:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 0.01308
[10/24/2023-13:02:42] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:42] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.010268
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.010268
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011524
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01024
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011428
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.014208
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011428
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.013828
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.011936
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.011936
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.015908
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.012928
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.016792
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.012928
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.026624
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01024
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01126
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011136
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011136
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.010496
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.010496
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.015232
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.012036
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.016532
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.012036
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.025088
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.008332
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.008332
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01332
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.008064
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.008064
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.012584
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019608
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.012584
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01474
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.01216
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.012184
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.016532
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.012184
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.025088
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /shared_conv/shared_conv.2/Relu_output_0) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.010244
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.015232
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.010244
[10/24/2023-13:02:43] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.017676
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.021376
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.017676
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.017444
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.021248
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.017444
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01256
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.016136
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.01256
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.014336
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.010892
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.010892
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011776
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.011396
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 0 Time: 0.011396
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011532
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.015764
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011532
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.019864
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.022912
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.019864
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019072
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011916
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019584
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011916
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.013696
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.013696
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011008
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011008
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.010664
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.014464
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.010664
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01984
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.0233
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.01984
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.018048
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.018816
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.018048
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.011932
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.019596
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.011932
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.013696
[10/24/2023-13:02:43] [V] [TRT] Tactic: 0 Time: 0.01984
[10/24/2023-13:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.013696
[10/24/2023-13:02:43] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:43] [V] [TRT] Tactic: 1002 Time: 0.01088
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.015888
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.01088
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.011008
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.016128
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.011008
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.013956
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.014884
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.013956
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01666
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.013056
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012992
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01694
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012992
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.010244
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.010244
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.01166
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01024
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.011692
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.014336
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.011692
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.01408
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01216
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.01216
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012824
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.015892
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012824
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.01282
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.016956
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.01282
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.026636
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01026
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.01026
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.011156
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.011156
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.010508
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.010508
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012168
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.014996
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012168
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012032
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.016536
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012032
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.024832
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.008064
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.008064
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.015232
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.010368
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012444
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.019712
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012444
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012308
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.015104
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012308
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.012032
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.016512
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.012032
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.025088
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.013328
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.013328
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/shared_conv/shared_conv.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.01024
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.015232
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.01024
[10/24/2023-13:02:44] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.14912
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.149376
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.127104
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.094976
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.13096
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.094976
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.107264
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.087832
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.087832
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.096512
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.09666
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.096512
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.09664
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.134016
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.09664
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.210688
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.126208
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.12288
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.12288
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.102144
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.188156
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.102144
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.107904
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.190976
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.107904
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.095496
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.090508
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.090508
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.095628
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.090388
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.090388
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.211092
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.131584
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.125952
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.122524
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.122524
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.102156
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.188672
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.102156
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.107776
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.191232
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.107776
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.096128
[10/24/2023-13:02:44] [V] [TRT] Tactic: 0 Time: 0.093568
[10/24/2023-13:02:44] [V] [TRT] Fastest Tactic: 0 Time: 0.093568
[10/24/2023-13:02:44] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:44] [V] [TRT] Tactic: 1002 Time: 0.095488
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.09344
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.09344
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.09562
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.14208
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.09562
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.100736
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.138892
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.100736
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.100364
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.137856
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.100364
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.070016
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.06554
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.06554
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.082332
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.069648
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.069648
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.082944
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.122496
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.082944
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.104464
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.091664
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.091664
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.104204
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.109948
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.104204
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.104192
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.111252
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.104192
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.161792
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.064384
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.064384
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.071696
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.070032
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.070032
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.071808
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.096796
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.071808
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.108544
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.098432
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.098432
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.0992
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.094336
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.094336
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.098944
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.096512
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.096512
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.139648
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.066572
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.066572
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.076928
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.06774
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.06774
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.066696
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.085256
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.066696
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.108672
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.162192
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.108672
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.099072
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.094324
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.094324
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.099732
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.096512
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.096512
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.139648
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.148224
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.139648
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.0768
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.152956
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.0768
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.066688
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.085136
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.066688
[10/24/2023-13:02:45] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.02112
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.01792
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.0177
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.021504
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.0177
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.014592
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.012552
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.012552
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.014344
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.01408
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.01408
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.011656
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.015632
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.011656
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.011776
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.015616
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.011776
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.01984
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.026112
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.01984
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.018432
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.019448
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.018432
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012548
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.020492
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012548
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.014592
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.020728
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.014592
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.0146
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012312
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.01472
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012312
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.01998
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.026392
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.01998
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.018048
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.018048
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.020352
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.014736
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.020608
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.014736
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.016256
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.016524
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.012416
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.015364
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.014592
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.014592
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.01728
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.017536
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:45] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:45] [V] [TRT] Tactic: 0 Time: 0.013056
[10/24/2023-13:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:45] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.011692
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.014336
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.011692
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.011544
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.014208
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.011544
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014208
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.01306
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.01306
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.012948
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.016512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.012948
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.013084
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.016972
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.013084
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.026624
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.010356
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.010356
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.01408
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.012172
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.012172
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.012932
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.012932
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.012564
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.016384
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.012564
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.024848
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.01344
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.01024
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.01024
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.01384
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.019468
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.01384
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.012712
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.016376
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.012712
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.02508
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.019328
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.019328
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.013324
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.013324
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.0/center/center.0/center.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.010384
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.015248
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.010384
[10/24/2023-13:02:46] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00514
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00514
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.008448
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.00832
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.005248
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005248
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014464
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014732
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014848
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.006016
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.006016
[10/24/2023-13:02:46] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.006164
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.005124
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005124
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.008208
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014464
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.005108
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.005108
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014348
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.014492
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:46] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.006144
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:46] [V] [TRT] Tactic: 1002 Time: 0.008204
[10/24/2023-13:02:46] [V] [TRT] Tactic: 0 Time: 0.00514
[10/24/2023-13:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.00514
[10/24/2023-13:02:46] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.008192
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.005368
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005368
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.014368
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.00512
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.014604
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.004992
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.014464
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.00614
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.00614
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(8388608,1,65536,512) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(2097152,1:4,16384,128) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(8388608,16384,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384:2,128,1) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,1:8,8192,64) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:16,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1,8192,64) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(262144,1:4,2048,16) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(1048576,16384,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,16384:2,128,1) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(131072,1:8,1024,8) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(65536,1:16,512,4) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:02:47] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.066188
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.075412
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.066188
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.066324
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.075904
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.066324
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050836
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.070272
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.050836
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.05566
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.046116
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.046116
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050944
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.050816
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.050816
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050688
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.068992
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.050688
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.069676
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.099464
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.069676
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.065928
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.064376
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.064376
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.054168
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.089728
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.054168
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.09024
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.056704
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.05056
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.048384
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.048384
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050432
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.048384
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.048384
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.069896
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.099828
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.069896
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.0659
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.06428
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.06428
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.054144
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.087808
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.054144
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.056476
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.088576
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.056476
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050432
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.049536
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.049536
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050432
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.049412
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.049412
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.050944
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.072576
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.050944
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.053128
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.073488
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.053128
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.052636
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.073984
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.052636
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.037284
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.035456
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.035456
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.039168
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.037376
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.037376
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.038928
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.066304
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.038928
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.054788
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.047752
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.047752
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.057088
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.055424
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.055188
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.057744
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.055188
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.086144
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.034688
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.034688
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.038552
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.036616
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.036616
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.038656
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.050432
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.038656
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.055552
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.05058
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.05058
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.05224
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.049664
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.049664
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.052224
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.0512
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.0512
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.076544
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.034816
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.034816
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.041088
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.035312
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.035312
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.036096
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.045824
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.036096
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.05568
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.075808
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.05568
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.052224
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.050032
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.050032
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:47] [V] [TRT] Tactic: 1002 Time: 0.052248
[10/24/2023-13:02:47] [V] [TRT] Tactic: 0 Time: 0.051456
[10/24/2023-13:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.051456
[10/24/2023-13:02:47] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.076032
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.071064
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.071064
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.041088
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.07168
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.041088
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.036096
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.045844
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.036096
[10/24/2023-13:02:48] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.017684
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.021248
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.017684
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.017668
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.021376
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.017668
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.014592
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.012696
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.012696
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.014336
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.013988
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.013988
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011672
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.015616
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011672
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.01152
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.015616
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.01152
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.020352
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.024832
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.020352
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.018688
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.019184
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.018688
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.019524
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.014316
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.020352
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.014316
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.01436
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011408
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.014372
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011408
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.020352
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.025088
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.020352
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.018688
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.019328
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.018688
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.019472
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.012288
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.014336
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.020224
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.014336
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.016384
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011308
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.016384
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011308
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.015488
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.014248
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.014248
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.013328
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.017408
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.013328
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.013316
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.017664
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.013316
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011392
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.013312
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011392
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011548
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.014336
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011548
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.011776
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.014336
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.011776
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.0138
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.012212
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.012212
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.012928
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.016508
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.012928
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.01306
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.016908
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.01306
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:48] [V] [TRT] Tactic: 1002 Time: 0.027024
[10/24/2023-13:02:48] [V] [TRT] Tactic: 0 Time: 0.01024
[10/24/2023-13:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[10/24/2023-13:02:48] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.011264
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.013696
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.011584
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.011584
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.01664
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.025328
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.013312
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.008192
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.010264
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.015356
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.010264
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.013688
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.019716
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.013688
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.015488
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.016524
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.012544
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.025216
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.019456
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.013316
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.019352
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.013316
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(/heads_list.5/dim/dim.0/dim.0.2/Relu_output_0 -> <out>) (Reformat)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1002 Time: 0.010396
[10/24/2023-13:02:49] [V] [TRT] Tactic: 0 Time: 0.01536
[10/24/2023-13:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.010396
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(49152,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(49152,1,384,3) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(32768,16384:2,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(4194304,1,32768,256) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(1048576,1:4,8192,64) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(4194304,16384,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(2097152,16384:2,128,1) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(524288,1:8,4096,32) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(262144,1:16,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing reformatting costs
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(32768,1,256,2) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Float(16384,1:4,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,16384:2,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:8,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning Reformat:Half(16384,1:16,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning format combination:  -> Float(256,1,1,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning format combination:  -> Half(256,1,1,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning format combination:  -> Float(256,1,1,1) ***************
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning format combination:  -> Half(256,1,1,1) ***************
[10/24/2023-13:02:49] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:02:49] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:02:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:02:49] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (FusedConvActConvolution)
[10/24/2023-13:02:49] [V] [TRT] Tactic: 524287 Time: 0.518048
[10/24/2023-13:02:49] [V] [TRT] Tactic: 720895 Time: 0.455944
[10/24/2023-13:02:49] [V] [TRT] Tactic: 983039 Time: 0.458624
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1048575 Time: 0.468368
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1703935 Time: 0.456448
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1769471 Time: 0.530344
[10/24/2023-13:02:49] [V] [TRT] Tactic: 1966079 Time: 0.600604
[10/24/2023-13:02:49] [V] [TRT] Tactic: 2031615 Time: 0.585368
[10/24/2023-13:02:49] [V] [TRT] Tactic: 2228223 Time: 0.512772
[10/24/2023-13:02:50] [V] [TRT] Tactic: 2424831 Time: 0.567428
[10/24/2023-13:02:50] [V] [TRT] Tactic: 2621439 Time: 0.482176
[10/24/2023-13:02:50] [V] [TRT] Tactic: 2752511 Time: 0.467312
[10/24/2023-13:02:50] [V] [TRT] Tactic: 2818047 Time: 0.514452
[10/24/2023-13:02:50] [V] [TRT] Tactic: 2883583 Time: 0.55758
[10/24/2023-13:02:50] [V] [TRT] Tactic: 3014655 Time: 0.452864
[10/24/2023-13:02:50] [V] [TRT] Tactic: 3145727 Time: 0.448128
[10/24/2023-13:02:50] [V] [TRT] Tactic: 3473407 Time: 0.482816
[10/24/2023-13:02:50] [V] [TRT] Tactic: 3604479 Time: 0.473728
[10/24/2023-13:02:50] [V] [TRT] Tactic: 3735551 Time: 0.51456
[10/24/2023-13:02:50] [V] [TRT] Tactic: 4390911 Time: 0.503424
[10/24/2023-13:02:50] [V] [TRT] Tactic: 5046271 Time: 0.497172
[10/24/2023-13:02:50] [V] [TRT] Tactic: 5963775 Time: 0.513672
[10/24/2023-13:02:50] [V] [TRT] Tactic: 6160383 Time: 0.563844
[10/24/2023-13:02:50] [V] [TRT] Tactic: 6488063 Time: 0.477184
[10/24/2023-13:02:51] [V] [TRT] Tactic: 6881279 Time: 0.532492
[10/24/2023-13:02:51] [V] [TRT] Tactic: 7274495 Time: 0.555392
[10/24/2023-13:02:51] [V] [TRT] Tactic: 7864319 Time: 0.50688
[10/24/2023-13:02:51] [V] [TRT] Tactic: 7995391 Time: 0.511764
[10/24/2023-13:02:51] [V] [TRT] Tactic: 8585215 Time: 0.4928
[10/24/2023-13:02:51] [V] [TRT] Tactic: 8847359 Time: 0.584704
[10/24/2023-13:02:51] [V] [TRT] Tactic: 8978431 Time: 0.50112
[10/24/2023-13:02:51] [V] [TRT] Tactic: 9043967 Time: 0.469376
[10/24/2023-13:02:51] [V] [TRT] Tactic: 9175039 Time: 0.473728
[10/24/2023-13:02:51] [V] [TRT] Tactic: 9502719 Time: 0.477976
[10/24/2023-13:02:51] [V] [TRT] Tactic: 9830399 Time: 0.53248
[10/24/2023-13:02:51] [V] [TRT] Tactic: 9961471 Time: 0.582784
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10027007 Time: 0.479116
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10092543 Time: 0.502528
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10289151 Time: 0.600704
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10485759 Time: 0.466448
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10682367 Time: 0.473356
[10/24/2023-13:02:51] [V] [TRT] Tactic: 10813439 Time: 0.474624
[10/24/2023-13:02:51] [V] [TRT] Fastest Tactic: 3145727 Time: 0.448128
[10/24/2023-13:02:52] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:02:56] [V] [TRT] Tactic: 0 Time: 0.9184
[10/24/2023-13:02:56] [V] [TRT] Tactic: 1 Time: 0.324392
[10/24/2023-13:02:56] [V] [TRT] Tactic: 2 Time: 1.08006
[10/24/2023-13:02:56] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17450532864, available: 4294967296
[10/24/2023-13:02:56] [V] [TRT] Tactic: 5 Time: 7.19882
[10/24/2023-13:02:56] [V] [TRT] Tactic: 6 Time: 0.374148
[10/24/2023-13:02:56] [V] [TRT] Tactic: 56 Time: 0.918284
[10/24/2023-13:02:56] [V] [TRT] Tactic: 57 Time: 0.32448
[10/24/2023-13:02:56] [V] [TRT] Tactic: 58 Time: 1.08059
[10/24/2023-13:02:56] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17450532864, available: 4294967296
[10/24/2023-13:02:56] [V] [TRT] Tactic: 61 Time: 7.20023
[10/24/2023-13:02:56] [V] [TRT] Tactic: 62 Time: 0.374144
[10/24/2023-13:02:56] [V] [TRT] Tactic: 112 Time: 0.918912
[10/24/2023-13:02:56] [V] [TRT] Tactic: 113 Time: 0.826752
[10/24/2023-13:02:56] [V] [TRT] Tactic: 114 Time: 1.0806
[10/24/2023-13:02:56] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17450532864, available: 4294967296
[10/24/2023-13:02:56] [V] [TRT] Tactic: 117 Time: 7.20013
[10/24/2023-13:02:56] [V] [TRT] Tactic: 118 Time: 0.375296
[10/24/2023-13:02:56] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[10/24/2023-13:02:56] [V] [TRT] Fastest Tactic: 1 Time: 0.324392
[10/24/2023-13:02:56] [V] [TRT] Setting workspace to 17450532864enables more tactics for profiling
[10/24/2023-13:02:56] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:02:56] [V] [TRT] Tactic: 4549827808004681195 Time: 0.648064
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:02:56] [V] [TRT] Tactic: 5779835512569528575 Time: 0.550152
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:02:56] [V] [TRT] Tactic: 6053873026024413720 Time: 0.56448
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:02:56] [V] [TRT] Tactic: 6767548733843469815 Time: 0.64768
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:02:56] [V] [TRT] Tactic: -6313876406580483184 Time: 0.750464
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:02:56] [V] [TRT] Tactic: -1123676555321336786 Time: 0.553984
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:02:56] [V] [TRT] Tactic: -701551393537224327 Time: 0.66204
[10/24/2023-13:02:56] [V] [TRT] Fastest Tactic: 5779835512569528575 Time: 0.550152
[10/24/2023-13:02:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:02:56] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:02:56] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:02:56] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:02:56] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:02:56] [V] [TRT] Tactic: 2086609538387166260 Time: 0.74382
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:02:56] [V] [TRT] Tactic: 2860655430572478466 Time: 0.617856
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:02:56] [V] [TRT] Tactic: 3239733199291090177 Time: 0.742784
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:02:56] [V] [TRT] Tactic: 4474630279712975759 Time: 0.575368
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:02:56] [V] [TRT] Tactic: 4479823862704990365 Time: 0.570904
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:02:56] [V] [TRT] Tactic: 4517590677127196184 Time: 1.12947
[10/24/2023-13:02:56] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4634080872644479428 Time: 0.733184
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4696204239951173149 Time: 0.618384
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:02:57] [V] [TRT] Tactic: 5778138195697110003 Time: 0.568448
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:02:57] [V] [TRT] Tactic: 6310198979346901507 Time: 0.70528
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:02:57] [V] [TRT] Tactic: 7155825427510256858 Time: 0.543232
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:02:57] [V] [TRT] Tactic: 7222247112373541608 Time: 0.922404
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:02:57] [V] [TRT] Tactic: 7472640475524677095 Time: 0.746112
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:02:57] [V] [TRT] Tactic: 8498373915030836990 Time: 1.22176
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:02:57] [V] [TRT] Tactic: 8869697132622550639 Time: 1.10221
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:02:57] [V] [TRT] Tactic: 8918020581761223752 Time: 0.537088
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:02:57] [V] [TRT] Tactic: -8937725997228636978 Time: 0.643252
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:02:57] [V] [TRT] Tactic: -8833858409138163072 Time: 1.13677
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:02:57] [V] [TRT] Tactic: -7989138351613022500 Time: 0.926352
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:02:57] [V] [TRT] Tactic: -7872883691240863058 Time: 0.741248
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:02:57] [V] [TRT] Tactic: -6729618519651721910 Time: 0.741248
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:02:57] [V] [TRT] Tactic: -5893833996418445881 Time: 1.07661
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:02:57] [V] [TRT] Tactic: -5701562095007058349 Time: 1.14291
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:02:57] [V] [TRT] Tactic: -5685503422376017600 Time: 0.917384
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:02:57] [V] [TRT] Tactic: -5521125187060117489 Time: 0.938884
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:02:57] [V] [TRT] Tactic: -4756382386362004279 Time: 0.609664
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:02:57] [V] [TRT] Tactic: -4615000974950361663 Time: 0.922376
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:02:57] [V] [TRT] Tactic: -4314913710375142296 Time: 0.987136
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:02:57] [V] [TRT] Tactic: -3855385237722507464 Time: 0.571528
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:02:57] [V] [TRT] Tactic: -3697587361057948972 Time: 0.918784
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:02:57] [V] [TRT] Tactic: -2809379259463049391 Time: 0.569344
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:02:57] [V] [TRT] Tactic: -2747929399988666512 Time: 1.12282
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:02:57] [V] [TRT] Tactic: -1472061967969061456 Time: 1.20051
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:02:57] [V] [TRT] Tactic: -504296718212024303 Time: 0.5394
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:02:57] [V] [TRT] Tactic: -444093195553988951 Time: 0.735232
[10/24/2023-13:02:57] [V] [TRT] Fastest Tactic: 8918020581761223752 Time: 0.537088
[10/24/2023-13:02:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8918020581761223752
[10/24/2023-13:02:57] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:02:57] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:02:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:02:57] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:02:57] [V] [TRT] Tactic: 2086609538387166260 Time: 0.74306
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:02:57] [V] [TRT] Tactic: 2860655430572478466 Time: 0.617988
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:02:57] [V] [TRT] Tactic: 3239733199291090177 Time: 0.741376
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4474630279712975759 Time: 0.575772
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4479823862704990365 Time: 0.573056
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4517590677127196184 Time: 1.13421
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4634080872644479428 Time: 0.732928
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:02:57] [V] [TRT] Tactic: 4696204239951173149 Time: 0.621312
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:02:57] [V] [TRT] Tactic: 5778138195697110003 Time: 0.568576
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:02:57] [V] [TRT] Tactic: 6310198979346901507 Time: 0.705408
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:02:57] [V] [TRT] Tactic: 7155825427510256858 Time: 0.543136
[10/24/2023-13:02:57] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:02:58] [V] [TRT] Tactic: 7222247112373541608 Time: 0.922372
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:02:58] [V] [TRT] Tactic: 7342025736444949634 Time: 0.233872
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:02:58] [V] [TRT] Tactic: 7472640475524677095 Time: 0.745984
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:02:58] [V] [TRT] Tactic: 8498373915030836990 Time: 1.22138
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:02:58] [V] [TRT] Tactic: 8869697132622550639 Time: 1.10196
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:02:58] [V] [TRT] Tactic: 8918020581761223752 Time: 0.53696
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:02:58] [V] [TRT] Tactic: -8937725997228636978 Time: 0.643712
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:02:58] [V] [TRT] Tactic: -8833858409138163072 Time: 1.13562
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:02:58] [V] [TRT] Tactic: -7989138351613022500 Time: 0.922496
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:02:58] [V] [TRT] Tactic: -7872883691240863058 Time: 0.739216
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:02:58] [V] [TRT] Tactic: -7377458734869418330 Time: 0.216324
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:02:58] [V] [TRT] Tactic: -6729618519651721910 Time: 0.741248
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:02:58] [V] [TRT] Tactic: -5893833996418445881 Time: 1.0761
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:02:58] [V] [TRT] Tactic: -5701562095007058349 Time: 1.14278
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:02:58] [V] [TRT] Tactic: -5685503422376017600 Time: 0.921472
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:02:58] [V] [TRT] Tactic: -5521125187060117489 Time: 0.939008
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:02:58] [V] [TRT] Tactic: -5457304872213719461 Time: 0.21568
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:02:58] [V] [TRT] Tactic: -4756382386362004279 Time: 0.612744
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:02:58] [V] [TRT] Tactic: -4615000974950361663 Time: 0.928512
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:02:58] [V] [TRT] Tactic: -4314913710375142296 Time: 0.987144
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:02:58] [V] [TRT] Tactic: -3855385237722507464 Time: 0.571264
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:02:58] [V] [TRT] Tactic: -3697587361057948972 Time: 0.916232
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:02:58] [V] [TRT] Tactic: -2809379259463049391 Time: 0.569112
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:02:58] [V] [TRT] Tactic: -2747929399988666512 Time: 1.1245
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:02:58] [V] [TRT] Tactic: -1472061967969061456 Time: 1.19108
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:02:58] [V] [TRT] Tactic: -504296718212024303 Time: 0.53952
[10/24/2023-13:02:58] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:02:58] [V] [TRT] Tactic: -444093195553988951 Time: 0.735616
[10/24/2023-13:02:58] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.21568
[10/24/2023-13:02:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:02:58] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:02:58] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:02:58] [V] [TRT] Tactic: 0 Time: 0.983168
[10/24/2023-13:02:58] [V] [TRT] Tactic: 1 Time: 0.809376
[10/24/2023-13:02:58] [V] [TRT] Tactic: 2 Time: 0.907136
[10/24/2023-13:02:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17450532864, available: 4294967296
[10/24/2023-13:02:58] [V] [TRT] Tactic: 5 Time: 7.14253
[10/24/2023-13:02:58] [V] [TRT] Tactic: 6 Time: 0.40572
[10/24/2023-13:02:58] [V] [TRT] Tactic: 56 Time: 0.980096
[10/24/2023-13:02:58] [V] [TRT] Tactic: 58 Time: 0.907648
[10/24/2023-13:02:58] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17450532864, available: 4294967296
[10/24/2023-13:02:59] [V] [TRT] Tactic: 61 Time: 7.14418
[10/24/2023-13:02:59] [V] [TRT] Tactic: 62 Time: 0.405632
[10/24/2023-13:02:59] [V] [TRT] Fastest Tactic: 62 Time: 0.405632
[10/24/2023-13:02:59] [V] [TRT] Setting workspace to 17450532864enables more tactics for profiling
[10/24/2023-13:02:59] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:02:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:02:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:02:59] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:02:59] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (FusedConvActConvolution)
[10/24/2023-13:02:59] [V] [TRT] Tactic: 524287 Time: 0.360448
[10/24/2023-13:02:59] [V] [TRT] Tactic: 720895 Time: 0.330636
[10/24/2023-13:02:59] [V] [TRT] Tactic: 983039 Time: 0.32192
[10/24/2023-13:02:59] [V] [TRT] Tactic: 1048575 Time: 0.326912
[10/24/2023-13:02:59] [V] [TRT] Tactic: 1703935 Time: 0.31552
[10/24/2023-13:02:59] [V] [TRT] Tactic: 1769471 Time: 0.35944
[10/24/2023-13:02:59] [V] [TRT] Tactic: 1966079 Time: 0.41066
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2031615 Time: 0.390928
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2228223 Time: 0.33856
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2424831 Time: 0.364032
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2621439 Time: 0.323712
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2752511 Time: 0.33408
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2818047 Time: 0.331532
[10/24/2023-13:02:59] [V] [TRT] Tactic: 2883583 Time: 0.398592
[10/24/2023-13:02:59] [V] [TRT] Tactic: 3014655 Time: 0.325256
[10/24/2023-13:02:59] [V] [TRT] Tactic: 3145727 Time: 0.324368
[10/24/2023-13:03:00] [V] [TRT] Tactic: 3473407 Time: 0.320044
[10/24/2023-13:03:00] [V] [TRT] Tactic: 3604479 Time: 0.3286
[10/24/2023-13:03:00] [V] [TRT] Tactic: 3735551 Time: 0.33282
[10/24/2023-13:03:00] [V] [TRT] Tactic: 4390911 Time: 0.354456
[10/24/2023-13:03:00] [V] [TRT] Tactic: 5046271 Time: 0.342292
[10/24/2023-13:03:00] [V] [TRT] Tactic: 5963775 Time: 0.369536
[10/24/2023-13:03:00] [V] [TRT] Tactic: 6160383 Time: 0.370816
[10/24/2023-13:03:00] [V] [TRT] Tactic: 6488063 Time: 0.363136
[10/24/2023-13:03:00] [V] [TRT] Tactic: 6881279 Time: 0.349952
[10/24/2023-13:03:00] [V] [TRT] Tactic: 7274495 Time: 0.34688
[10/24/2023-13:03:00] [V] [TRT] Tactic: 7864319 Time: 0.3424
[10/24/2023-13:03:00] [V] [TRT] Tactic: 7995391 Time: 0.358028
[10/24/2023-13:03:00] [V] [TRT] Tactic: 8585215 Time: 0.343044
[10/24/2023-13:03:00] [V] [TRT] Tactic: 8847359 Time: 0.344576
[10/24/2023-13:03:00] [V] [TRT] Tactic: 8978431 Time: 0.370944
[10/24/2023-13:03:00] [V] [TRT] Tactic: 9043967 Time: 0.33844
[10/24/2023-13:03:00] [V] [TRT] Tactic: 9175039 Time: 0.328576
[10/24/2023-13:03:00] [V] [TRT] Tactic: 9502719 Time: 0.353304
[10/24/2023-13:03:00] [V] [TRT] Tactic: 9830399 Time: 0.354576
[10/24/2023-13:03:00] [V] [TRT] Tactic: 9961471 Time: 0.368512
[10/24/2023-13:03:00] [V] [TRT] Tactic: 10027007 Time: 0.337992
[10/24/2023-13:03:00] [V] [TRT] Tactic: 10092543 Time: 0.354304
[10/24/2023-13:03:01] [V] [TRT] Tactic: 10289151 Time: 0.410772
[10/24/2023-13:03:01] [V] [TRT] Tactic: 10485759 Time: 0.328576
[10/24/2023-13:03:01] [V] [TRT] Tactic: 10682367 Time: 0.329604
[10/24/2023-13:03:01] [V] [TRT] Tactic: 10813439 Time: 0.32512
[10/24/2023-13:03:01] [V] [TRT] Fastest Tactic: 1703935 Time: 0.31552
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:03:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:03:01] [V] [TRT] Tactic: 2195670545862694453 Time: 0.399876
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:03:01] [V] [TRT] Tactic: 3419182076704469245 Time: 0.3894
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:03:01] [V] [TRT] Tactic: 3891805945559659536 Time: 0.36864
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:03:01] [V] [TRT] Tactic: 5548126322150286555 Time: 0.385664
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:03:01] [V] [TRT] Tactic: 6057304366605292508 Time: 0.379136
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:03:01] [V] [TRT] Tactic: -7928611605886347652 Time: 0.37696
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:03:01] [V] [TRT] Tactic: -5172391392092686714 Time: 0.407076
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:03:01] [V] [TRT] Tactic: -4374269919094467161 Time: 0.391424
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:03:01] [V] [TRT] Tactic: -4083394051665370953 Time: 0.173832
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:03:01] [V] [TRT] Tactic: -1546027692247304867 Time: 0.368
[10/24/2023-13:03:01] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.173832
[10/24/2023-13:03:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:03:01] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:03:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:03:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:01] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:03:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:03:01] [V] [TRT] Tactic: 0 Time: 1.09619
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1 Time: 1.68692
[10/24/2023-13:03:01] [V] [TRT] Tactic: 2 Time: 1.96544
[10/24/2023-13:03:01] [V] [TRT] Tactic: 6 Time: 0.41114
[10/24/2023-13:03:01] [V] [TRT] Tactic: 56 Time: 1.09928
[10/24/2023-13:03:01] [V] [TRT] Tactic: 58 Time: 1.97837
[10/24/2023-13:03:01] [V] [TRT] Tactic: 62 Time: 0.41102
[10/24/2023-13:03:01] [V] [TRT] Fastest Tactic: 62 Time: 0.41102
[10/24/2023-13:03:01] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:03:01] [V] [TRT] Tactic: 254850674756030979 Time: 0.109468
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:03:01] [V] [TRT] Tactic: 328038211831149625 Time: 0.106636
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:03:01] [V] [TRT] Tactic: 411553864378931917 Time: 0.1344
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1011057357468998345 Time: 0.115088
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1156328698016730421 Time: 0.108288
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1723736032573714698 Time: 0.128132
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1832046141070096030 Time: 0.110848
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1838082074606840426 Time: 0.112
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:03:01] [V] [TRT] Tactic: 1899296423087490472 Time: 0.118912
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:03:01] [V] [TRT] Tactic: 2428167804343994714 Time: 0.133248
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:03:01] [V] [TRT] Tactic: 2541579301352125276 Time: 0.123136
[10/24/2023-13:03:01] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:03:02] [V] [TRT] Tactic: 2657157263811141609 Time: 0.120592
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:03:02] [V] [TRT] Tactic: 2819719497590964443 Time: 0.124928
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:03:02] [V] [TRT] Tactic: 2968605903460894194 Time: 0.112164
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:03:02] [V] [TRT] Tactic: 2986078304285316765 Time: 0.125876
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:03:02] [V] [TRT] Tactic: 3362537467505018070 Time: 0.106624
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:03:02] [V] [TRT] Tactic: 3513075359009385578 Time: 0.10752
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:03:02] [V] [TRT] Tactic: 3573559043797674382 Time: 0.112128
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:03:02] [V] [TRT] Tactic: 3591970081995419777 Time: 0.15744
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:03:02] [V] [TRT] Tactic: 3704534001553878387 Time: 0.106128
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:03:02] [V] [TRT] Tactic: 4278315135102886928 Time: 0.121368
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:03:02] [V] [TRT] Tactic: 4503233883285355107 Time: 0.180096
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:03:02] [V] [TRT] Tactic: 4802447371470387646 Time: 0.140684
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5059676457552313631 Time: 0.107008
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5368829646735632944 Time: 0.154148
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5398999388616959893 Time: 0.115952
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5746691132547383910 Time: 0.12864
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5770170567977052602 Time: 0.13724
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:03:02] [V] [TRT] Tactic: 5953552212833506549 Time: 0.11174
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6034364043891107501 Time: 0.124672
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6074229447555668232 Time: 0.120576
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6154447660803990543 Time: 0.135436
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6325769668000961702 Time: 0.106496
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6350273239113254096 Time: 0.219648
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6377497238381488891 Time: 0.10652
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6446388116965632819 Time: 0.111616
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6468794451065529747 Time: 0.111888
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6642277870194067185 Time: 0.108672
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6859477213531075460 Time: 0.118016
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6972489290272968208 Time: 0.10688
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:03:02] [V] [TRT] Tactic: 6979044990896381511 Time: 0.106496
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:03:02] [V] [TRT] Tactic: 7216571380637776659 Time: 0.119448
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:03:02] [V] [TRT] Tactic: 7609923741161019135 Time: 0.110204
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:03:02] [V] [TRT] Tactic: 7705739241028240201 Time: 0.122112
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:03:02] [V] [TRT] Tactic: 8072087735545283117 Time: 0.195728
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:03:02] [V] [TRT] Tactic: 8101703987960976805 Time: 0.123008
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:03:02] [V] [TRT] Tactic: 8170606396342855895 Time: 0.111744
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:03:02] [V] [TRT] Tactic: 8839784824303350101 Time: 0.118016
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:03:02] [V] [TRT] Tactic: -9217371357561775773 Time: 0.123168
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:03:02] [V] [TRT] Tactic: -9009272790678027912 Time: 0.145024
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:03:02] [V] [TRT] Tactic: -8985224497679592364 Time: 0.183304
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:03:02] [V] [TRT] Tactic: -8949544755481315679 Time: 0.113536
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:03:02] [V] [TRT] Tactic: -8759929675070720385 Time: 0.107288
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:03:02] [V] [TRT] Tactic: -8604374562669615024 Time: 0.119364
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6902925267326201166 Time: 0.218868
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6840588038605932325 Time: 0.122
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6799856376604253964 Time: 0.191748
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6625722781282978136 Time: 0.172544
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6525498856028268801 Time: 0.114156
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6356316196810535311 Time: 0.124928
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6324345858751792783 Time: 0.174092
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6262400699544994312 Time: 0.191656
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6257787336162086472 Time: 0.108692
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:03:02] [V] [TRT] Tactic: -6063766379489217211 Time: 0.11008
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5777580938094193096 Time: 0.129968
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5657273398217409378 Time: 0.108424
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5530886555766748586 Time: 0.122636
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5422685219138380548 Time: 0.125828
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5161596964442251102 Time: 0.12802
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:03:02] [V] [TRT] Tactic: -5127240325355316006 Time: 0.124408
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4825567853927730435 Time: 0.126976
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4796511246675321840 Time: 0.124288
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4706569565442112734 Time: 0.124696
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4566599693570369588 Time: 0.105776
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4409144516525410768 Time: 0.106524
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4379519430184503304 Time: 0.109824
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4152066959007262150 Time: 0.1065
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:03:02] [V] [TRT] Tactic: -4021926646879732549 Time: 0.121344
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3987638434926559037 Time: 0.124032
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3905653247016903130 Time: 0.118016
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3903974568488493144 Time: 0.129824
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3895429239811098010 Time: 0.12482
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3864869056275745423 Time: 0.132236
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3601464762214218301 Time: 0.117248
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3412636942650049698 Time: 0.118504
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3338665856053412950 Time: 0.112
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:03:02] [V] [TRT] Tactic: -3058330359340425555 Time: 0.128128
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2816084650627734155 Time: 0.145432
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2662892962457732243 Time: 0.128916
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2559894581585337900 Time: 0.108544
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2530740716768816092 Time: 0.186912
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2332828394978346992 Time: 0.107008
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2241736083352441442 Time: 0.118272
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:03:02] [V] [TRT] Tactic: -2161909437867201546 Time: 0.216448
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:03:02] [V] [TRT] Tactic: -1985778916402815946 Time: 0.136336
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:03:02] [V] [TRT] Tactic: -1500496213132463076 Time: 0.113408
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:03:02] [V] [TRT] Tactic: -1099247066487349374 Time: 0.11904
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:03:02] [V] [TRT] Tactic: -910286698936744682 Time: 0.158632
[10/24/2023-13:03:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:03:03] [V] [TRT] Tactic: -606726295133751039 Time: 0.183168
[10/24/2023-13:03:03] [V] [TRT] Fastest Tactic: -4566599693570369588 Time: 0.105776
[10/24/2023-13:03:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4566599693570369588
[10/24/2023-13:03:03] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:03] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CudnnConvolution)
[10/24/2023-13:03:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:03] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (CaskConvolution)
[10/24/2023-13:03:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:03] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:03] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:03] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:03:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:03] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (FusedConvActConvolution)
[10/24/2023-13:03:03] [V] [TRT] Tactic: 524287 Time: 0.28416
[10/24/2023-13:03:03] [V] [TRT] Tactic: 720895 Time: 0.251136
[10/24/2023-13:03:03] [V] [TRT] Tactic: 983039 Time: 0.245152
[10/24/2023-13:03:03] [V] [TRT] Tactic: 1048575 Time: 0.256004
[10/24/2023-13:03:03] [V] [TRT] Tactic: 1703935 Time: 0.245656
[10/24/2023-13:03:03] [V] [TRT] Tactic: 1769471 Time: 0.301956
[10/24/2023-13:03:03] [V] [TRT] Tactic: 1966079 Time: 0.325632
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2031615 Time: 0.316676
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2228223 Time: 0.278016
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2424831 Time: 0.325504
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2621439 Time: 0.262656
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2752511 Time: 0.264832
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2818047 Time: 0.294188
[10/24/2023-13:03:03] [V] [TRT] Tactic: 2883583 Time: 0.310016
[10/24/2023-13:03:03] [V] [TRT] Tactic: 3014655 Time: 0.247936
[10/24/2023-13:03:03] [V] [TRT] Tactic: 3145727 Time: 0.251796
[10/24/2023-13:03:03] [V] [TRT] Tactic: 3473407 Time: 0.27266
[10/24/2023-13:03:03] [V] [TRT] Tactic: 3604479 Time: 0.257152
[10/24/2023-13:03:03] [V] [TRT] Tactic: 3735551 Time: 0.280064
[10/24/2023-13:03:03] [V] [TRT] Tactic: 4390911 Time: 0.280064
[10/24/2023-13:03:03] [V] [TRT] Tactic: 5046271 Time: 0.262912
[10/24/2023-13:03:03] [V] [TRT] Tactic: 5963775 Time: 0.278144
[10/24/2023-13:03:03] [V] [TRT] Tactic: 6160383 Time: 0.296192
[10/24/2023-13:03:03] [V] [TRT] Tactic: 6488063 Time: 0.258952
[10/24/2023-13:03:03] [V] [TRT] Tactic: 6881279 Time: 0.295808
[10/24/2023-13:03:03] [V] [TRT] Tactic: 7274495 Time: 0.30336
[10/24/2023-13:03:03] [V] [TRT] Tactic: 7864319 Time: 0.274688
[10/24/2023-13:03:04] [V] [TRT] Tactic: 7995391 Time: 0.273692
[10/24/2023-13:03:04] [V] [TRT] Tactic: 8585215 Time: 0.272128
[10/24/2023-13:03:04] [V] [TRT] Tactic: 8847359 Time: 0.331032
[10/24/2023-13:03:04] [V] [TRT] Tactic: 8978431 Time: 0.272256
[10/24/2023-13:03:04] [V] [TRT] Tactic: 9043967 Time: 0.250112
[10/24/2023-13:03:04] [V] [TRT] Tactic: 9175039 Time: 0.257552
[10/24/2023-13:03:04] [V] [TRT] Tactic: 9502719 Time: 0.269724
[10/24/2023-13:03:04] [V] [TRT] Tactic: 9830399 Time: 0.28546
[10/24/2023-13:03:04] [V] [TRT] Tactic: 9961471 Time: 0.328448
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10027007 Time: 0.2537
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10092543 Time: 0.280192
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10289151 Time: 0.325632
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10485759 Time: 0.245504
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10682367 Time: 0.258432
[10/24/2023-13:03:04] [V] [TRT] Tactic: 10813439 Time: 0.252288
[10/24/2023-13:03:04] [V] [TRT] Fastest Tactic: 983039 Time: 0.245152
[10/24/2023-13:03:04] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:04] [V] [TRT] Tactic: 0 Time: 0.512788
[10/24/2023-13:03:04] [V] [TRT] Tactic: 1 Time: 0.207232
[10/24/2023-13:03:04] [V] [TRT] Tactic: 2 Time: 0.584984
[10/24/2023-13:03:04] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8725266432, available: 4294967296
[10/24/2023-13:03:04] [V] [TRT] Tactic: 5 Time: 3.6974
[10/24/2023-13:03:04] [V] [TRT] Tactic: 6 Time: 0.230568
[10/24/2023-13:03:04] [V] [TRT] Tactic: 56 Time: 0.510208
[10/24/2023-13:03:04] [V] [TRT] Tactic: 57 Time: 0.207488
[10/24/2023-13:03:04] [V] [TRT] Tactic: 58 Time: 0.585728
[10/24/2023-13:03:04] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8725266432, available: 4294967296
[10/24/2023-13:03:04] [V] [TRT] Tactic: 61 Time: 3.69979
[10/24/2023-13:03:04] [V] [TRT] Tactic: 62 Time: 0.230784
[10/24/2023-13:03:04] [V] [TRT] Tactic: 112 Time: 0.511232
[10/24/2023-13:03:04] [V] [TRT] Tactic: 113 Time: 0.399476
[10/24/2023-13:03:04] [V] [TRT] Tactic: 114 Time: 0.584576
[10/24/2023-13:03:04] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8725266432, available: 4294967296
[10/24/2023-13:03:04] [V] [TRT] Tactic: 117 Time: 3.70164
[10/24/2023-13:03:04] [V] [TRT] Tactic: 118 Time: 0.230528
[10/24/2023-13:03:04] [V] [TRT] Fastest Tactic: 1 Time: 0.207232
[10/24/2023-13:03:04] [V] [TRT] Setting workspace to 8725266432enables more tactics for profiling
[10/24/2023-13:03:04] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:04] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:03:04] [V] [TRT] Tactic: 4549827808004681195 Time: 0.3291
[10/24/2023-13:03:04] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:03:05] [V] [TRT] Tactic: 5779835512569528575 Time: 0.282368
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:03:05] [V] [TRT] Tactic: 6053873026024413720 Time: 0.292224
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:03:05] [V] [TRT] Tactic: 6767548733843469815 Time: 0.332288
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:03:05] [V] [TRT] Tactic: -6313876406580483184 Time: 0.379904
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:03:05] [V] [TRT] Tactic: -1123676555321336786 Time: 0.284176
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:03:05] [V] [TRT] Tactic: -701551393537224327 Time: 0.337152
[10/24/2023-13:03:05] [V] [TRT] Fastest Tactic: 5779835512569528575 Time: 0.282368
[10/24/2023-13:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:03:05] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:03:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:03:05] [V] [TRT] Tactic: 2086609538387166260 Time: 0.377224
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:03:05] [V] [TRT] Tactic: 2860655430572478466 Time: 0.315904
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:03:05] [V] [TRT] Tactic: 3239733199291090177 Time: 0.376192
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4474630279712975759 Time: 0.297228
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4479823862704990365 Time: 0.294912
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4517590677127196184 Time: 0.574472
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4634080872644479428 Time: 0.377472
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4696204239951173149 Time: 0.31734
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:03:05] [V] [TRT] Tactic: 5778138195697110003 Time: 0.292096
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:03:05] [V] [TRT] Tactic: 6310198979346901507 Time: 0.3648
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7155825427510256858 Time: 0.28004
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7222247112373541608 Time: 0.47104
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7472640475524677095 Time: 0.385556
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:03:05] [V] [TRT] Tactic: 8498373915030836990 Time: 0.623488
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:03:05] [V] [TRT] Tactic: 8869697132622550639 Time: 0.559632
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:03:05] [V] [TRT] Tactic: 8918020581761223752 Time: 0.276992
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:03:05] [V] [TRT] Tactic: -8937725997228636978 Time: 0.334228
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:03:05] [V] [TRT] Tactic: -8833858409138163072 Time: 0.581272
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:03:05] [V] [TRT] Tactic: -7989138351613022500 Time: 0.466304
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:03:05] [V] [TRT] Tactic: -7872883691240863058 Time: 0.381568
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:03:05] [V] [TRT] Tactic: -6729618519651721910 Time: 0.38208
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:03:05] [V] [TRT] Tactic: -5893833996418445881 Time: 0.548736
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:03:05] [V] [TRT] Tactic: -5701562095007058349 Time: 0.584832
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:03:05] [V] [TRT] Tactic: -5685503422376017600 Time: 0.46602
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:03:05] [V] [TRT] Tactic: -5521125187060117489 Time: 0.47194
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:03:05] [V] [TRT] Tactic: -4756382386362004279 Time: 0.313344
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:03:05] [V] [TRT] Tactic: -4615000974950361663 Time: 0.46618
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:03:05] [V] [TRT] Tactic: -4314913710375142296 Time: 0.5033
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:03:05] [V] [TRT] Tactic: -3855385237722507464 Time: 0.293888
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:03:05] [V] [TRT] Tactic: -3697587361057948972 Time: 0.466048
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:03:05] [V] [TRT] Tactic: -2809379259463049391 Time: 0.292888
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:03:05] [V] [TRT] Tactic: -2747929399988666512 Time: 0.569984
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:03:05] [V] [TRT] Tactic: -1472061967969061456 Time: 0.60352
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:03:05] [V] [TRT] Tactic: -504296718212024303 Time: 0.278036
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:03:05] [V] [TRT] Tactic: -444093195553988951 Time: 0.375076
[10/24/2023-13:03:05] [V] [TRT] Fastest Tactic: 8918020581761223752 Time: 0.276992
[10/24/2023-13:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8918020581761223752
[10/24/2023-13:03:05] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:03:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:03:05] [V] [TRT] Tactic: 2086609538387166260 Time: 0.376852
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:03:05] [V] [TRT] Tactic: 2860655430572478466 Time: 0.316544
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:03:05] [V] [TRT] Tactic: 3239733199291090177 Time: 0.376064
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4474630279712975759 Time: 0.29734
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4479823862704990365 Time: 0.294912
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4517590677127196184 Time: 0.573956
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4634080872644479428 Time: 0.377472
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:03:05] [V] [TRT] Tactic: 4696204239951173149 Time: 0.317696
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:03:05] [V] [TRT] Tactic: 5778138195697110003 Time: 0.292352
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:03:05] [V] [TRT] Tactic: 6310198979346901507 Time: 0.365304
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7155825427510256858 Time: 0.280192
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7222247112373541608 Time: 0.468224
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7342025736444949634 Time: 0.128276
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:03:05] [V] [TRT] Tactic: 7472640475524677095 Time: 0.386048
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:03:05] [V] [TRT] Tactic: 8498373915030836990 Time: 0.623364
[10/24/2023-13:03:05] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:03:06] [V] [TRT] Tactic: 8869697132622550639 Time: 0.559488
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:03:06] [V] [TRT] Tactic: 8918020581761223752 Time: 0.276992
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:03:06] [V] [TRT] Tactic: -8937725997228636978 Time: 0.333952
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:03:06] [V] [TRT] Tactic: -8833858409138163072 Time: 0.581624
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:03:06] [V] [TRT] Tactic: -7989138351613022500 Time: 0.46616
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:03:06] [V] [TRT] Tactic: -7872883691240863058 Time: 0.38122
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:03:06] [V] [TRT] Tactic: -7377458734869418330 Time: 0.120188
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:03:06] [V] [TRT] Tactic: -6729618519651721910 Time: 0.382336
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:03:06] [V] [TRT] Tactic: -5893833996418445881 Time: 0.548992
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:03:06] [V] [TRT] Tactic: -5701562095007058349 Time: 0.584576
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:03:06] [V] [TRT] Tactic: -5685503422376017600 Time: 0.46556
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:03:06] [V] [TRT] Tactic: -5521125187060117489 Time: 0.472064
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:03:06] [V] [TRT] Tactic: -5457304872213719461 Time: 0.119448
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:03:06] [V] [TRT] Tactic: -4756382386362004279 Time: 0.313448
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:03:06] [V] [TRT] Tactic: -4615000974950361663 Time: 0.466228
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:03:06] [V] [TRT] Tactic: -4314913710375142296 Time: 0.503148
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:03:06] [V] [TRT] Tactic: -3855385237722507464 Time: 0.293892
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:03:06] [V] [TRT] Tactic: -3697587361057948972 Time: 0.46554
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:03:06] [V] [TRT] Tactic: -2809379259463049391 Time: 0.292744
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:03:06] [V] [TRT] Tactic: -2747929399988666512 Time: 0.566652
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:03:06] [V] [TRT] Tactic: -1472061967969061456 Time: 0.603012
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:03:06] [V] [TRT] Tactic: -504296718212024303 Time: 0.278248
[10/24/2023-13:03:06] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:03:06] [V] [TRT] Tactic: -444093195553988951 Time: 0.37478
[10/24/2023-13:03:06] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.119448
[10/24/2023-13:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:03:06] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:03:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:06] [V] [TRT] Tactic: 0 Time: 0.506516
[10/24/2023-13:03:06] [V] [TRT] Tactic: 1 Time: 0.451584
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2 Time: 0.463884
[10/24/2023-13:03:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8725266432, available: 4294967296
[10/24/2023-13:03:06] [V] [TRT] Tactic: 5 Time: 3.65064
[10/24/2023-13:03:06] [V] [TRT] Tactic: 6 Time: 0.241152
[10/24/2023-13:03:06] [V] [TRT] Tactic: 56 Time: 0.505596
[10/24/2023-13:03:06] [V] [TRT] Tactic: 58 Time: 0.46314
[10/24/2023-13:03:06] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8725266432, available: 4294967296
[10/24/2023-13:03:06] [V] [TRT] Tactic: 61 Time: 3.64416
[10/24/2023-13:03:06] [V] [TRT] Tactic: 62 Time: 0.241392
[10/24/2023-13:03:06] [V] [TRT] Fastest Tactic: 6 Time: 0.241152
[10/24/2023-13:03:06] [V] [TRT] Setting workspace to 8725266432enables more tactics for profiling
[10/24/2023-13:03:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[10/24/2023-13:03:06] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:03:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (FusedConvActConvolution)
[10/24/2023-13:03:06] [V] [TRT] Tactic: 524287 Time: 0.191756
[10/24/2023-13:03:06] [V] [TRT] Tactic: 720895 Time: 0.175092
[10/24/2023-13:03:06] [V] [TRT] Tactic: 983039 Time: 0.169216
[10/24/2023-13:03:06] [V] [TRT] Tactic: 1048575 Time: 0.172304
[10/24/2023-13:03:06] [V] [TRT] Tactic: 1703935 Time: 0.166916
[10/24/2023-13:03:06] [V] [TRT] Tactic: 1769471 Time: 0.210588
[10/24/2023-13:03:06] [V] [TRT] Tactic: 1966079 Time: 0.217612
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2031615 Time: 0.206104
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2228223 Time: 0.179344
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2424831 Time: 0.215032
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2621439 Time: 0.175376
[10/24/2023-13:03:06] [V] [TRT] Tactic: 2752511 Time: 0.178572
[10/24/2023-13:03:07] [V] [TRT] Tactic: 2818047 Time: 0.179428
[10/24/2023-13:03:07] [V] [TRT] Tactic: 2883583 Time: 0.21148
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3014655 Time: 0.171136
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3145727 Time: 0.172928
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3473407 Time: 0.171664
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3604479 Time: 0.174092
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3735551 Time: 0.17654
[10/24/2023-13:03:07] [V] [TRT] Tactic: 4390911 Time: 0.190696
[10/24/2023-13:03:07] [V] [TRT] Tactic: 5046271 Time: 0.178804
[10/24/2023-13:03:07] [V] [TRT] Tactic: 5963775 Time: 0.196492
[10/24/2023-13:03:07] [V] [TRT] Tactic: 6160383 Time: 0.195332
[10/24/2023-13:03:07] [V] [TRT] Tactic: 6488063 Time: 0.190328
[10/24/2023-13:03:07] [V] [TRT] Tactic: 6881279 Time: 0.186592
[10/24/2023-13:03:07] [V] [TRT] Tactic: 7274495 Time: 0.190848
[10/24/2023-13:03:07] [V] [TRT] Tactic: 7864319 Time: 0.188672
[10/24/2023-13:03:07] [V] [TRT] Tactic: 7995391 Time: 0.19074
[10/24/2023-13:03:07] [V] [TRT] Tactic: 8585215 Time: 0.181144
[10/24/2023-13:03:07] [V] [TRT] Tactic: 8847359 Time: 0.187264
[10/24/2023-13:03:07] [V] [TRT] Tactic: 8978431 Time: 0.196076
[10/24/2023-13:03:07] [V] [TRT] Tactic: 9043967 Time: 0.178048
[10/24/2023-13:03:07] [V] [TRT] Tactic: 9175039 Time: 0.17408
[10/24/2023-13:03:07] [V] [TRT] Tactic: 9502719 Time: 0.189656
[10/24/2023-13:03:07] [V] [TRT] Tactic: 9830399 Time: 0.188416
[10/24/2023-13:03:07] [V] [TRT] Tactic: 9961471 Time: 0.216468
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10027007 Time: 0.17728
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10092543 Time: 0.190752
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10289151 Time: 0.217728
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10485759 Time: 0.172452
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10682367 Time: 0.181376
[10/24/2023-13:03:07] [V] [TRT] Tactic: 10813439 Time: 0.173952
[10/24/2023-13:03:07] [V] [TRT] Fastest Tactic: 1703935 Time: 0.166916
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:07] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:03:07] [V] [TRT] Tactic: 2195670545862694453 Time: 0.205328
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3419182076704469245 Time: 0.20032
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:03:07] [V] [TRT] Tactic: 3891805945559659536 Time: 0.191872
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:03:07] [V] [TRT] Tactic: 5548126322150286555 Time: 0.198656
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:03:07] [V] [TRT] Tactic: 6057304366605292508 Time: 0.194852
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:03:07] [V] [TRT] Tactic: -7928611605886347652 Time: 0.19584
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:03:07] [V] [TRT] Tactic: -5172391392092686714 Time: 0.208544
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:03:07] [V] [TRT] Tactic: -4374269919094467161 Time: 0.201088
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:03:07] [V] [TRT] Tactic: -4083394051665370953 Time: 0.094212
[10/24/2023-13:03:07] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:03:07] [V] [TRT] Tactic: -1546027692247304867 Time: 0.190976
[10/24/2023-13:03:07] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.094212
[10/24/2023-13:03:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:03:07] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:07] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:07] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:07] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:03:07] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:07] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:07] [V] [TRT] Tactic: 0 Time: 0.565632
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1 Time: 0.895256
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2 Time: 0.566528
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6 Time: 0.243948
[10/24/2023-13:03:08] [V] [TRT] Tactic: 56 Time: 0.563712
[10/24/2023-13:03:08] [V] [TRT] Tactic: 58 Time: 0.566276
[10/24/2023-13:03:08] [V] [TRT] Tactic: 62 Time: 0.244992
[10/24/2023-13:03:08] [V] [TRT] Fastest Tactic: 6 Time: 0.243948
[10/24/2023-13:03:08] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:03:08] [V] [TRT] Tactic: 254850674756030979 Time: 0.061708
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:03:08] [V] [TRT] Tactic: 328038211831149625 Time: 0.0594
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:03:08] [V] [TRT] Tactic: 411553864378931917 Time: 0.074112
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1011057357468998345 Time: 0.065792
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1156328698016730421 Time: 0.0608
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1723736032573714698 Time: 0.068884
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1832046141070096030 Time: 0.06528
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1838082074606840426 Time: 0.065664
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:03:08] [V] [TRT] Tactic: 1899296423087490472 Time: 0.071712
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2428167804343994714 Time: 0.07296
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2541579301352125276 Time: 0.071184
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2657157263811141609 Time: 0.07296
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2819719497590964443 Time: 0.072228
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2968605903460894194 Time: 0.065828
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:03:08] [V] [TRT] Tactic: 2986078304285316765 Time: 0.07232
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:03:08] [V] [TRT] Tactic: 3362537467505018070 Time: 0.062848
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:03:08] [V] [TRT] Tactic: 3513075359009385578 Time: 0.061324
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:03:08] [V] [TRT] Tactic: 3573559043797674382 Time: 0.066208
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:03:08] [V] [TRT] Tactic: 3591970081995419777 Time: 0.087936
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:03:08] [V] [TRT] Tactic: 3704534001553878387 Time: 0.059652
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:03:08] [V] [TRT] Tactic: 4278315135102886928 Time: 0.068796
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:03:08] [V] [TRT] Tactic: 4503233883285355107 Time: 0.092436
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:03:08] [V] [TRT] Tactic: 4802447371470387646 Time: 0.078364
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5059676457552313631 Time: 0.060936
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5368829646735632944 Time: 0.085248
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5398999388616959893 Time: 0.066688
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5746691132547383910 Time: 0.0717
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5770170567977052602 Time: 0.077952
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:03:08] [V] [TRT] Tactic: 5953552212833506549 Time: 0.064404
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6034364043891107501 Time: 0.068484
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6074229447555668232 Time: 0.071424
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6154447660803990543 Time: 0.074904
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6325769668000961702 Time: 0.061312
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6350273239113254096 Time: 0.123904
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6377497238381488891 Time: 0.062468
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6446388116965632819 Time: 0.064904
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6468794451065529747 Time: 0.066688
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6642277870194067185 Time: 0.061568
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6859477213531075460 Time: 0.06978
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6972489290272968208 Time: 0.061312
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:03:08] [V] [TRT] Tactic: 6979044990896381511 Time: 0.059392
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:03:08] [V] [TRT] Tactic: 7216571380637776659 Time: 0.063872
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:03:08] [V] [TRT] Tactic: 7609923741161019135 Time: 0.063888
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:03:08] [V] [TRT] Tactic: 7705739241028240201 Time: 0.072704
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:03:08] [V] [TRT] Tactic: 8072087735545283117 Time: 0.1065
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:03:08] [V] [TRT] Tactic: 8101703987960976805 Time: 0.074496
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:03:08] [V] [TRT] Tactic: 8170606396342855895 Time: 0.06658
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:03:08] [V] [TRT] Tactic: 8839784824303350101 Time: 0.062208
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:03:08] [V] [TRT] Tactic: -9217371357561775773 Time: 0.075264
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:03:08] [V] [TRT] Tactic: -9009272790678027912 Time: 0.08128
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:03:08] [V] [TRT] Tactic: -8985224497679592364 Time: 0.094976
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:03:08] [V] [TRT] Tactic: -8949544755481315679 Time: 0.066844
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:03:08] [V] [TRT] Tactic: -8759929675070720385 Time: 0.062336
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:03:08] [V] [TRT] Tactic: -8604374562669615024 Time: 0.071188
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6902925267326201166 Time: 0.123392
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6840588038605932325 Time: 0.069248
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6799856376604253964 Time: 0.104448
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6625722781282978136 Time: 0.0928
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6525498856028268801 Time: 0.065292
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6356316196810535311 Time: 0.075904
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6324345858751792783 Time: 0.093952
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6262400699544994312 Time: 0.104576
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6257787336162086472 Time: 0.061056
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:03:08] [V] [TRT] Tactic: -6063766379489217211 Time: 0.06464
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5777580938094193096 Time: 0.07008
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5657273398217409378 Time: 0.060032
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5530886555766748586 Time: 0.070784
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5422685219138380548 Time: 0.06912
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5161596964442251102 Time: 0.07104
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:03:08] [V] [TRT] Tactic: -5127240325355316006 Time: 0.068236
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4825567853927730435 Time: 0.069892
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4796511246675321840 Time: 0.071936
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4706569565442112734 Time: 0.075944
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4566599693570369588 Time: 0.061312
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4409144516525410768 Time: 0.06272
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4379519430184503304 Time: 0.063756
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4152066959007262150 Time: 0.06016
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:03:08] [V] [TRT] Tactic: -4021926646879732549 Time: 0.068752
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3987638434926559037 Time: 0.07168
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3905653247016903130 Time: 0.06784
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3903974568488493144 Time: 0.071936
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3895429239811098010 Time: 0.068376
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3864869056275745423 Time: 0.075152
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3601464762214218301 Time: 0.068872
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3412636942650049698 Time: 0.067848
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3338665856053412950 Time: 0.064128
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:03:08] [V] [TRT] Tactic: -3058330359340425555 Time: 0.070928
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2816084650627734155 Time: 0.08
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2662892962457732243 Time: 0.069772
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2559894581585337900 Time: 0.061696
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2530740716768816092 Time: 0.100748
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2332828394978346992 Time: 0.061324
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2241736083352441442 Time: 0.064
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:03:08] [V] [TRT] Tactic: -2161909437867201546 Time: 0.119448
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:03:08] [V] [TRT] Tactic: -1985778916402815946 Time: 0.077568
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:03:08] [V] [TRT] Tactic: -1500496213132463076 Time: 0.067712
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:03:08] [V] [TRT] Tactic: -1099247066487349374 Time: 0.070528
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:03:08] [V] [TRT] Tactic: -910286698936744682 Time: 0.089088
[10/24/2023-13:03:08] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:03:09] [V] [TRT] Tactic: -606726295133751039 Time: 0.095616
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 6979044990896381511 Time: 0.059392
[10/24/2023-13:03:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6979044990896381511
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CudnnConvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu (CaskConvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(2097152,1,16384,128) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(524288,1:4,4096,32) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(1048576,16384:2,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(2097152,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(262144,1:8,2048,16) ***************
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(131072,1:16,1024,8) ***************
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.15424
[10/24/2023-13:03:09] [V] [TRT] Tactic: 1 Time: 0.096512
[10/24/2023-13:03:09] [V] [TRT] Tactic: 3 Time: 0.227464
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 1 Time: 0.096512
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.209536
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.209536
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnDeconvolution Tactic: 1
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.276096
[10/24/2023-13:03:09] [V] [TRT] Tactic: 1 Time: 0.082824
[10/24/2023-13:03:09] [V] [TRT] Tactic: 3 Time: 0.214372
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 1 Time: 0.082824
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.10626
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.10626
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnDeconvolution Tactic: 1
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.07824
[10/24/2023-13:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.07824
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:03:09] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:03:09] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:03:09] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1), Float(256,1,1,1), Float(256,1,1,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:03:09] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:09] [V] [TRT] Tactic: 0 Time: 0.062344
[10/24/2023-13:03:09] [V] [TRT] Tactic: 1 Time: 0.06606
[10/24/2023-13:03:09] [V] [TRT] Tactic: 2 Time: 0.065536
[10/24/2023-13:03:10] [V] [TRT] Tactic: 3 Time: 0.067584
[10/24/2023-13:03:10] [V] [TRT] Tactic: 4 Time: 0.065432
[10/24/2023-13:03:10] [V] [TRT] Tactic: 5 Time: 0.065312
[10/24/2023-13:03:10] [V] [TRT] Tactic: 6 Time: 0.067584
[10/24/2023-13:03:11] [V] [TRT] Tactic: 7 Time: 0.06528
[10/24/2023-13:03:11] [V] [TRT] Tactic: 8 Time: 0.064656
[10/24/2023-13:03:11] [V] [TRT] Tactic: 9 Time: 0.065044
[10/24/2023-13:03:11] [V] [TRT] Tactic: 28 Time: 0.062068
[10/24/2023-13:03:11] [V] [TRT] Fastest Tactic: 28 Time: 0.062068
[10/24/2023-13:03:11] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:11] [V] [TRT] Tactic: 128 Time: 0.130596
[10/24/2023-13:03:11] [V] [TRT] Tactic: 256 Time: 0.131484
[10/24/2023-13:03:11] [V] [TRT] Tactic: 512 Time: 0.136468
[10/24/2023-13:03:11] [V] [TRT] Tactic: -32 Time: 0.26332
[10/24/2023-13:03:11] [V] [TRT] Tactic: -64 Time: 0.155416
[10/24/2023-13:03:11] [V] [TRT] Tactic: -128 Time: 0.14016
[10/24/2023-13:03:11] [V] [TRT] Fastest Tactic: 128 Time: 0.130596
[10/24/2023-13:03:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[10/24/2023-13:03:11] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256), Float(256,1,256,256), Float(256,1,256,256) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:03:11] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:12] [V] [TRT] Tactic: 0 Time: 0.064256
[10/24/2023-13:03:12] [V] [TRT] Tactic: 1 Time: 0.066188
[10/24/2023-13:03:12] [V] [TRT] Tactic: 2 Time: 0.064524
[10/24/2023-13:03:12] [V] [TRT] Tactic: 3 Time: 0.067584
[10/24/2023-13:03:13] [V] [TRT] Tactic: 4 Time: 0.065424
[10/24/2023-13:03:13] [V] [TRT] Tactic: 5 Time: 0.06464
[10/24/2023-13:03:13] [V] [TRT] Tactic: 6 Time: 0.070676
[10/24/2023-13:03:13] [V] [TRT] Tactic: 7 Time: 0.067072
[10/24/2023-13:03:14] [V] [TRT] Tactic: 8 Time: 0.066432
[10/24/2023-13:03:14] [V] [TRT] Tactic: 9 Time: 0.066048
[10/24/2023-13:03:14] [V] [TRT] Tactic: 28 Time: 0.063616
[10/24/2023-13:03:14] [V] [TRT] Fastest Tactic: 28 Time: 0.063616
[10/24/2023-13:03:14] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:14] [V] [TRT] Tactic: 128 Time: 0.13632
[10/24/2023-13:03:14] [V] [TRT] Tactic: 256 Time: 0.137344
[10/24/2023-13:03:14] [V] [TRT] Tactic: 512 Time: 0.14144
[10/24/2023-13:03:14] [V] [TRT] Tactic: -32 Time: 0.225836
[10/24/2023-13:03:14] [V] [TRT] Tactic: -64 Time: 0.145696
[10/24/2023-13:03:14] [V] [TRT] Tactic: -128 Time: 0.146304
[10/24/2023-13:03:14] [V] [TRT] Fastest Tactic: 128 Time: 0.13632
[10/24/2023-13:03:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 28
[10/24/2023-13:03:14] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64), Float(64,1:4,64,64), Float(64,1:4,64,64) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:03:14] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:14] [V] [TRT] Tactic: 0 Time: 0.163584
[10/24/2023-13:03:15] [V] [TRT] Tactic: 1 Time: 0.1536
[10/24/2023-13:03:15] [V] [TRT] Tactic: 2 Time: 0.182676
[10/24/2023-13:03:15] [V] [TRT] Tactic: 3 Time: 0.154496
[10/24/2023-13:03:15] [V] [TRT] Tactic: 4 Time: 0.17088
[10/24/2023-13:03:16] [V] [TRT] Tactic: 5 Time: 0.17052
[10/24/2023-13:03:16] [V] [TRT] Tactic: 6 Time: 0.154644
[10/24/2023-13:03:16] [V] [TRT] Tactic: 7 Time: 0.170624
[10/24/2023-13:03:17] [V] [TRT] Tactic: 8 Time: 0.156928
[10/24/2023-13:03:17] [V] [TRT] Tactic: 9 Time: 0.14554
[10/24/2023-13:03:17] [V] [TRT] Tactic: 10 Time: 0.12416
[10/24/2023-13:03:17] [V] [TRT] Tactic: 11 Time: 0.117652
[10/24/2023-13:03:18] [V] [TRT] Tactic: 12 Time: 0.165632
[10/24/2023-13:03:18] [V] [TRT] Tactic: 13 Time: 0.11392
[10/24/2023-13:03:18] [V] [TRT] Tactic: 14 Time: 0.157184
[10/24/2023-13:03:18] [V] [TRT] Tactic: 15 Time: 0.17626
[10/24/2023-13:03:19] [V] [TRT] Tactic: 16 Time: 0.114048
[10/24/2023-13:03:19] [V] [TRT] Tactic: 17 Time: 0.157056
[10/24/2023-13:03:19] [V] [TRT] Tactic: 18 Time: 0.168192
[10/24/2023-13:03:20] [V] [TRT] Tactic: 19 Time: 0.167696
[10/24/2023-13:03:20] [V] [TRT] Tactic: 20 Time: 0.065792
[10/24/2023-13:03:20] [V] [TRT] Tactic: 21 Time: 0.065308
[10/24/2023-13:03:20] [V] [TRT] Tactic: 22 Time: 0.067456
[10/24/2023-13:03:21] [V] [TRT] Tactic: 23 Time: 0.070284
[10/24/2023-13:03:21] [V] [TRT] Tactic: 28 Time: 0.163852
[10/24/2023-13:03:21] [V] [TRT] Tactic: 29 Time: 0.123648
[10/24/2023-13:03:21] [V] [TRT] Tactic: 30 Time: 0.065312
[10/24/2023-13:03:21] [V] [TRT] Fastest Tactic: 21 Time: 0.065308
[10/24/2023-13:03:21] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:21] [V] [TRT] Tactic: 128 Time: 0.135592
[10/24/2023-13:03:21] [V] [TRT] Tactic: 256 Time: 0.136488
[10/24/2023-13:03:21] [V] [TRT] Tactic: 512 Time: 0.1407
[10/24/2023-13:03:21] [V] [TRT] Tactic: -32 Time: 0.225504
[10/24/2023-13:03:21] [V] [TRT] Tactic: -64 Time: 0.145424
[10/24/2023-13:03:21] [V] [TRT] Tactic: -128 Time: 0.145664
[10/24/2023-13:03:21] [V] [TRT] Fastest Tactic: 128 Time: 0.135592
[10/24/2023-13:03:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 21
[10/24/2023-13:03:21] [V] [TRT] *************** Autotuning format combination: Float(131072,16384:32,128,1), Float(8,1:32,1,1), Float(8,1:32,1,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:03:21] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:22] [V] [TRT] Tactic: 24 Time: 0.16322
[10/24/2023-13:03:22] [V] [TRT] Tactic: 25 Time: 0.150268
[10/24/2023-13:03:22] [V] [TRT] Tactic: 26 Time: 0.14274
[10/24/2023-13:03:22] [V] [TRT] Tactic: 27 Time: 0.1376
[10/24/2023-13:03:23] [V] [TRT] Tactic: 31 Time: 0.163564
[10/24/2023-13:03:23] [V] [TRT] Fastest Tactic: 27 Time: 0.1376
[10/24/2023-13:03:23] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:23] [V] [TRT] Tactic: 128 Time: 0.135552
[10/24/2023-13:03:23] [V] [TRT] Tactic: 256 Time: 0.136448
[10/24/2023-13:03:23] [V] [TRT] Tactic: 512 Time: 0.140684
[10/24/2023-13:03:23] [V] [TRT] Tactic: -32 Time: 0.26292
[10/24/2023-13:03:23] [V] [TRT] Tactic: -64 Time: 0.261088
[10/24/2023-13:03:23] [V] [TRT] Tactic: -128 Time: 0.264328
[10/24/2023-13:03:23] [V] [TRT] Fastest Tactic: 128 Time: 0.135552
[10/24/2023-13:03:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWise Tactic: 128
[10/24/2023-13:03:23] [V] [TRT] *************** Autotuning format combination: Float(1:4,16384,128,1), Float(1:4,1,1,1), Float(1:4,1,1,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:03:23] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:23] [V] [TRT] Tactic: 0 Time: 9.87675
[10/24/2023-13:03:24] [V] [TRT] Tactic: 1 Time: 10.0408
[10/24/2023-13:03:24] [V] [TRT] Tactic: 2 Time: 9.95637
[10/24/2023-13:03:25] [V] [TRT] Tactic: 3 Time: 10.1599
[10/24/2023-13:03:25] [V] [TRT] Tactic: 4 Time: 5.32518
[10/24/2023-13:03:25] [V] [TRT] Tactic: 5 Time: 4.78733
[10/24/2023-13:03:26] [V] [TRT] Tactic: 6 Time: 10.3526
[10/24/2023-13:03:26] [V] [TRT] Tactic: 7 Time: 6.02216
[10/24/2023-13:03:27] [V] [TRT] Tactic: 8 Time: 6.99125
[10/24/2023-13:03:27] [V] [TRT] Tactic: 9 Time: 7.424
[10/24/2023-13:03:27] [V] [TRT] Tactic: 10 Time: 2.51392
[10/24/2023-13:03:28] [V] [TRT] Tactic: 11 Time: 2.86914
[10/24/2023-13:03:28] [V] [TRT] Tactic: 12 Time: 2.6299
[10/24/2023-13:03:28] [V] [TRT] Tactic: 13 Time: 3.25926
[10/24/2023-13:03:29] [V] [TRT] Tactic: 14 Time: 3.71635
[10/24/2023-13:03:29] [V] [TRT] Tactic: 15 Time: 2.7369
[10/24/2023-13:03:29] [V] [TRT] Tactic: 16 Time: 4.05365
[10/24/2023-13:03:30] [V] [TRT] Tactic: 17 Time: 4.51866
[10/24/2023-13:03:30] [V] [TRT] Tactic: 18 Time: 4.69261
[10/24/2023-13:03:31] [V] [TRT] Tactic: 19 Time: 3.51578
[10/24/2023-13:03:31] [V] [TRT] Tactic: 20 Time: 1.96098
[10/24/2023-13:03:31] [V] [TRT] Tactic: 21 Time: 2.33921
[10/24/2023-13:03:31] [V] [TRT] Tactic: 22 Time: 2.75443
[10/24/2023-13:03:32] [V] [TRT] Tactic: 23 Time: 3.61075
[10/24/2023-13:03:32] [V] [TRT] Tactic: 28 Time: 0.643216
[10/24/2023-13:03:32] [V] [TRT] Tactic: 29 Time: 0.48154
[10/24/2023-13:03:33] [V] [TRT] Tactic: 30 Time: 0.252928
[10/24/2023-13:03:33] [V] [TRT] Fastest Tactic: 30 Time: 0.252928
[10/24/2023-13:03:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 30
[10/24/2023-13:03:33] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1), Half(256,1,1,1), Half(256,1,1,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:03:33] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:33] [V] [TRT] Tactic: 0 Time: 0.05326
[10/24/2023-13:03:33] [V] [TRT] Tactic: 1 Time: 0.04288
[10/24/2023-13:03:33] [V] [TRT] Tactic: 2 Time: 0.038912
[10/24/2023-13:03:34] [V] [TRT] Tactic: 3 Time: 0.039808
[10/24/2023-13:03:34] [V] [TRT] Tactic: 4 Time: 0.036644
[10/24/2023-13:03:34] [V] [TRT] Tactic: 5 Time: 0.03456
[10/24/2023-13:03:34] [V] [TRT] Tactic: 6 Time: 0.042244
[10/24/2023-13:03:35] [V] [TRT] Tactic: 7 Time: 0.041088
[10/24/2023-13:03:35] [V] [TRT] Tactic: 8 Time: 0.041864
[10/24/2023-13:03:35] [V] [TRT] Tactic: 9 Time: 0.04072
[10/24/2023-13:03:35] [V] [TRT] Tactic: 28 Time: 0.05212
[10/24/2023-13:03:35] [V] [TRT] Fastest Tactic: 5 Time: 0.03456
[10/24/2023-13:03:35] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:35] [V] [TRT] Tactic: 128 Time: 0.140544
[10/24/2023-13:03:35] [V] [TRT] Tactic: 256 Time: 0.137484
[10/24/2023-13:03:35] [V] [TRT] Tactic: 512 Time: 0.129696
[10/24/2023-13:03:35] [V] [TRT] Tactic: -32 Time: 0.25472
[10/24/2023-13:03:35] [V] [TRT] Tactic: -64 Time: 0.150656
[10/24/2023-13:03:35] [V] [TRT] Tactic: -128 Time: 0.140288
[10/24/2023-13:03:35] [V] [TRT] Fastest Tactic: 512 Time: 0.129696
[10/24/2023-13:03:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[10/24/2023-13:03:35] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1), Half(128,1:2,1,1), Half(128,1:2,1,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:03:35] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:36] [V] [TRT] Tactic: 0 Time: 0.040832
[10/24/2023-13:03:36] [V] [TRT] Tactic: 1 Time: 0.040832
[10/24/2023-13:03:36] [V] [TRT] Tactic: 2 Time: 0.066832
[10/24/2023-13:03:36] [V] [TRT] Tactic: 3 Time: 0.043264
[10/24/2023-13:03:37] [V] [TRT] Tactic: 4 Time: 0.066688
[10/24/2023-13:03:37] [V] [TRT] Tactic: 5 Time: 0.090776
[10/24/2023-13:03:37] [V] [TRT] Tactic: 6 Time: 0.043284
[10/24/2023-13:03:37] [V] [TRT] Tactic: 7 Time: 0.066084
[10/24/2023-13:03:38] [V] [TRT] Tactic: 8 Time: 0.087424
[10/24/2023-13:03:38] [V] [TRT] Tactic: 9 Time: 0.083448
[10/24/2023-13:03:38] [V] [TRT] Tactic: 10 Time: 0.057344
[10/24/2023-13:03:38] [V] [TRT] Tactic: 11 Time: 0.046336
[10/24/2023-13:03:38] [V] [TRT] Tactic: 12 Time: 0.043012
[10/24/2023-13:03:38] [V] [TRT] Tactic: 13 Time: 0.04096
[10/24/2023-13:03:39] [V] [TRT] Tactic: 14 Time: 0.039672
[10/24/2023-13:03:39] [V] [TRT] Tactic: 15 Time: 0.037888
[10/24/2023-13:03:39] [V] [TRT] Tactic: 16 Time: 0.042152
[10/24/2023-13:03:39] [V] [TRT] Tactic: 17 Time: 0.03776
[10/24/2023-13:03:39] [V] [TRT] Tactic: 18 Time: 0.037376
[10/24/2023-13:03:40] [V] [TRT] Tactic: 19 Time: 0.036608
[10/24/2023-13:03:40] [V] [TRT] Tactic: 28 Time: 0.040108
[10/24/2023-13:03:40] [V] [TRT] Tactic: 29 Time: 0.05632
[10/24/2023-13:03:40] [V] [TRT] Fastest Tactic: 19 Time: 0.036608
[10/24/2023-13:03:40] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:40] [V] [TRT] Tactic: 128 Time: 0.134144
[10/24/2023-13:03:40] [V] [TRT] Tactic: 256 Time: 0.13504
[10/24/2023-13:03:40] [V] [TRT] Tactic: 512 Time: 0.137384
[10/24/2023-13:03:40] [V] [TRT] Fastest Tactic: 128 Time: 0.134144
[10/24/2023-13:03:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 19
[10/24/2023-13:03:40] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32), Half(32,1:8,32,32), Half(32,1:8,32,32) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:03:40] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:40] [V] [TRT] Tactic: 0 Time: 0.083916
[10/24/2023-13:03:40] [V] [TRT] Tactic: 1 Time: 0.083964
[10/24/2023-13:03:41] [V] [TRT] Tactic: 2 Time: 0.082448
[10/24/2023-13:03:41] [V] [TRT] Tactic: 3 Time: 0.084224
[10/24/2023-13:03:41] [V] [TRT] Tactic: 4 Time: 0.075332
[10/24/2023-13:03:41] [V] [TRT] Tactic: 5 Time: 0.077724
[10/24/2023-13:03:42] [V] [TRT] Tactic: 6 Time: 0.083968
[10/24/2023-13:03:42] [V] [TRT] Tactic: 7 Time: 0.076672
[10/24/2023-13:03:42] [V] [TRT] Tactic: 8 Time: 0.053632
[10/24/2023-13:03:43] [V] [TRT] Tactic: 9 Time: 0.056332
[10/24/2023-13:03:43] [V] [TRT] Tactic: 10 Time: 0.063724
[10/24/2023-13:03:43] [V] [TRT] Tactic: 11 Time: 0.063232
[10/24/2023-13:03:43] [V] [TRT] Tactic: 12 Time: 0.085404
[10/24/2023-13:03:43] [V] [TRT] Tactic: 13 Time: 0.062848
[10/24/2023-13:03:44] [V] [TRT] Tactic: 14 Time: 0.083472
[10/24/2023-13:03:44] [V] [TRT] Tactic: 15 Time: 0.083712
[10/24/2023-13:03:44] [V] [TRT] Tactic: 16 Time: 0.06336
[10/24/2023-13:03:44] [V] [TRT] Tactic: 17 Time: 0.083688
[10/24/2023-13:03:44] [V] [TRT] Tactic: 18 Time: 0.076624
[10/24/2023-13:03:45] [V] [TRT] Tactic: 19 Time: 0.076204
[10/24/2023-13:03:45] [V] [TRT] Tactic: 20 Time: 0.044412
[10/24/2023-13:03:45] [V] [TRT] Tactic: 21 Time: 0.039936
[10/24/2023-13:03:45] [V] [TRT] Tactic: 22 Time: 0.043404
[10/24/2023-13:03:45] [V] [TRT] Tactic: 23 Time: 0.043404
[10/24/2023-13:03:46] [V] [TRT] Tactic: 24 Time: 0.064952
[10/24/2023-13:03:46] [V] [TRT] Tactic: 25 Time: 0.05034
[10/24/2023-13:03:46] [V] [TRT] Tactic: 26 Time: 0.041956
[10/24/2023-13:03:46] [V] [TRT] Tactic: 27 Time: 0.042284
[10/24/2023-13:03:46] [V] [TRT] Tactic: 28 Time: 0.083584
[10/24/2023-13:03:47] [V] [TRT] Tactic: 29 Time: 0.063916
[10/24/2023-13:03:47] [V] [TRT] Tactic: 30 Time: 0.04398
[10/24/2023-13:03:47] [V] [TRT] Tactic: 31 Time: 0.063744
[10/24/2023-13:03:47] [V] [TRT] Fastest Tactic: 21 Time: 0.039936
[10/24/2023-13:03:47] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:47] [V] [TRT] Tactic: 128 Time: 0.142368
[10/24/2023-13:03:47] [V] [TRT] Tactic: 256 Time: 0.13928
[10/24/2023-13:03:47] [V] [TRT] Tactic: 512 Time: 0.132108
[10/24/2023-13:03:47] [V] [TRT] Tactic: -32 Time: 0.22132
[10/24/2023-13:03:47] [V] [TRT] Tactic: -64 Time: 0.143012
[10/24/2023-13:03:47] [V] [TRT] Tactic: -128 Time: 0.148456
[10/24/2023-13:03:47] [V] [TRT] Fastest Tactic: 512 Time: 0.132108
[10/24/2023-13:03:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 21
[10/24/2023-13:03:47] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16), Half(16,1:16,16,16), Half(16,1:16,16,16) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:03:47] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:47] [V] [TRT] Tactic: 10 Time: 0.08448
[10/24/2023-13:03:48] [V] [TRT] Tactic: 11 Time: 0.084624
[10/24/2023-13:03:48] [V] [TRT] Tactic: 12 Time: 0.0832
[10/24/2023-13:03:48] [V] [TRT] Tactic: 13 Time: 0.084516
[10/24/2023-13:03:48] [V] [TRT] Tactic: 14 Time: 0.076032
[10/24/2023-13:03:49] [V] [TRT] Tactic: 15 Time: 0.07758
[10/24/2023-13:03:49] [V] [TRT] Tactic: 16 Time: 0.0842
[10/24/2023-13:03:49] [V] [TRT] Tactic: 17 Time: 0.076396
[10/24/2023-13:03:50] [V] [TRT] Tactic: 18 Time: 0.053376
[10/24/2023-13:03:50] [V] [TRT] Tactic: 19 Time: 0.056188
[10/24/2023-13:03:50] [V] [TRT] Tactic: 20 Time: 0.063656
[10/24/2023-13:03:50] [V] [TRT] Tactic: 21 Time: 0.062924
[10/24/2023-13:03:51] [V] [TRT] Tactic: 22 Time: 0.062952
[10/24/2023-13:03:51] [V] [TRT] Tactic: 23 Time: 0.063
[10/24/2023-13:03:51] [V] [TRT] Tactic: 24 Time: 0.044284
[10/24/2023-13:03:51] [V] [TRT] Tactic: 25 Time: 0.039952
[10/24/2023-13:03:52] [V] [TRT] Tactic: 26 Time: 0.043004
[10/24/2023-13:03:52] [V] [TRT] Tactic: 27 Time: 0.043128
[10/24/2023-13:03:52] [V] [TRT] Tactic: 29 Time: 0.083724
[10/24/2023-13:03:52] [V] [TRT] Tactic: 30 Time: 0.063744
[10/24/2023-13:03:52] [V] [TRT] Tactic: 31 Time: 0.044132
[10/24/2023-13:03:52] [V] [TRT] Fastest Tactic: 25 Time: 0.039952
[10/24/2023-13:03:52] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWise)
[10/24/2023-13:03:52] [V] [TRT] Tactic: 128 Time: 0.14224
[10/24/2023-13:03:52] [V] [TRT] Tactic: 256 Time: 0.139376
[10/24/2023-13:03:52] [V] [TRT] Tactic: 512 Time: 0.132096
[10/24/2023-13:03:52] [V] [TRT] Tactic: -32 Time: 0.221464
[10/24/2023-13:03:52] [V] [TRT] Tactic: -64 Time: 0.142848
[10/24/2023-13:03:52] [V] [TRT] Tactic: -128 Time: 0.148608
[10/24/2023-13:03:52] [V] [TRT] Fastest Tactic: 512 Time: 0.132096
[10/24/2023-13:03:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[10/24/2023-13:03:52] [V] [TRT] *************** Autotuning format combination: Half(1:8,16384,128,1), Half(1:8,1,1,1), Half(1:8,1,1,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:03:52] [V] [TRT] --------------- Timing Runner: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) (PointWiseV2)
[10/24/2023-13:03:53] [V] [TRT] Tactic: 0 Time: 9.23584
[10/24/2023-13:03:53] [V] [TRT] Tactic: 1 Time: 7.20346
[10/24/2023-13:03:54] [V] [TRT] Tactic: 2 Time: 9.4311
[10/24/2023-13:03:54] [V] [TRT] Tactic: 3 Time: 7.76333
[10/24/2023-13:03:54] [V] [TRT] Tactic: 4 Time: 8.27328
[10/24/2023-13:03:55] [V] [TRT] Tactic: 5 Time: 7.19641
[10/24/2023-13:03:55] [V] [TRT] Tactic: 6 Time: 9.23561
[10/24/2023-13:03:56] [V] [TRT] Tactic: 7 Time: 9.59104
[10/24/2023-13:03:56] [V] [TRT] Tactic: 8 Time: 10.8598
[10/24/2023-13:03:57] [V] [TRT] Tactic: 9 Time: 11.9881
[10/24/2023-13:03:57] [V] [TRT] Tactic: 10 Time: 3.76128
[10/24/2023-13:03:57] [V] [TRT] Tactic: 11 Time: 4.18944
[10/24/2023-13:03:58] [V] [TRT] Tactic: 12 Time: 3.91462
[10/24/2023-13:03:58] [V] [TRT] Tactic: 13 Time: 4.70033
[10/24/2023-13:03:58] [V] [TRT] Tactic: 14 Time: 5.07929
[10/24/2023-13:03:59] [V] [TRT] Tactic: 15 Time: 4.04786
[10/24/2023-13:03:59] [V] [TRT] Tactic: 16 Time: 5.74182
[10/24/2023-13:03:59] [V] [TRT] Tactic: 17 Time: 5.94839
[10/24/2023-13:04:00] [V] [TRT] Tactic: 18 Time: 6.02714
[10/24/2023-13:04:00] [V] [TRT] Tactic: 19 Time: 5.10246
[10/24/2023-13:04:00] [V] [TRT] Tactic: 20 Time: 2.56705
[10/24/2023-13:04:01] [V] [TRT] Tactic: 21 Time: 3.01248
[10/24/2023-13:04:01] [V] [TRT] Tactic: 22 Time: 3.4569
[10/24/2023-13:04:01] [V] [TRT] Tactic: 23 Time: 4.36518
[10/24/2023-13:04:02] [V] [TRT] Tactic: 24 Time: 1.99579
[10/24/2023-13:04:02] [V] [TRT] Tactic: 25 Time: 2.43891
[10/24/2023-13:04:02] [V] [TRT] Tactic: 26 Time: 2.85478
[10/24/2023-13:04:02] [V] [TRT] Tactic: 27 Time: 3.69792
[10/24/2023-13:04:03] [V] [TRT] Tactic: 28 Time: 0.637968
[10/24/2023-13:04:03] [V] [TRT] Tactic: 29 Time: 0.480772
[10/24/2023-13:04:03] [V] [TRT] Tactic: 30 Time: 0.32576
[10/24/2023-13:04:04] [V] [TRT] Tactic: 31 Time: 0.496896
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 30 Time: 0.32576
[10/24/2023-13:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 30
[10/24/2023-13:04:04] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 0 Time: 0.063616
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 0 Time: 0.063616
[10/24/2023-13:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 0 Time: 0.034452
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 0 Time: 0.034452
[10/24/2023-13:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 0 Time: 0.034688
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 0 Time: 0.034688
[10/24/2023-13:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 0 Time: 0.034832
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 0 Time: 0.034832
[10/24/2023-13:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu (Scale)
[10/24/2023-13:04:04] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:04] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:04] [V] [TRT] *************** Autotuning format combination: Float(2097152,16384,128,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (FusedConvActConvolution)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 458751 Time: 0.251264
[10/24/2023-13:04:04] [V] [TRT] Fastest Tactic: 458751 Time: 0.251264
[10/24/2023-13:04:04] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:04] [V] [TRT] Tactic: 0 Time: 0.2235
[10/24/2023-13:04:04] [V] [TRT] Tactic: 1 Time: 0.109216
[10/24/2023-13:04:04] [V] [TRT] Tactic: 2 Time: 0.269752
[10/24/2023-13:04:04] [V] [TRT] Tactic: 5 Time: 6.99367
[10/24/2023-13:04:04] [V] [TRT] Tactic: 56 Time: 0.224256
[10/24/2023-13:04:04] [V] [TRT] Tactic: 57 Time: 0.11058
[10/24/2023-13:04:04] [V] [TRT] Tactic: 58 Time: 0.269824
[10/24/2023-13:04:04] [V] [TRT] Tactic: 61 Time: 6.99404
[10/24/2023-13:04:04] [V] [TRT] Tactic: 112 Time: 0.224
[10/24/2023-13:04:04] [V] [TRT] Tactic: 113 Time: 0.264688
[10/24/2023-13:04:04] [V] [TRT] Tactic: 114 Time: 0.270088
[10/24/2023-13:04:05] [V] [TRT] Tactic: 117 Time: 6.99162
[10/24/2023-13:04:05] [V] [TRT] Fastest Tactic: 1 Time: 0.109216
[10/24/2023-13:04:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4549827808004681195 Time: 0.168448
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:05] [V] [TRT] Tactic: 5779835512569528575 Time: 0.147204
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:05] [V] [TRT] Tactic: 6053873026024413720 Time: 0.147608
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:05] [V] [TRT] Tactic: 6767548733843469815 Time: 0.160796
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:05] [V] [TRT] Tactic: -6313876406580483184 Time: 0.19712
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:05] [V] [TRT] Tactic: -1123676555321336786 Time: 0.14592
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:05] [V] [TRT] Tactic: -701551393537224327 Time: 0.173328
[10/24/2023-13:04:05] [V] [TRT] Fastest Tactic: -1123676555321336786 Time: 0.14592
[10/24/2023-13:04:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:04:05] [V] [TRT] *************** Autotuning format combination: Float(2097152,1,16384,128) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:05] [V] [TRT] Tactic: 2086609538387166260 Time: 0.195872
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:05] [V] [TRT] Tactic: 2860655430572478466 Time: 0.165376
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:05] [V] [TRT] Tactic: 3239733199291090177 Time: 0.195712
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4474630279712975759 Time: 0.174444
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4479823862704990365 Time: 0.172824
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4517590677127196184 Time: 0.157448
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188032
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4696204239951173149 Time: 0.16576
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:05] [V] [TRT] Tactic: 5778138195697110003 Time: 0.1632
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:05] [V] [TRT] Tactic: 6310198979346901507 Time: 0.35328
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:05] [V] [TRT] Tactic: 7155825427510256858 Time: 0.152192
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:05] [V] [TRT] Tactic: 7222247112373541608 Time: 0.242956
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:05] [V] [TRT] Tactic: 7472640475524677095 Time: 0.192128
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:05] [V] [TRT] Tactic: 8498373915030836990 Time: 0.31488
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:05] [V] [TRT] Tactic: 8869697132622550639 Time: 0.307712
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:05] [V] [TRT] Tactic: 8918020581761223752 Time: 0.149388
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:05] [V] [TRT] Tactic: -8937725997228636978 Time: 0.321824
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:05] [V] [TRT] Tactic: -8833858409138163072 Time: 0.291088
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:05] [V] [TRT] Tactic: -7989138351613022500 Time: 0.270464
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:05] [V] [TRT] Tactic: -7872883691240863058 Time: 0.369792
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:05] [V] [TRT] Tactic: -6729618519651721910 Time: 0.18944
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:05] [V] [TRT] Tactic: -5893833996418445881 Time: 0.314764
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:05] [V] [TRT] Tactic: -5701562095007058349 Time: 0.293784
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:05] [V] [TRT] Tactic: -5685503422376017600 Time: 0.241152
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:05] [V] [TRT] Tactic: -5521125187060117489 Time: 0.27394
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:05] [V] [TRT] Tactic: -4756382386362004279 Time: 0.16384
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:05] [V] [TRT] Tactic: -4615000974950361663 Time: 0.270996
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:05] [V] [TRT] Tactic: -4314913710375142296 Time: 0.272384
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:05] [V] [TRT] Tactic: -3855385237722507464 Time: 0.164368
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:05] [V] [TRT] Tactic: -3697587361057948972 Time: 0.240776
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:05] [V] [TRT] Tactic: -2809379259463049391 Time: 0.16128
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:05] [V] [TRT] Tactic: -2747929399988666512 Time: 0.153728
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:05] [V] [TRT] Tactic: -1472061967969061456 Time: 0.179328
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:05] [V] [TRT] Tactic: -504296718212024303 Time: 0.150784
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:05] [V] [TRT] Tactic: -444093195553988951 Time: 0.194948
[10/24/2023-13:04:05] [V] [TRT] Fastest Tactic: 8918020581761223752 Time: 0.149388
[10/24/2023-13:04:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8918020581761223752
[10/24/2023-13:04:05] [V] [TRT] *************** Autotuning format combination: Float(524288,1:4,4096,32) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:05] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:05] [V] [TRT] Tactic: 2086609538387166260 Time: 0.195488
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:05] [V] [TRT] Tactic: 2860655430572478466 Time: 0.165504
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:05] [V] [TRT] Tactic: 3239733199291090177 Time: 0.19584
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4474630279712975759 Time: 0.174336
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:05] [V] [TRT] Tactic: 4479823862704990365 Time: 0.1728
[10/24/2023-13:04:05] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:06] [V] [TRT] Tactic: 4517590677127196184 Time: 0.157336
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:06] [V] [TRT] Tactic: 4634080872644479428 Time: 0.187784
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:06] [V] [TRT] Tactic: 4696204239951173149 Time: 0.165632
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:06] [V] [TRT] Tactic: 5778138195697110003 Time: 0.163456
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:06] [V] [TRT] Tactic: 6310198979346901507 Time: 0.35316
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:06] [V] [TRT] Tactic: 7155825427510256858 Time: 0.15232
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:06] [V] [TRT] Tactic: 7222247112373541608 Time: 0.24256
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:06] [V] [TRT] Tactic: 7342025736444949634 Time: 0.065536
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:06] [V] [TRT] Tactic: 7472640475524677095 Time: 0.191844
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:06] [V] [TRT] Tactic: 8498373915030836990 Time: 0.31502
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:06] [V] [TRT] Tactic: 8869697132622550639 Time: 0.307212
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:06] [V] [TRT] Tactic: 8918020581761223752 Time: 0.149376
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:06] [V] [TRT] Tactic: -8937725997228636978 Time: 0.32194
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:06] [V] [TRT] Tactic: -8833858409138163072 Time: 0.291328
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:06] [V] [TRT] Tactic: -7989138351613022500 Time: 0.27072
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:06] [V] [TRT] Tactic: -7872883691240863058 Time: 0.369792
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:06] [V] [TRT] Tactic: -7377458734869418330 Time: 0.062464
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:06] [V] [TRT] Tactic: -6729618519651721910 Time: 0.18944
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5893833996418445881 Time: 0.314496
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5701562095007058349 Time: 0.293284
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5685503422376017600 Time: 0.241024
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5521125187060117489 Time: 0.27382
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5457304872213719461 Time: 0.062436
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:06] [V] [TRT] Tactic: -4756382386362004279 Time: 0.16372
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:06] [V] [TRT] Tactic: -4615000974950361663 Time: 0.270856
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:06] [V] [TRT] Tactic: -4314913710375142296 Time: 0.271644
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:06] [V] [TRT] Tactic: -3855385237722507464 Time: 0.16436
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:06] [V] [TRT] Tactic: -3697587361057948972 Time: 0.24064
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:06] [V] [TRT] Tactic: -2809379259463049391 Time: 0.161076
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:06] [V] [TRT] Tactic: -2747929399988666512 Time: 0.153868
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:06] [V] [TRT] Tactic: -1472061967969061456 Time: 0.179328
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:06] [V] [TRT] Tactic: -504296718212024303 Time: 0.150784
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:06] [V] [TRT] Tactic: -444093195553988951 Time: 0.194792
[10/24/2023-13:04:06] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.062436
[10/24/2023-13:04:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:04:06] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384,128,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:06] [V] [TRT] Tactic: 0 Time: 0.242304
[10/24/2023-13:04:06] [V] [TRT] Tactic: 1 Time: 0.210432
[10/24/2023-13:04:06] [V] [TRT] Tactic: 2 Time: 0.241024
[10/24/2023-13:04:06] [V] [TRT] Tactic: 5 Time: 6.9758
[10/24/2023-13:04:06] [V] [TRT] Tactic: 56 Time: 0.242176
[10/24/2023-13:04:06] [V] [TRT] Tactic: 58 Time: 0.241664
[10/24/2023-13:04:06] [V] [TRT] Tactic: 61 Time: 6.97526
[10/24/2023-13:04:06] [V] [TRT] Fastest Tactic: 1 Time: 0.210432
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:04:06] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384:2,128,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (FusedConvActConvolution)
[10/24/2023-13:04:06] [V] [TRT] Tactic: 458751 Time: 0.118392
[10/24/2023-13:04:06] [V] [TRT] Fastest Tactic: 458751 Time: 0.118392
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:06] [V] [TRT] Tactic: 2195670545862694453 Time: 0.109208
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:06] [V] [TRT] Tactic: 3419182076704469245 Time: 0.108672
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:06] [V] [TRT] Tactic: 3891805945559659536 Time: 0.09728
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:06] [V] [TRT] Tactic: 5548126322150286555 Time: 0.107784
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:06] [V] [TRT] Tactic: 6057304366605292508 Time: 0.105088
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:06] [V] [TRT] Tactic: -7928611605886347652 Time: 0.099608
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:06] [V] [TRT] Tactic: -5172391392092686714 Time: 0.109832
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:06] [V] [TRT] Tactic: -4374269919094467161 Time: 0.107648
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:06] [V] [TRT] Tactic: -1546027692247304867 Time: 0.097824
[10/24/2023-13:04:06] [V] [TRT] Fastest Tactic: 3891805945559659536 Time: 0.09728
[10/24/2023-13:04:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3891805945559659536
[10/24/2023-13:04:06] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:06] [V] [TRT] *************** Autotuning format combination: Half(262144,1:8,2048,16) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:06] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:06] [V] [TRT] Tactic: 0 Time: 0.295424
[10/24/2023-13:04:06] [V] [TRT] Tactic: 1 Time: 0.581888
[10/24/2023-13:04:06] [V] [TRT] Tactic: 2 Time: 0.292992
[10/24/2023-13:04:06] [V] [TRT] Tactic: 56 Time: 0.293888
[10/24/2023-13:04:06] [V] [TRT] Tactic: 58 Time: 0.292736
[10/24/2023-13:04:06] [V] [TRT] Fastest Tactic: 58 Time: 0.292736
[10/24/2023-13:04:06] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:06] [V] [TRT] Tactic: 254850674756030979 Time: 0.054568
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:06] [V] [TRT] Tactic: 328038211831149625 Time: 0.052492
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:06] [V] [TRT] Tactic: 411553864378931917 Time: 0.042112
[10/24/2023-13:04:06] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1011057357468998345 Time: 0.032776
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1156328698016730421 Time: 0.036108
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1723736032573714698 Time: 0.036096
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1832046141070096030 Time: 0.039444
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1838082074606840426 Time: 0.039936
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:07] [V] [TRT] Tactic: 1899296423087490472 Time: 0.050048
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2428167804343994714 Time: 0.038292
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2541579301352125276 Time: 0.03712
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2657157263811141609 Time: 0.051456
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2819719497590964443 Time: 0.041216
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2968605903460894194 Time: 0.039828
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:07] [V] [TRT] Tactic: 2986078304285316765 Time: 0.037888
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:07] [V] [TRT] Tactic: 3362537467505018070 Time: 0.031872
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:07] [V] [TRT] Tactic: 3513075359009385578 Time: 0.054844
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:07] [V] [TRT] Tactic: 3573559043797674382 Time: 0.039952
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:07] [V] [TRT] Tactic: 3591970081995419777 Time: 0.050304
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:07] [V] [TRT] Tactic: 3704534001553878387 Time: 0.03458
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:07] [V] [TRT] Tactic: 4278315135102886928 Time: 0.03928
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:07] [V] [TRT] Tactic: 4503233883285355107 Time: 0.052992
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:07] [V] [TRT] Tactic: 4802447371470387646 Time: 0.041984
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5059676457552313631 Time: 0.053636
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5368829646735632944 Time: 0.049792
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5398999388616959893 Time: 0.036864
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5746691132547383910 Time: 0.040732
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5770170567977052602 Time: 0.042368
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:07] [V] [TRT] Tactic: 5953552212833506549 Time: 0.031744
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6034364043891107501 Time: 0.039044
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6074229447555668232 Time: 0.049428
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6154447660803990543 Time: 0.042496
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6325769668000961702 Time: 0.031752
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6350273239113254096 Time: 0.070144
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6377497238381488891 Time: 0.031872
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6446388116965632819 Time: 0.039168
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6468794451065529747 Time: 0.04032
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6642277870194067185 Time: 0.055552
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6859477213531075460 Time: 0.049024
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6972489290272968208 Time: 0.030848
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:07] [V] [TRT] Tactic: 6979044990896381511 Time: 0.052496
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:07] [V] [TRT] Tactic: 7216571380637776659 Time: 0.042512
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:07] [V] [TRT] Tactic: 7609923741161019135 Time: 0.038764
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:07] [V] [TRT] Tactic: 7705739241028240201 Time: 0.050816
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:07] [V] [TRT] Tactic: 8072087735545283117 Time: 0.053376
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:07] [V] [TRT] Tactic: 8101703987960976805 Time: 0.051328
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:07] [V] [TRT] Tactic: 8170606396342855895 Time: 0.04032
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:07] [V] [TRT] Tactic: 8839784824303350101 Time: 0.040448
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:07] [V] [TRT] Tactic: -9217371357561775773 Time: 0.051328
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:07] [V] [TRT] Tactic: -9009272790678027912 Time: 0.04352
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:07] [V] [TRT] Tactic: -8985224497679592364 Time: 0.054296
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:07] [V] [TRT] Tactic: -8949544755481315679 Time: 0.03994
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:07] [V] [TRT] Tactic: -8759929675070720385 Time: 0.031232
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:07] [V] [TRT] Tactic: -8604374562669615024 Time: 0.050312
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6902925267326201166 Time: 0.068864
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6840588038605932325 Time: 0.03968
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6799856376604253964 Time: 0.05248
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6625722781282978136 Time: 0.05056
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6525498856028268801 Time: 0.032512
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6356316196810535311 Time: 0.052992
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6324345858751792783 Time: 0.051596
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6262400699544994312 Time: 0.05248
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6257787336162086472 Time: 0.03648
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:07] [V] [TRT] Tactic: -6063766379489217211 Time: 0.039476
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5777580938094193096 Time: 0.036264
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5657273398217409378 Time: 0.053504
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5530886555766748586 Time: 0.03712
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5422685219138380548 Time: 0.037012
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5161596964442251102 Time: 0.04032
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:07] [V] [TRT] Tactic: -5127240325355316006 Time: 0.038796
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4825567853927730435 Time: 0.037268
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4796511246675321840 Time: 0.04086
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4706569565442112734 Time: 0.052992
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4566599693570369588 Time: 0.031616
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4409144516525410768 Time: 0.032132
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4379519430184503304 Time: 0.038804
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:07] [V] [TRT] Tactic: -4152066959007262150 Time: 0.054528
[10/24/2023-13:04:07] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:08] [V] [TRT] Tactic: -4021926646879732549 Time: 0.039424
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3987638434926559037 Time: 0.04096
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3905653247016903130 Time: 0.037644
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3903974568488493144 Time: 0.037888
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3895429239811098010 Time: 0.039168
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3864869056275745423 Time: 0.040964
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3601464762214218301 Time: 0.048676
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3412636942650049698 Time: 0.037376
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3338665856053412950 Time: 0.031888
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:08] [V] [TRT] Tactic: -3058330359340425555 Time: 0.040448
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2816084650627734155 Time: 0.043264
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2662892962457732243 Time: 0.03586
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2559894581585337900 Time: 0.054528
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2530740716768816092 Time: 0.052224
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2332828394978346992 Time: 0.030728
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2241736083352441442 Time: 0.042624
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:08] [V] [TRT] Tactic: -2161909437867201546 Time: 0.065792
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:08] [V] [TRT] Tactic: -1985778916402815946 Time: 0.042248
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:08] [V] [TRT] Tactic: -1500496213132463076 Time: 0.040832
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:08] [V] [TRT] Tactic: -1099247066487349374 Time: 0.050048
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:08] [V] [TRT] Tactic: -910286698936744682 Time: 0.051712
[10/24/2023-13:04:08] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:08] [V] [TRT] Tactic: -606726295133751039 Time: 0.053504
[10/24/2023-13:04:08] [V] [TRT] Fastest Tactic: -2332828394978346992 Time: 0.030728
[10/24/2023-13:04:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2332828394978346992
[10/24/2023-13:04:08] [V] [TRT] *************** Autotuning format combination: Half(131072,1:16,1024,8) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:08] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CudnnConvolution)
[10/24/2023-13:04:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:08] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu (CaskConvolution)
[10/24/2023-13:04:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:08] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:08] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:08] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:08] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (FusedConvActConvolution)
[10/24/2023-13:04:08] [V] [TRT] Tactic: 524287 Time: 0.27776
[10/24/2023-13:04:08] [V] [TRT] Tactic: 720895 Time: 0.264336
[10/24/2023-13:04:08] [V] [TRT] Tactic: 983039 Time: 0.251648
[10/24/2023-13:04:08] [V] [TRT] Tactic: 1048575 Time: 0.283924
[10/24/2023-13:04:08] [V] [TRT] Tactic: 1703935 Time: 0.236928
[10/24/2023-13:04:08] [V] [TRT] Tactic: 1769471 Time: 0.301972
[10/24/2023-13:04:08] [V] [TRT] Tactic: 1966079 Time: 0.321032
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2031615 Time: 0.348416
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2228223 Time: 0.28992
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2424831 Time: 0.299144
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2621439 Time: 0.247832
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2752511 Time: 0.342812
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2818047 Time: 0.3392
[10/24/2023-13:04:08] [V] [TRT] Tactic: 2883583 Time: 0.371612
[10/24/2023-13:04:08] [V] [TRT] Tactic: 3014655 Time: 0.246292
[10/24/2023-13:04:08] [V] [TRT] Tactic: 3145727 Time: 0.281728
[10/24/2023-13:04:09] [V] [TRT] Tactic: 3473407 Time: 0.297344
[10/24/2023-13:04:09] [V] [TRT] Tactic: 3604479 Time: 0.260352
[10/24/2023-13:04:09] [V] [TRT] Tactic: 3735551 Time: 0.281216
[10/24/2023-13:04:09] [V] [TRT] Tactic: 4390911 Time: 0.356244
[10/24/2023-13:04:09] [V] [TRT] Tactic: 5046271 Time: 0.278656
[10/24/2023-13:04:09] [V] [TRT] Tactic: 5963775 Time: 0.294664
[10/24/2023-13:04:09] [V] [TRT] Tactic: 6160383 Time: 0.29888
[10/24/2023-13:04:09] [V] [TRT] Tactic: 6488063 Time: 0.314772
[10/24/2023-13:04:09] [V] [TRT] Tactic: 6881279 Time: 0.289816
[10/24/2023-13:04:09] [V] [TRT] Tactic: 7274495 Time: 0.30656
[10/24/2023-13:04:09] [V] [TRT] Tactic: 7864319 Time: 0.281984
[10/24/2023-13:04:09] [V] [TRT] Tactic: 7995391 Time: 0.300288
[10/24/2023-13:04:09] [V] [TRT] Tactic: 8585215 Time: 0.325888
[10/24/2023-13:04:09] [V] [TRT] Tactic: 8847359 Time: 0.33344
[10/24/2023-13:04:09] [V] [TRT] Tactic: 8978431 Time: 0.283504
[10/24/2023-13:04:09] [V] [TRT] Tactic: 9043967 Time: 0.268544
[10/24/2023-13:04:09] [V] [TRT] Tactic: 9175039 Time: 0.26048
[10/24/2023-13:04:09] [V] [TRT] Tactic: 9502719 Time: 0.330392
[10/24/2023-13:04:09] [V] [TRT] Tactic: 9830399 Time: 0.292356
[10/24/2023-13:04:09] [V] [TRT] Tactic: 9961471 Time: 0.310656
[10/24/2023-13:04:09] [V] [TRT] Tactic: 10027007 Time: 0.28672
[10/24/2023-13:04:09] [V] [TRT] Tactic: 10092543 Time: 0.356608
[10/24/2023-13:04:09] [V] [TRT] Tactic: 10289151 Time: 0.321408
[10/24/2023-13:04:09] [V] [TRT] Tactic: 10485759 Time: 0.259972
[10/24/2023-13:04:10] [V] [TRT] Tactic: 10682367 Time: 0.243456
[10/24/2023-13:04:10] [V] [TRT] Tactic: 10813439 Time: 0.261884
[10/24/2023-13:04:10] [V] [TRT] Fastest Tactic: 1703935 Time: 0.236928
[10/24/2023-13:04:10] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:10] [V] [TRT] Tactic: 0 Time: 0.416616
[10/24/2023-13:04:10] [V] [TRT] Tactic: 1 Time: 0.141196
[10/24/2023-13:04:10] [V] [TRT] Tactic: 2 Time: 0.469248
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8760590336, available: 4294967296
[10/24/2023-13:04:10] [V] [TRT] Tactic: 5 Time: 5.39135
[10/24/2023-13:04:10] [V] [TRT] Tactic: 6 Time: 0.205316
[10/24/2023-13:04:10] [V] [TRT] Tactic: 56 Time: 0.41624
[10/24/2023-13:04:10] [V] [TRT] Tactic: 57 Time: 0.140288
[10/24/2023-13:04:10] [V] [TRT] Tactic: 58 Time: 0.46848
[10/24/2023-13:04:10] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8760590336, available: 4294967296
[10/24/2023-13:04:10] [V] [TRT] Tactic: 61 Time: 5.38159
[10/24/2023-13:04:10] [V] [TRT] Tactic: 62 Time: 0.206956
[10/24/2023-13:04:10] [V] [TRT] Tactic: 112 Time: 0.416896
[10/24/2023-13:04:10] [V] [TRT] Tactic: 113 Time: 0.39424
[10/24/2023-13:04:10] [V] [TRT] Tactic: 114 Time: 0.468228
[10/24/2023-13:04:10] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8760590336, available: 4294967296
[10/24/2023-13:04:10] [V] [TRT] Tactic: 117 Time: 5.38355
[10/24/2023-13:04:10] [V] [TRT] Tactic: 118 Time: 0.207232
[10/24/2023-13:04:10] [V] [TRT] Fastest Tactic: 57 Time: 0.140288
[10/24/2023-13:04:10] [V] [TRT] Setting workspace to 8760590336enables more tactics for profiling
[10/24/2023-13:04:10] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4549827808004681195 Time: 0.32576
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:10] [V] [TRT] Tactic: 5779835512569528575 Time: 0.282724
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:10] [V] [TRT] Tactic: 6053873026024413720 Time: 0.285336
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:10] [V] [TRT] Tactic: 6767548733843469815 Time: 0.315392
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:10] [V] [TRT] Tactic: -6313876406580483184 Time: 0.37632
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:10] [V] [TRT] Tactic: -1123676555321336786 Time: 0.282752
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:10] [V] [TRT] Tactic: -701551393537224327 Time: 0.3351
[10/24/2023-13:04:10] [V] [TRT] Fastest Tactic: 5779835512569528575 Time: 0.282724
[10/24/2023-13:04:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[10/24/2023-13:04:10] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:10] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:10] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:10] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:10] [V] [TRT] Tactic: 2086609538387166260 Time: 0.382568
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:10] [V] [TRT] Tactic: 2860655430572478466 Time: 0.316684
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:10] [V] [TRT] Tactic: 3239733199291090177 Time: 0.383232
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4474630279712975759 Time: 0.334844
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4479823862704990365 Time: 0.330372
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4517590677127196184 Time: 0.306432
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4634080872644479428 Time: 0.364928
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:10] [V] [TRT] Tactic: 4696204239951173149 Time: 0.317056
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:10] [V] [TRT] Tactic: 5778138195697110003 Time: 0.299264
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:10] [V] [TRT] Tactic: 6310198979346901507 Time: 0.693504
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:10] [V] [TRT] Tactic: 7155825427510256858 Time: 0.279808
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:10] [V] [TRT] Tactic: 7222247112373541608 Time: 0.479744
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:10] [V] [TRT] Tactic: 7472640475524677095 Time: 0.37568
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:10] [V] [TRT] Tactic: 8498373915030836990 Time: 0.619392
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:10] [V] [TRT] Tactic: 8869697132622550639 Time: 0.598912
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:10] [V] [TRT] Tactic: 8918020581761223752 Time: 0.274176
[10/24/2023-13:04:10] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:10] [V] [TRT] Tactic: -8937725997228636978 Time: 0.633984
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:11] [V] [TRT] Tactic: -8833858409138163072 Time: 0.571916
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:11] [V] [TRT] Tactic: -7989138351613022500 Time: 0.534528
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:11] [V] [TRT] Tactic: -7872883691240863058 Time: 0.726528
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:11] [V] [TRT] Tactic: -6729618519651721910 Time: 0.367244
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5893833996418445881 Time: 0.6208
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5701562095007058349 Time: 0.576512
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5685503422376017600 Time: 0.477208
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5521125187060117489 Time: 0.539776
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4756382386362004279 Time: 0.312708
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4615000974950361663 Time: 0.536584
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4314913710375142296 Time: 0.536068
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:11] [V] [TRT] Tactic: -3855385237722507464 Time: 0.29966
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:11] [V] [TRT] Tactic: -3697587361057948972 Time: 0.476416
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:11] [V] [TRT] Tactic: -2809379259463049391 Time: 0.293888
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:11] [V] [TRT] Tactic: -2747929399988666512 Time: 0.296948
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:11] [V] [TRT] Tactic: -1472061967969061456 Time: 0.349304
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:11] [V] [TRT] Tactic: -504296718212024303 Time: 0.2784
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:11] [V] [TRT] Tactic: -444093195553988951 Time: 0.379636
[10/24/2023-13:04:11] [V] [TRT] Fastest Tactic: 8918020581761223752 Time: 0.274176
[10/24/2023-13:04:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8918020581761223752
[10/24/2023-13:04:11] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:11] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:11] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:11] [V] [TRT] Tactic: 2086609538387166260 Time: 0.382708
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:11] [V] [TRT] Tactic: 2860655430572478466 Time: 0.316684
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:11] [V] [TRT] Tactic: 3239733199291090177 Time: 0.383104
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:11] [V] [TRT] Tactic: 4474630279712975759 Time: 0.33308
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:11] [V] [TRT] Tactic: 4479823862704990365 Time: 0.33216
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:11] [V] [TRT] Tactic: 4517590677127196184 Time: 0.306304
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:11] [V] [TRT] Tactic: 4634080872644479428 Time: 0.364944
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:11] [V] [TRT] Tactic: 4696204239951173149 Time: 0.317312
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:11] [V] [TRT] Tactic: 5778138195697110003 Time: 0.299264
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:11] [V] [TRT] Tactic: 6310198979346901507 Time: 0.694632
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:11] [V] [TRT] Tactic: 7155825427510256858 Time: 0.280064
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:11] [V] [TRT] Tactic: 7222247112373541608 Time: 0.479872
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:11] [V] [TRT] Tactic: 7342025736444949634 Time: 0.112896
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:11] [V] [TRT] Tactic: 7472640475524677095 Time: 0.37568
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:11] [V] [TRT] Tactic: 8498373915030836990 Time: 0.619008
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:11] [V] [TRT] Tactic: 8869697132622550639 Time: 0.599016
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:11] [V] [TRT] Tactic: 8918020581761223752 Time: 0.273796
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:11] [V] [TRT] Tactic: -8937725997228636978 Time: 0.632748
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:11] [V] [TRT] Tactic: -8833858409138163072 Time: 0.571416
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:11] [V] [TRT] Tactic: -7989138351613022500 Time: 0.532616
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:11] [V] [TRT] Tactic: -7872883691240863058 Time: 0.726032
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:11] [V] [TRT] Tactic: -7377458734869418330 Time: 0.104564
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:11] [V] [TRT] Tactic: -6729618519651721910 Time: 0.366336
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5893833996418445881 Time: 0.620416
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5701562095007058349 Time: 0.576388
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5685503422376017600 Time: 0.476904
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5521125187060117489 Time: 0.54208
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:11] [V] [TRT] Tactic: -5457304872213719461 Time: 0.104192
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4756382386362004279 Time: 0.312448
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4615000974950361663 Time: 0.537472
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:11] [V] [TRT] Tactic: -4314913710375142296 Time: 0.5366
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:11] [V] [TRT] Tactic: -3855385237722507464 Time: 0.299368
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:11] [V] [TRT] Tactic: -3697587361057948972 Time: 0.475776
[10/24/2023-13:04:11] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:12] [V] [TRT] Tactic: -2809379259463049391 Time: 0.294124
[10/24/2023-13:04:12] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:12] [V] [TRT] Tactic: -2747929399988666512 Time: 0.296836
[10/24/2023-13:04:12] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:12] [V] [TRT] Tactic: -1472061967969061456 Time: 0.349056
[10/24/2023-13:04:12] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:12] [V] [TRT] Tactic: -504296718212024303 Time: 0.278164
[10/24/2023-13:04:12] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:12] [V] [TRT] Tactic: -444093195553988951 Time: 0.379264
[10/24/2023-13:04:12] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.104192
[10/24/2023-13:04:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:04:12] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:12] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:12] [V] [TRT] Tactic: 0 Time: 0.438112
[10/24/2023-13:04:12] [V] [TRT] Tactic: 1 Time: 0.384744
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2 Time: 0.413056
[10/24/2023-13:04:12] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8760590336, available: 4294967296
[10/24/2023-13:04:12] [V] [TRT] Tactic: 5 Time: 5.34988
[10/24/2023-13:04:12] [V] [TRT] Tactic: 6 Time: 0.233088
[10/24/2023-13:04:12] [V] [TRT] Tactic: 56 Time: 0.437648
[10/24/2023-13:04:12] [V] [TRT] Tactic: 58 Time: 0.412928
[10/24/2023-13:04:12] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8760590336, available: 4294967296
[10/24/2023-13:04:12] [V] [TRT] Tactic: 61 Time: 5.34871
[10/24/2023-13:04:12] [V] [TRT] Tactic: 62 Time: 0.23296
[10/24/2023-13:04:12] [V] [TRT] Fastest Tactic: 62 Time: 0.23296
[10/24/2023-13:04:12] [V] [TRT] Setting workspace to 8760590336enables more tactics for profiling
[10/24/2023-13:04:12] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:12] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:12] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:12] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (FusedConvActConvolution)
[10/24/2023-13:04:12] [V] [TRT] Tactic: 524287 Time: 0.194816
[10/24/2023-13:04:12] [V] [TRT] Tactic: 720895 Time: 0.193536
[10/24/2023-13:04:12] [V] [TRT] Tactic: 983039 Time: 0.17688
[10/24/2023-13:04:12] [V] [TRT] Tactic: 1048575 Time: 0.17024
[10/24/2023-13:04:12] [V] [TRT] Tactic: 1703935 Time: 0.162816
[10/24/2023-13:04:12] [V] [TRT] Tactic: 1769471 Time: 0.204032
[10/24/2023-13:04:12] [V] [TRT] Tactic: 1966079 Time: 0.213504
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2031615 Time: 0.24704
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2228223 Time: 0.192264
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2424831 Time: 0.188416
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2621439 Time: 0.16576
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2752511 Time: 0.220032
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2818047 Time: 0.214528
[10/24/2023-13:04:12] [V] [TRT] Tactic: 2883583 Time: 0.26754
[10/24/2023-13:04:12] [V] [TRT] Tactic: 3014655 Time: 0.177152
[10/24/2023-13:04:12] [V] [TRT] Tactic: 3145727 Time: 0.191488
[10/24/2023-13:04:12] [V] [TRT] Tactic: 3473407 Time: 0.19456
[10/24/2023-13:04:12] [V] [TRT] Tactic: 3604479 Time: 0.178176
[10/24/2023-13:04:12] [V] [TRT] Tactic: 3735551 Time: 0.189572
[10/24/2023-13:04:13] [V] [TRT] Tactic: 4390911 Time: 0.23552
[10/24/2023-13:04:13] [V] [TRT] Tactic: 5046271 Time: 0.1887
[10/24/2023-13:04:13] [V] [TRT] Tactic: 5963775 Time: 0.200448
[10/24/2023-13:04:13] [V] [TRT] Tactic: 6160383 Time: 0.192524
[10/24/2023-13:04:13] [V] [TRT] Tactic: 6488063 Time: 0.208512
[10/24/2023-13:04:13] [V] [TRT] Tactic: 6881279 Time: 0.21314
[10/24/2023-13:04:13] [V] [TRT] Tactic: 7274495 Time: 0.191744
[10/24/2023-13:04:13] [V] [TRT] Tactic: 7864319 Time: 0.189352
[10/24/2023-13:04:13] [V] [TRT] Tactic: 7995391 Time: 0.208256
[10/24/2023-13:04:13] [V] [TRT] Tactic: 8585215 Time: 0.230656
[10/24/2023-13:04:13] [V] [TRT] Tactic: 8847359 Time: 0.193536
[10/24/2023-13:04:13] [V] [TRT] Tactic: 8978431 Time: 0.199936
[10/24/2023-13:04:13] [V] [TRT] Tactic: 9043967 Time: 0.191872
[10/24/2023-13:04:13] [V] [TRT] Tactic: 9175039 Time: 0.178176
[10/24/2023-13:04:13] [V] [TRT] Tactic: 9502719 Time: 0.236032
[10/24/2023-13:04:13] [V] [TRT] Tactic: 9830399 Time: 0.195968
[10/24/2023-13:04:13] [V] [TRT] Tactic: 9961471 Time: 0.193152
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10027007 Time: 0.199944
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10092543 Time: 0.235392
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10289151 Time: 0.213888
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10485759 Time: 0.181248
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10682367 Time: 0.167808
[10/24/2023-13:04:13] [V] [TRT] Tactic: 10813439 Time: 0.17984
[10/24/2023-13:04:13] [V] [TRT] Fastest Tactic: 1703935 Time: 0.162816
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:13] [V] [TRT] Tactic: 2195670545862694453 Time: 0.20992
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:13] [V] [TRT] Tactic: 3419182076704469245 Time: 0.208896
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:13] [V] [TRT] Tactic: 3891805945559659536 Time: 0.185088
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:13] [V] [TRT] Tactic: 5548126322150286555 Time: 0.205884
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:13] [V] [TRT] Tactic: 6057304366605292508 Time: 0.19968
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:13] [V] [TRT] Tactic: -7928611605886347652 Time: 0.190592
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:13] [V] [TRT] Tactic: -5172391392092686714 Time: 0.210688
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:13] [V] [TRT] Tactic: -4374269919094467161 Time: 0.205184
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:13] [V] [TRT] Tactic: -4083394051665370953 Time: 0.101524
[10/24/2023-13:04:13] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:13] [V] [TRT] Tactic: -1546027692247304867 Time: 0.185984
[10/24/2023-13:04:13] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.101524
[10/24/2023-13:04:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:13] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:13] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:13] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:13] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:13] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:13] [V] [TRT] Tactic: 0 Time: 0.56872
[10/24/2023-13:04:13] [V] [TRT] Tactic: 1 Time: 0.940928
[10/24/2023-13:04:13] [V] [TRT] Tactic: 2 Time: 0.462592
[10/24/2023-13:04:13] [V] [TRT] Tactic: 6 Time: 0.22976
[10/24/2023-13:04:14] [V] [TRT] Tactic: 56 Time: 0.565248
[10/24/2023-13:04:14] [V] [TRT] Tactic: 58 Time: 0.462576
[10/24/2023-13:04:14] [V] [TRT] Tactic: 62 Time: 0.229504
[10/24/2023-13:04:14] [V] [TRT] Fastest Tactic: 62 Time: 0.229504
[10/24/2023-13:04:14] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:14] [V] [TRT] Tactic: 254850674756030979 Time: 0.098028
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:14] [V] [TRT] Tactic: 328038211831149625 Time: 0.09536
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:14] [V] [TRT] Tactic: 411553864378931917 Time: 0.06912
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1011057357468998345 Time: 0.055936
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1156328698016730421 Time: 0.060056
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1723736032573714698 Time: 0.062464
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1832046141070096030 Time: 0.057344
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1838082074606840426 Time: 0.057344
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:14] [V] [TRT] Tactic: 1899296423087490472 Time: 0.069632
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2428167804343994714 Time: 0.068736
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2541579301352125276 Time: 0.059392
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2657157263811141609 Time: 0.070656
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2819719497590964443 Time: 0.064512
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2968605903460894194 Time: 0.057344
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:14] [V] [TRT] Tactic: 2986078304285316765 Time: 0.060928
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:14] [V] [TRT] Tactic: 3362537467505018070 Time: 0.05312
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:14] [V] [TRT] Tactic: 3513075359009385578 Time: 0.099456
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:14] [V] [TRT] Tactic: 3573559043797674382 Time: 0.058368
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:14] [V] [TRT] Tactic: 3591970081995419777 Time: 0.086656
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:14] [V] [TRT] Tactic: 3704534001553878387 Time: 0.056356
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:14] [V] [TRT] Tactic: 4278315135102886928 Time: 0.063
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:14] [V] [TRT] Tactic: 4503233883285355107 Time: 0.100224
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:14] [V] [TRT] Tactic: 4802447371470387646 Time: 0.0704
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5059676457552313631 Time: 0.09728
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5368829646735632944 Time: 0.087296
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5398999388616959893 Time: 0.057216
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5746691132547383910 Time: 0.06532
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5770170567977052602 Time: 0.0703
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:14] [V] [TRT] Tactic: 5953552212833506549 Time: 0.05224
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6034364043891107501 Time: 0.062868
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6074229447555668232 Time: 0.070656
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6154447660803990543 Time: 0.070784
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6325769668000961702 Time: 0.053248
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6350273239113254096 Time: 0.11868
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6377497238381488891 Time: 0.053248
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6446388116965632819 Time: 0.057744
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6468794451065529747 Time: 0.057776
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6642277870194067185 Time: 0.101024
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6859477213531075460 Time: 0.068752
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6972489290272968208 Time: 0.052224
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:14] [V] [TRT] Tactic: 6979044990896381511 Time: 0.09556
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:14] [V] [TRT] Tactic: 7216571380637776659 Time: 0.065556
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:14] [V] [TRT] Tactic: 7609923741161019135 Time: 0.056832
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:14] [V] [TRT] Tactic: 7705739241028240201 Time: 0.071568
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:14] [V] [TRT] Tactic: 8072087735545283117 Time: 0.09728
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:14] [V] [TRT] Tactic: 8101703987960976805 Time: 0.07208
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:14] [V] [TRT] Tactic: 8170606396342855895 Time: 0.057856
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:14] [V] [TRT] Tactic: 8839784824303350101 Time: 0.060032
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:14] [V] [TRT] Tactic: -9217371357561775773 Time: 0.072212
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:14] [V] [TRT] Tactic: -9009272790678027912 Time: 0.073984
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:14] [V] [TRT] Tactic: -8985224497679592364 Time: 0.101504
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:14] [V] [TRT] Tactic: -8949544755481315679 Time: 0.058368
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:14] [V] [TRT] Tactic: -8759929675070720385 Time: 0.053248
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:14] [V] [TRT] Tactic: -8604374562669615024 Time: 0.06976
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6902925267326201166 Time: 0.118152
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6840588038605932325 Time: 0.063232
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6799856376604253964 Time: 0.095232
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6625722781282978136 Time: 0.09024
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6525498856028268801 Time: 0.053252
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6356316196810535311 Time: 0.072832
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6324345858751792783 Time: 0.091532
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6262400699544994312 Time: 0.09536
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6257787336162086472 Time: 0.06056
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:14] [V] [TRT] Tactic: -6063766379489217211 Time: 0.057344
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5777580938094193096 Time: 0.063364
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5657273398217409378 Time: 0.09728
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5530886555766748586 Time: 0.059392
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5422685219138380548 Time: 0.06452
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5161596964442251102 Time: 0.064656
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:14] [V] [TRT] Tactic: -5127240325355316006 Time: 0.06336
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4825567853927730435 Time: 0.064512
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4796511246675321840 Time: 0.064284
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4706569565442112734 Time: 0.07296
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4566599693570369588 Time: 0.053248
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4409144516525410768 Time: 0.053248
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4379519430184503304 Time: 0.056448
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4152066959007262150 Time: 0.098304
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:14] [V] [TRT] Tactic: -4021926646879732549 Time: 0.062848
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3987638434926559037 Time: 0.064512
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3905653247016903130 Time: 0.058388
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3903974568488493144 Time: 0.06592
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3895429239811098010 Time: 0.06336
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3864869056275745423 Time: 0.067456
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3601464762214218301 Time: 0.068608
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:14] [V] [TRT] Tactic: -3412636942650049698 Time: 0.058392
[10/24/2023-13:04:14] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:15] [V] [TRT] Tactic: -3338665856053412950 Time: 0.052204
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:15] [V] [TRT] Tactic: -3058330359340425555 Time: 0.06516
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2816084650627734155 Time: 0.07348
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2662892962457732243 Time: 0.062468
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2559894581585337900 Time: 0.097812
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2530740716768816092 Time: 0.094848
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2332828394978346992 Time: 0.052224
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2241736083352441442 Time: 0.065536
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:15] [V] [TRT] Tactic: -2161909437867201546 Time: 0.116708
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:15] [V] [TRT] Tactic: -1985778916402815946 Time: 0.069632
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:15] [V] [TRT] Tactic: -1500496213132463076 Time: 0.0589
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:15] [V] [TRT] Tactic: -1099247066487349374 Time: 0.069632
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:15] [V] [TRT] Tactic: -910286698936744682 Time: 0.089216
[10/24/2023-13:04:15] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:15] [V] [TRT] Tactic: -606726295133751039 Time: 0.10138
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: -3338665856053412950 Time: 0.052204
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3338665856053412950
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CudnnConvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu (CaskConvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(1048576,1,16384,256) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(262144,1:4,4096,64) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(524288,4096:2,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Float(1048576,4096,64,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(131072,1:8,2048,32) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(65536,1:16,1024,16) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,4096,64,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.248216
[10/24/2023-13:04:15] [V] [TRT] Tactic: 1 Time: 0.172416
[10/24/2023-13:04:15] [V] [TRT] Tactic: 3 Time: 13.8611
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 1 Time: 0.172416
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.21696
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.21696
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnDeconvolution Tactic: 1
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,16384,256) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,4096,64) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1048576,4096,64,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.288512
[10/24/2023-13:04:15] [V] [TRT] Tactic: 1 Time: 0.86556
[10/24/2023-13:04:15] [V] [TRT] Tactic: 3 Time: 13.8375
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.288512
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.091392
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.091392
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,4096:2,64,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.13632
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.13632
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,2048,32) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.074624
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.074624
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,1024,16) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CudnnDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (GemmDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose (CaskDeconvolution)
[10/24/2023-13:04:15] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination:  -> Float(256,1,1,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination:  -> Half(256,1,1,1) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination:  -> Float(256,1,1,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination:  -> Half(256,1,1,1) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1), Float(256,1,1,1), Float(256,1,1,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256), Float(256,1,256,256), Float(256,1,256,256) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64), Float(64,1:4,64,64), Float(64,1:4,64,64) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(131072,16384:32,128,1), Float(8,1:32,1,1), Float(8,1:32,1,1) -> Float(131072,16384:32,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1:4,16384,128,1), Float(1:4,1,1,1), Float(1:4,1,1,1) -> Float(1:4,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1), Half(256,1,1,1), Half(256,1,1,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1), Half(128,1:2,1,1), Half(128,1:2,1,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32), Half(32,1:8,32,32), Half(32,1:8,32,32) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16), Half(16,1:16,16,16), Half(16,1:16,16,16) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(1:8,16384,128,1), Half(1:8,1,1,1), Half(1:8,1,1,1) -> Half(1:8,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.064256
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.064256
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.034832
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.034832
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.034944
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.034944
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 0 Time: 0.035196
[10/24/2023-13:04:15] [V] [TRT] Fastest Tactic: 0 Time: 0.035196
[10/24/2023-13:04:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu (Scale)
[10/24/2023-13:04:15] [V] [TRT] Scale has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:15] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:15] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:15] [V] [TRT] Tactic: 524287 Time: 0.530304
[10/24/2023-13:04:16] [V] [TRT] Tactic: 720895 Time: 0.512128
[10/24/2023-13:04:16] [V] [TRT] Tactic: 983039 Time: 0.486912
[10/24/2023-13:04:16] [V] [TRT] Tactic: 1048575 Time: 0.534656
[10/24/2023-13:04:16] [V] [TRT] Tactic: 1703935 Time: 0.45258
[10/24/2023-13:04:16] [V] [TRT] Tactic: 1769471 Time: 0.490624
[10/24/2023-13:04:16] [V] [TRT] Tactic: 1966079 Time: 0.588044
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2031615 Time: 0.654216
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2228223 Time: 0.556544
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2424831 Time: 0.58048
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2621439 Time: 0.472588
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2752511 Time: 0.450816
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2818047 Time: 0.912784
[10/24/2023-13:04:16] [V] [TRT] Tactic: 2883583 Time: 1.03643
[10/24/2023-13:04:16] [V] [TRT] Tactic: 3014655 Time: 0.469124
[10/24/2023-13:04:16] [V] [TRT] Tactic: 3145727 Time: 0.430464
[10/24/2023-13:04:16] [V] [TRT] Tactic: 3473407 Time: 0.89024
[10/24/2023-13:04:16] [V] [TRT] Tactic: 3604479 Time: 0.497172
[10/24/2023-13:04:16] [V] [TRT] Tactic: 3735551 Time: 0.867968
[10/24/2023-13:04:17] [V] [TRT] Tactic: 4390911 Time: 0.66816
[10/24/2023-13:04:17] [V] [TRT] Tactic: 5046271 Time: 0.538368
[10/24/2023-13:04:17] [V] [TRT] Tactic: 5963775 Time: 0.568456
[10/24/2023-13:04:17] [V] [TRT] Tactic: 6160383 Time: 0.573068
[10/24/2023-13:04:17] [V] [TRT] Tactic: 6488063 Time: 0.5559
[10/24/2023-13:04:17] [V] [TRT] Tactic: 6881279 Time: 0.544256
[10/24/2023-13:04:17] [V] [TRT] Tactic: 7274495 Time: 0.533888
[10/24/2023-13:04:17] [V] [TRT] Tactic: 7864319 Time: 0.496512
[10/24/2023-13:04:17] [V] [TRT] Tactic: 7995391 Time: 0.584432
[10/24/2023-13:04:17] [V] [TRT] Tactic: 8585215 Time: 0.484736
[10/24/2023-13:04:17] [V] [TRT] Tactic: 8847359 Time: 0.560128
[10/24/2023-13:04:17] [V] [TRT] Tactic: 8978431 Time: 0.518672
[10/24/2023-13:04:17] [V] [TRT] Tactic: 9043967 Time: 0.478212
[10/24/2023-13:04:17] [V] [TRT] Tactic: 9175039 Time: 0.497776
[10/24/2023-13:04:17] [V] [TRT] Tactic: 9502719 Time: 0.612748
[10/24/2023-13:04:17] [V] [TRT] Tactic: 9830399 Time: 0.963328
[10/24/2023-13:04:17] [V] [TRT] Tactic: 9961471 Time: 0.597248
[10/24/2023-13:04:17] [V] [TRT] Tactic: 10027007 Time: 0.527488
[10/24/2023-13:04:17] [V] [TRT] Tactic: 10092543 Time: 0.668448
[10/24/2023-13:04:18] [V] [TRT] Tactic: 10289151 Time: 0.587668
[10/24/2023-13:04:18] [V] [TRT] Tactic: 10485759 Time: 0.468992
[10/24/2023-13:04:18] [V] [TRT] Tactic: 10682367 Time: 0.464
[10/24/2023-13:04:18] [V] [TRT] Tactic: 10813439 Time: 0.510224
[10/24/2023-13:04:18] [V] [TRT] Fastest Tactic: 3145727 Time: 0.430464
[10/24/2023-13:04:18] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:18] [V] [TRT] Tactic: 0 Time: 1.6233
[10/24/2023-13:04:18] [V] [TRT] Tactic: 1 Time: 0.358532
[10/24/2023-13:04:18] [V] [TRT] Tactic: 2 Time: 1.9917
[10/24/2023-13:04:18] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17585799168, available: 4294967296
[10/24/2023-13:04:18] [V] [TRT] Tactic: 5 Time: 7.09696
[10/24/2023-13:04:18] [V] [TRT] Tactic: 6 Time: 0.364136
[10/24/2023-13:04:18] [V] [TRT] Tactic: 56 Time: 1.62317
[10/24/2023-13:04:18] [V] [TRT] Tactic: 57 Time: 0.360064
[10/24/2023-13:04:18] [V] [TRT] Tactic: 58 Time: 1.99348
[10/24/2023-13:04:18] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17585799168, available: 4294967296
[10/24/2023-13:04:18] [V] [TRT] Tactic: 61 Time: 7.10089
[10/24/2023-13:04:18] [V] [TRT] Tactic: 62 Time: 0.363748
[10/24/2023-13:04:18] [V] [TRT] Tactic: 112 Time: 1.62125
[10/24/2023-13:04:18] [V] [TRT] Tactic: 113 Time: 0.629376
[10/24/2023-13:04:18] [V] [TRT] Tactic: 114 Time: 1.99155
[10/24/2023-13:04:18] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17585799168, available: 4294967296
[10/24/2023-13:04:18] [V] [TRT] Tactic: 117 Time: 7.10012
[10/24/2023-13:04:18] [V] [TRT] Tactic: 118 Time: 0.36494
[10/24/2023-13:04:18] [V] [TRT] Fastest Tactic: 1 Time: 0.358532
[10/24/2023-13:04:18] [V] [TRT] Setting workspace to 17585799168enables more tactics for profiling
[10/24/2023-13:04:18] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:18] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:18] [V] [TRT] Tactic: 4549827808004681195 Time: 0.639232
[10/24/2023-13:04:18] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:18] [V] [TRT] Tactic: 5779835512569528575 Time: 1.08352
[10/24/2023-13:04:18] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:18] [V] [TRT] Tactic: 6053873026024413720 Time: 1.10694
[10/24/2023-13:04:18] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:18] [V] [TRT] Tactic: 6767548733843469815 Time: 0.611608
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:19] [V] [TRT] Tactic: -6313876406580483184 Time: 0.760844
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:19] [V] [TRT] Tactic: -1123676555321336786 Time: 1.09184
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:19] [V] [TRT] Tactic: -701551393537224327 Time: 0.660608
[10/24/2023-13:04:19] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 0.611608
[10/24/2023-13:04:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:04:19] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(1048576,1,8192,64) ***************
[10/24/2023-13:04:19] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:19] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:19] [V] [TRT] Tactic: 2086609538387166260 Time: 1.44553
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:19] [V] [TRT] Tactic: 2860655430572478466 Time: 0.62184
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:19] [V] [TRT] Tactic: 3239733199291090177 Time: 1.4463
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:19] [V] [TRT] Tactic: 4474630279712975759 Time: 0.653964
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:19] [V] [TRT] Tactic: 4479823862704990365 Time: 0.65308
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:19] [V] [TRT] Tactic: 4517590677127196184 Time: 2.24308
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:19] [V] [TRT] Tactic: 4634080872644479428 Time: 1.4426
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:19] [V] [TRT] Tactic: 4696204239951173149 Time: 0.623616
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:19] [V] [TRT] Tactic: 5778138195697110003 Time: 1.10208
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:19] [V] [TRT] Tactic: 6310198979346901507 Time: 1.38099
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:19] [V] [TRT] Tactic: 7155825427510256858 Time: 1.06522
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:19] [V] [TRT] Tactic: 7222247112373541608 Time: 0.952196
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:19] [V] [TRT] Tactic: 7472640475524677095 Time: 1.45984
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:19] [V] [TRT] Tactic: 8498373915030836990 Time: 2.41359
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:19] [V] [TRT] Tactic: 8869697132622550639 Time: 1.20166
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:19] [V] [TRT] Tactic: 8918020581761223752 Time: 1.05278
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:19] [V] [TRT] Tactic: -8937725997228636978 Time: 1.2576
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:19] [V] [TRT] Tactic: -8833858409138163072 Time: 2.24666
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:19] [V] [TRT] Tactic: -7989138351613022500 Time: 1.06522
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:19] [V] [TRT] Tactic: -7872883691240863058 Time: 1.43014
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:19] [V] [TRT] Tactic: -6729618519651721910 Time: 1.45283
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:19] [V] [TRT] Tactic: -5893833996418445881 Time: 1.23495
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:19] [V] [TRT] Tactic: -5701562095007058349 Time: 2.25792
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:19] [V] [TRT] Tactic: -5685503422376017600 Time: 0.946576
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:19] [V] [TRT] Tactic: -5521125187060117489 Time: 1.07622
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:19] [V] [TRT] Tactic: -4756382386362004279 Time: 0.6144
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:19] [V] [TRT] Tactic: -4615000974950361663 Time: 1.06086
[10/24/2023-13:04:19] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:20] [V] [TRT] Tactic: -4314913710375142296 Time: 1.0646
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:20] [V] [TRT] Tactic: -3855385237722507464 Time: 1.10926
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:20] [V] [TRT] Tactic: -3697587361057948972 Time: 0.945664
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:20] [V] [TRT] Tactic: -2809379259463049391 Time: 1.10221
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:20] [V] [TRT] Tactic: -2747929399988666512 Time: 2.21939
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:20] [V] [TRT] Tactic: -1472061967969061456 Time: 2.36032
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:20] [V] [TRT] Tactic: -504296718212024303 Time: 1.05741
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:20] [V] [TRT] Tactic: -444093195553988951 Time: 1.45983
[10/24/2023-13:04:20] [V] [TRT] Fastest Tactic: -4756382386362004279 Time: 0.6144
[10/24/2023-13:04:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4756382386362004279
[10/24/2023-13:04:20] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(262144,1:4,2048,16) ***************
[10/24/2023-13:04:20] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:20] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:20] [V] [TRT] Tactic: 2086609538387166260 Time: 1.44539
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:20] [V] [TRT] Tactic: 2860655430572478466 Time: 0.621952
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:20] [V] [TRT] Tactic: 3239733199291090177 Time: 1.44666
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:20] [V] [TRT] Tactic: 4474630279712975759 Time: 0.653576
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:20] [V] [TRT] Tactic: 4479823862704990365 Time: 0.6486
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:20] [V] [TRT] Tactic: 4517590677127196184 Time: 2.24051
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:20] [V] [TRT] Tactic: 4634080872644479428 Time: 1.44077
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:20] [V] [TRT] Tactic: 4696204239951173149 Time: 0.624
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:20] [V] [TRT] Tactic: 5778138195697110003 Time: 1.1021
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:20] [V] [TRT] Tactic: 6310198979346901507 Time: 1.3815
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:20] [V] [TRT] Tactic: 7155825427510256858 Time: 1.06507
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:20] [V] [TRT] Tactic: 7222247112373541608 Time: 0.95232
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:20] [V] [TRT] Tactic: 7342025736444949634 Time: 0.430592
[10/24/2023-13:04:20] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:21] [V] [TRT] Tactic: 7472640475524677095 Time: 1.45984
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:21] [V] [TRT] Tactic: 8498373915030836990 Time: 2.41101
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:21] [V] [TRT] Tactic: 8869697132622550639 Time: 1.20294
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:21] [V] [TRT] Tactic: 8918020581761223752 Time: 1.05291
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:21] [V] [TRT] Tactic: -8937725997228636978 Time: 1.25696
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:21] [V] [TRT] Tactic: -8833858409138163072 Time: 2.24321
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:21] [V] [TRT] Tactic: -7989138351613022500 Time: 1.0596
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:21] [V] [TRT] Tactic: -7872883691240863058 Time: 1.42915
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:21] [V] [TRT] Tactic: -7377458734869418330 Time: 0.396184
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:21] [V] [TRT] Tactic: -6729618519651721910 Time: 1.45135
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:21] [V] [TRT] Tactic: -5893833996418445881 Time: 1.23277
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:21] [V] [TRT] Tactic: -5701562095007058349 Time: 2.25587
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:21] [V] [TRT] Tactic: -5685503422376017600 Time: 0.946432
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:21] [V] [TRT] Tactic: -5521125187060117489 Time: 1.07406
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:21] [V] [TRT] Tactic: -5457304872213719461 Time: 0.395788
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:21] [V] [TRT] Tactic: -4756382386362004279 Time: 0.613912
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:21] [V] [TRT] Tactic: -4615000974950361663 Time: 1.05882
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:21] [V] [TRT] Tactic: -4314913710375142296 Time: 1.06534
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:21] [V] [TRT] Tactic: -3855385237722507464 Time: 1.10822
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:21] [V] [TRT] Tactic: -3697587361057948972 Time: 0.945036
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:21] [V] [TRT] Tactic: -2809379259463049391 Time: 1.10208
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:21] [V] [TRT] Tactic: -2747929399988666512 Time: 2.21722
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:21] [V] [TRT] Tactic: -1472061967969061456 Time: 2.36032
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:21] [V] [TRT] Tactic: -504296718212024303 Time: 1.05677
[10/24/2023-13:04:21] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:21] [V] [TRT] Tactic: -444093195553988951 Time: 1.45997
[10/24/2023-13:04:21] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.395788
[10/24/2023-13:04:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:04:21] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(1048576,16384,128,1) ***************
[10/24/2023-13:04:21] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:22] [V] [TRT] Tactic: 0 Time: 1.70253
[10/24/2023-13:04:22] [V] [TRT] Tactic: 1 Time: 0.917868
[10/24/2023-13:04:22] [V] [TRT] Tactic: 2 Time: 1.70304
[10/24/2023-13:04:22] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17585799168, available: 4294967296
[10/24/2023-13:04:22] [V] [TRT] Tactic: 5 Time: 7.07376
[10/24/2023-13:04:22] [V] [TRT] Tactic: 6 Time: 0.465408
[10/24/2023-13:04:22] [V] [TRT] Tactic: 56 Time: 1.70112
[10/24/2023-13:04:22] [V] [TRT] Tactic: 58 Time: 1.70163
[10/24/2023-13:04:22] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17585799168, available: 4294967296
[10/24/2023-13:04:22] [V] [TRT] Tactic: 61 Time: 7.07469
[10/24/2023-13:04:22] [V] [TRT] Tactic: 62 Time: 0.465152
[10/24/2023-13:04:22] [V] [TRT] Fastest Tactic: 62 Time: 0.465152
[10/24/2023-13:04:22] [V] [TRT] Setting workspace to 17585799168enables more tactics for profiling
[10/24/2023-13:04:22] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:22] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(524288,16384:2,128,1) ***************
[10/24/2023-13:04:22] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:22] [V] [TRT] Tactic: 524287 Time: 0.390528
[10/24/2023-13:04:22] [V] [TRT] Tactic: 720895 Time: 0.384128
[10/24/2023-13:04:22] [V] [TRT] Tactic: 983039 Time: 0.345724
[10/24/2023-13:04:23] [V] [TRT] Tactic: 1048575 Time: 0.339468
[10/24/2023-13:04:23] [V] [TRT] Tactic: 1703935 Time: 0.318464
[10/24/2023-13:04:23] [V] [TRT] Tactic: 1769471 Time: 0.346112
[10/24/2023-13:04:23] [V] [TRT] Tactic: 1966079 Time: 0.439424
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2031615 Time: 0.489856
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2228223 Time: 0.374144
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2424831 Time: 0.348568
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2621439 Time: 0.316828
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2752511 Time: 0.34586
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2818047 Time: 0.625304
[10/24/2023-13:04:23] [V] [TRT] Tactic: 2883583 Time: 0.758164
[10/24/2023-13:04:23] [V] [TRT] Tactic: 3014655 Time: 0.350496
[10/24/2023-13:04:23] [V] [TRT] Tactic: 3145727 Time: 0.327936
[10/24/2023-13:04:23] [V] [TRT] Tactic: 3473407 Time: 0.608384
[10/24/2023-13:04:23] [V] [TRT] Tactic: 3604479 Time: 0.348928
[10/24/2023-13:04:23] [V] [TRT] Tactic: 3735551 Time: 0.624384
[10/24/2023-13:04:23] [V] [TRT] Tactic: 4390911 Time: 0.472576
[10/24/2023-13:04:23] [V] [TRT] Tactic: 5046271 Time: 0.372616
[10/24/2023-13:04:23] [V] [TRT] Tactic: 5963775 Time: 0.394624
[10/24/2023-13:04:23] [V] [TRT] Tactic: 6160383 Time: 0.393344
[10/24/2023-13:04:23] [V] [TRT] Tactic: 6488063 Time: 0.415616
[10/24/2023-13:04:24] [V] [TRT] Tactic: 6881279 Time: 0.432784
[10/24/2023-13:04:24] [V] [TRT] Tactic: 7274495 Time: 0.340104
[10/24/2023-13:04:24] [V] [TRT] Tactic: 7864319 Time: 0.331904
[10/24/2023-13:04:24] [V] [TRT] Tactic: 7995391 Time: 0.418948
[10/24/2023-13:04:24] [V] [TRT] Tactic: 8585215 Time: 0.38068
[10/24/2023-13:04:24] [V] [TRT] Tactic: 8847359 Time: 0.336896
[10/24/2023-13:04:24] [V] [TRT] Tactic: 8978431 Time: 0.409216
[10/24/2023-13:04:24] [V] [TRT] Tactic: 9043967 Time: 0.345248
[10/24/2023-13:04:24] [V] [TRT] Tactic: 9175039 Time: 0.348928
[10/24/2023-13:04:24] [V] [TRT] Tactic: 9502719 Time: 0.468376
[10/24/2023-13:04:24] [V] [TRT] Tactic: 9830399 Time: 0.68096
[10/24/2023-13:04:24] [V] [TRT] Tactic: 9961471 Time: 0.357888
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10027007 Time: 0.348304
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10092543 Time: 0.47232
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10289151 Time: 0.439424
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10485759 Time: 0.331648
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10682367 Time: 0.318616
[10/24/2023-13:04:24] [V] [TRT] Tactic: 10813439 Time: 0.349568
[10/24/2023-13:04:24] [V] [TRT] Fastest Tactic: 2621439 Time: 0.316828
[10/24/2023-13:04:24] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:24] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:24] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:24] [V] [TRT] Tactic: 2195670545862694453 Time: 0.409344
[10/24/2023-13:04:24] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:24] [V] [TRT] Tactic: 3419182076704469245 Time: 0.405964
[10/24/2023-13:04:24] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:25] [V] [TRT] Tactic: 3891805945559659536 Time: 0.721664
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:25] [V] [TRT] Tactic: 5548126322150286555 Time: 0.401176
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:25] [V] [TRT] Tactic: 6057304366605292508 Time: 0.390932
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:25] [V] [TRT] Tactic: -7928611605886347652 Time: 0.738188
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:25] [V] [TRT] Tactic: -5172391392092686714 Time: 0.41024
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:25] [V] [TRT] Tactic: -4374269919094467161 Time: 0.40512
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:25] [V] [TRT] Tactic: -4083394051665370953 Time: 0.191872
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:25] [V] [TRT] Tactic: -1546027692247304867 Time: 0.720256
[10/24/2023-13:04:25] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.191872
[10/24/2023-13:04:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:25] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(1048576,16384,128,1) ***************
[10/24/2023-13:04:25] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:25] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:25] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:25] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:25] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(131072,1:8,1024,8) ***************
[10/24/2023-13:04:25] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:25] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:25] [V] [TRT] Tactic: 0 Time: 1.98336
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1 Time: 1.88825
[10/24/2023-13:04:25] [V] [TRT] Tactic: 2 Time: 3.85051
[10/24/2023-13:04:25] [V] [TRT] Tactic: 6 Time: 0.473968
[10/24/2023-13:04:25] [V] [TRT] Tactic: 56 Time: 2.01293
[10/24/2023-13:04:25] [V] [TRT] Tactic: 58 Time: 3.84888
[10/24/2023-13:04:25] [V] [TRT] Tactic: 62 Time: 0.473984
[10/24/2023-13:04:25] [V] [TRT] Fastest Tactic: 6 Time: 0.473968
[10/24/2023-13:04:25] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:25] [V] [TRT] Tactic: 254850674756030979 Time: 0.197904
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:25] [V] [TRT] Tactic: 328038211831149625 Time: 0.195356
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:25] [V] [TRT] Tactic: 411553864378931917 Time: 0.129664
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1011057357468998345 Time: 0.209792
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1156328698016730421 Time: 0.200192
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1723736032573714698 Time: 0.185856
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1832046141070096030 Time: 0.110208
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1838082074606840426 Time: 0.108928
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:25] [V] [TRT] Tactic: 1899296423087490472 Time: 0.124424
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:25] [V] [TRT] Tactic: 2428167804343994714 Time: 0.128128
[10/24/2023-13:04:25] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:26] [V] [TRT] Tactic: 2541579301352125276 Time: 0.203024
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:26] [V] [TRT] Tactic: 2657157263811141609 Time: 0.125184
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:26] [V] [TRT] Tactic: 2819719497590964443 Time: 0.19662
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:26] [V] [TRT] Tactic: 2968605903460894194 Time: 0.108676
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:26] [V] [TRT] Tactic: 2986078304285316765 Time: 0.20422
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:26] [V] [TRT] Tactic: 3362537467505018070 Time: 0.188928
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:26] [V] [TRT] Tactic: 3513075359009385578 Time: 0.195984
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:26] [V] [TRT] Tactic: 3573559043797674382 Time: 0.111488
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:26] [V] [TRT] Tactic: 3591970081995419777 Time: 0.163072
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:26] [V] [TRT] Tactic: 3704534001553878387 Time: 0.193536
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:26] [V] [TRT] Tactic: 4278315135102886928 Time: 0.19148
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:26] [V] [TRT] Tactic: 4503233883285355107 Time: 0.193152
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:26] [V] [TRT] Tactic: 4802447371470387646 Time: 0.135688
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5059676457552313631 Time: 0.193664
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5368829646735632944 Time: 0.162432
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5398999388616959893 Time: 0.122752
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5746691132547383910 Time: 0.195072
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5770170567977052602 Time: 0.135396
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:26] [V] [TRT] Tactic: 5953552212833506549 Time: 0.118528
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6034364043891107501 Time: 0.190592
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6074229447555668232 Time: 0.126472
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6154447660803990543 Time: 0.129408
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6325769668000961702 Time: 0.188048
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6350273239113254096 Time: 0.216196
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6377497238381488891 Time: 0.188316
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6446388116965632819 Time: 0.110852
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6468794451065529747 Time: 0.108184
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6642277870194067185 Time: 0.19776
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6859477213531075460 Time: 0.124576
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6972489290272968208 Time: 0.194432
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:26] [V] [TRT] Tactic: 6979044990896381511 Time: 0.19392
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:26] [V] [TRT] Tactic: 7216571380637776659 Time: 0.157592
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:26] [V] [TRT] Tactic: 7609923741161019135 Time: 0.10944
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:26] [V] [TRT] Tactic: 7705739241028240201 Time: 0.127616
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:26] [V] [TRT] Tactic: 8072087735545283117 Time: 0.36928
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:26] [V] [TRT] Tactic: 8101703987960976805 Time: 0.128
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:26] [V] [TRT] Tactic: 8170606396342855895 Time: 0.10816
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:26] [V] [TRT] Tactic: 8839784824303350101 Time: 0.14848
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:26] [V] [TRT] Tactic: -9217371357561775773 Time: 0.128028
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:26] [V] [TRT] Tactic: -9009272790678027912 Time: 0.14144
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:26] [V] [TRT] Tactic: -8985224497679592364 Time: 0.193792
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:26] [V] [TRT] Tactic: -8949544755481315679 Time: 0.110208
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:26] [V] [TRT] Tactic: -8759929675070720385 Time: 0.190724
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:26] [V] [TRT] Tactic: -8604374562669615024 Time: 0.125312
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6902925267326201166 Time: 0.216704
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6840588038605932325 Time: 0.192788
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6799856376604253964 Time: 0.360704
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6625722781282978136 Time: 0.175384
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6525498856028268801 Time: 0.123648
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6356316196810535311 Time: 0.128896
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6324345858751792783 Time: 0.17664
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6262400699544994312 Time: 0.361484
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6257787336162086472 Time: 0.200704
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:26] [V] [TRT] Tactic: -6063766379489217211 Time: 0.109824
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5777580938094193096 Time: 0.20314
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5657273398217409378 Time: 0.19776
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5530886555766748586 Time: 0.200852
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5422685219138380548 Time: 0.12288
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5161596964442251102 Time: 0.193152
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:26] [V] [TRT] Tactic: -5127240325355316006 Time: 0.19008
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:26] [V] [TRT] Tactic: -4825567853927730435 Time: 0.123416
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:26] [V] [TRT] Tactic: -4796511246675321840 Time: 0.194048
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:26] [V] [TRT] Tactic: -4706569565442112734 Time: 0.129024
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:26] [V] [TRT] Tactic: -4566599693570369588 Time: 0.187664
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:26] [V] [TRT] Tactic: -4409144516525410768 Time: 0.18882
[10/24/2023-13:04:26] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:27] [V] [TRT] Tactic: -4379519430184503304 Time: 0.109184
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:27] [V] [TRT] Tactic: -4152066959007262150 Time: 0.194176
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:27] [V] [TRT] Tactic: -4021926646879732549 Time: 0.191232
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3987638434926559037 Time: 0.193944
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3905653247016903130 Time: 0.125824
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3903974568488493144 Time: 0.126336
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3895429239811098010 Time: 0.191616
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3864869056275745423 Time: 0.130688
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3601464762214218301 Time: 0.123908
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3412636942650049698 Time: 0.125824
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3338665856053412950 Time: 0.11906
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:27] [V] [TRT] Tactic: -3058330359340425555 Time: 0.193164
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2816084650627734155 Time: 0.140416
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2662892962457732243 Time: 0.189312
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2559894581585337900 Time: 0.19598
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2530740716768816092 Time: 0.178696
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2332828394978346992 Time: 0.193664
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2241736083352441442 Time: 0.157208
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:27] [V] [TRT] Tactic: -2161909437867201546 Time: 0.215044
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:27] [V] [TRT] Tactic: -1985778916402815946 Time: 0.134272
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:27] [V] [TRT] Tactic: -1500496213132463076 Time: 0.109988
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:27] [V] [TRT] Tactic: -1099247066487349374 Time: 0.124928
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:27] [V] [TRT] Tactic: -910286698936744682 Time: 0.164864
[10/24/2023-13:04:27] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:27] [V] [TRT] Tactic: -606726295133751039 Time: 0.193556
[10/24/2023-13:04:27] [V] [TRT] Fastest Tactic: 8170606396342855895 Time: 0.10816
[10/24/2023-13:04:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8170606396342855895
[10/24/2023-13:04:27] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(65536,1:16,512,4) ***************
[10/24/2023-13:04:27] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CudnnConvolution)
[10/24/2023-13:04:27] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:27] [V] [TRT] --------------- Timing Runner: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu (CaskConvolution)
[10/24/2023-13:04:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:27] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:27] [V] [TRT] *************** Autotuning format combination: Float(1048576,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:27] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:27] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:27] [V] [TRT] Tactic: 524287 Time: 0.563712
[10/24/2023-13:04:27] [V] [TRT] Tactic: 720895 Time: 0.499092
[10/24/2023-13:04:27] [V] [TRT] Tactic: 983039 Time: 0.494208
[10/24/2023-13:04:27] [V] [TRT] Tactic: 1048575 Time: 0.524424
[10/24/2023-13:04:27] [V] [TRT] Tactic: 1703935 Time: 0.509716
[10/24/2023-13:04:27] [V] [TRT] Tactic: 1769471 Time: 0.691456
[10/24/2023-13:04:28] [V] [TRT] Tactic: 1966079 Time: 0.572416
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2031615 Time: 0.564352
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2228223 Time: 0.54324
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2424831 Time: 0.731392
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2621439 Time: 0.567056
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2752511 Time: 0.559628
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2818047 Time: 0.667416
[10/24/2023-13:04:28] [V] [TRT] Tactic: 2883583 Time: 0.742924
[10/24/2023-13:04:28] [V] [TRT] Tactic: 3014655 Time: 0.499472
[10/24/2023-13:04:28] [V] [TRT] Tactic: 3145727 Time: 0.536192
[10/24/2023-13:04:28] [V] [TRT] Tactic: 3473407 Time: 0.614528
[10/24/2023-13:04:28] [V] [TRT] Tactic: 3604479 Time: 0.53466
[10/24/2023-13:04:28] [V] [TRT] Tactic: 3735551 Time: 0.838656
[10/24/2023-13:04:28] [V] [TRT] Tactic: 4390911 Time: 0.688768
[10/24/2023-13:04:28] [V] [TRT] Tactic: 5046271 Time: 0.520832
[10/24/2023-13:04:28] [V] [TRT] Tactic: 5963775 Time: 0.560152
[10/24/2023-13:04:28] [V] [TRT] Tactic: 6160383 Time: 0.559232
[10/24/2023-13:04:28] [V] [TRT] Tactic: 6488063 Time: 0.501908
[10/24/2023-13:04:28] [V] [TRT] Tactic: 6881279 Time: 0.578048
[10/24/2023-13:04:29] [V] [TRT] Tactic: 7274495 Time: 0.627328
[10/24/2023-13:04:29] [V] [TRT] Tactic: 7864319 Time: 0.589076
[10/24/2023-13:04:29] [V] [TRT] Tactic: 7995391 Time: 0.50624
[10/24/2023-13:04:29] [V] [TRT] Tactic: 8585215 Time: 0.546572
[10/24/2023-13:04:29] [V] [TRT] Tactic: 8847359 Time: 0.783488
[10/24/2023-13:04:29] [V] [TRT] Tactic: 8978431 Time: 0.566528
[10/24/2023-13:04:29] [V] [TRT] Tactic: 9043967 Time: 0.499996
[10/24/2023-13:04:29] [V] [TRT] Tactic: 9175039 Time: 0.534912
[10/24/2023-13:04:29] [V] [TRT] Tactic: 9502719 Time: 0.60096
[10/24/2023-13:04:29] [V] [TRT] Tactic: 9830399 Time: 0.715008
[10/24/2023-13:04:29] [V] [TRT] Tactic: 9961471 Time: 0.742016
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10027007 Time: 0.50496
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10092543 Time: 0.683912
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10289151 Time: 0.572952
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10485759 Time: 0.509568
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10682367 Time: 0.546944
[10/24/2023-13:04:29] [V] [TRT] Tactic: 10813439 Time: 0.50304
[10/24/2023-13:04:29] [V] [TRT] Fastest Tactic: 983039 Time: 0.494208
[10/24/2023-13:04:29] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:29] [V] [TRT] Tactic: 0 Time: 0.909196
[10/24/2023-13:04:29] [V] [TRT] Tactic: 1 Time: 0.501864
[10/24/2023-13:04:29] [V] [TRT] Tactic: 2 Time: 0.924416
[10/24/2023-13:04:29] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17349083136, available: 4294967296
[10/24/2023-13:04:30] [V] [TRT] Tactic: 5 Time: 6.96456
[10/24/2023-13:04:30] [V] [TRT] Tactic: 6 Time: 0.58406
[10/24/2023-13:04:30] [V] [TRT] Tactic: 56 Time: 0.910164
[10/24/2023-13:04:30] [V] [TRT] Tactic: 57 Time: 0.505728
[10/24/2023-13:04:30] [V] [TRT] Tactic: 58 Time: 0.922624
[10/24/2023-13:04:30] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17349083136, available: 4294967296
[10/24/2023-13:04:30] [V] [TRT] Tactic: 61 Time: 6.97227
[10/24/2023-13:04:30] [V] [TRT] Tactic: 62 Time: 0.583576
[10/24/2023-13:04:30] [V] [TRT] Tactic: 112 Time: 0.907404
[10/24/2023-13:04:30] [V] [TRT] Tactic: 113 Time: 0.747904
[10/24/2023-13:04:30] [V] [TRT] Tactic: 114 Time: 0.925064
[10/24/2023-13:04:30] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17349083136, available: 4294967296
[10/24/2023-13:04:30] [V] [TRT] Tactic: 117 Time: 6.97534
[10/24/2023-13:04:30] [V] [TRT] Tactic: 118 Time: 0.584708
[10/24/2023-13:04:30] [V] [TRT] Fastest Tactic: 1 Time: 0.501864
[10/24/2023-13:04:30] [V] [TRT] Setting workspace to 17349083136enables more tactics for profiling
[10/24/2023-13:04:30] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4549827808004681195 Time: 0.517544
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:30] [V] [TRT] Tactic: 5779835512569528575 Time: 0.50228
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:30] [V] [TRT] Tactic: 6053873026024413720 Time: 0.550528
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:30] [V] [TRT] Tactic: 6767548733843469815 Time: 0.502288
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:30] [V] [TRT] Tactic: -6313876406580483184 Time: 0.574976
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:30] [V] [TRT] Tactic: -1123676555321336786 Time: 0.505728
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:30] [V] [TRT] Tactic: -701551393537224327 Time: 0.528388
[10/24/2023-13:04:30] [V] [TRT] Fastest Tactic: 5779835512569528575 Time: 0.50228
[10/24/2023-13:04:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 983039
[10/24/2023-13:04:30] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:30] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:30] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:30] [V] [TRT] Tactic: 2086609538387166260 Time: 0.597128
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:30] [V] [TRT] Tactic: 2860655430572478466 Time: 0.510992
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:30] [V] [TRT] Tactic: 3239733199291090177 Time: 0.598036
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4474630279712975759 Time: 0.541952
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4479823862704990365 Time: 0.533376
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4517590677127196184 Time: 0.518784
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4634080872644479428 Time: 0.68252
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:30] [V] [TRT] Tactic: 4696204239951173149 Time: 0.513156
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:30] [V] [TRT] Tactic: 5778138195697110003 Time: 0.5257
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:30] [V] [TRT] Tactic: 6310198979346901507 Time: 0.762112
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:30] [V] [TRT] Tactic: 7155825427510256858 Time: 0.511112
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:30] [V] [TRT] Tactic: 7222247112373541608 Time: 0.752404
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:30] [V] [TRT] Tactic: 7472640475524677095 Time: 0.686488
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:30] [V] [TRT] Tactic: 8498373915030836990 Time: 0.675328
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:30] [V] [TRT] Tactic: 8869697132622550639 Time: 1.00186
[10/24/2023-13:04:30] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:31] [V] [TRT] Tactic: 8918020581761223752 Time: 0.507136
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:31] [V] [TRT] Tactic: -8937725997228636978 Time: 0.701836
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:31] [V] [TRT] Tactic: -8833858409138163072 Time: 0.630656
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:31] [V] [TRT] Tactic: -7989138351613022500 Time: 0.824064
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:31] [V] [TRT] Tactic: -7872883691240863058 Time: 0.794496
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:31] [V] [TRT] Tactic: -6729618519651721910 Time: 0.694272
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5893833996418445881 Time: 0.960128
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5701562095007058349 Time: 0.636288
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5685503422376017600 Time: 0.750088
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5521125187060117489 Time: 0.833664
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:31] [V] [TRT] Tactic: -4756382386362004279 Time: 0.507136
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:31] [V] [TRT] Tactic: -4615000974950361663 Time: 0.82432
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:31] [V] [TRT] Tactic: -4314913710375142296 Time: 0.866304
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:31] [V] [TRT] Tactic: -3855385237722507464 Time: 0.530852
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:31] [V] [TRT] Tactic: -3697587361057948972 Time: 0.75264
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:31] [V] [TRT] Tactic: -2809379259463049391 Time: 0.529024
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:31] [V] [TRT] Tactic: -2747929399988666512 Time: 0.510464
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:31] [V] [TRT] Tactic: -1472061967969061456 Time: 0.552704
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:31] [V] [TRT] Tactic: -504296718212024303 Time: 0.507524
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:31] [V] [TRT] Tactic: -444093195553988951 Time: 0.595072
[10/24/2023-13:04:31] [V] [TRT] Fastest Tactic: 8918020581761223752 Time: 0.507136
[10/24/2023-13:04:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8918020581761223752
[10/24/2023-13:04:31] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,2048,16) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:31] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:31] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:31] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:31] [V] [TRT] Tactic: 2086609538387166260 Time: 0.597248
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:31] [V] [TRT] Tactic: 2860655430572478466 Time: 0.510848
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:31] [V] [TRT] Tactic: 3239733199291090177 Time: 0.597912
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:31] [V] [TRT] Tactic: 4474630279712975759 Time: 0.541952
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:31] [V] [TRT] Tactic: 4479823862704990365 Time: 0.533392
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:31] [V] [TRT] Tactic: 4517590677127196184 Time: 0.518272
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:31] [V] [TRT] Tactic: 4634080872644479428 Time: 0.684288
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:31] [V] [TRT] Tactic: 4696204239951173149 Time: 0.513152
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:31] [V] [TRT] Tactic: 5778138195697110003 Time: 0.525696
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:31] [V] [TRT] Tactic: 6310198979346901507 Time: 0.76212
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:31] [V] [TRT] Tactic: 7155825427510256858 Time: 0.511496
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:31] [V] [TRT] Tactic: 7222247112373541608 Time: 0.752768
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:31] [V] [TRT] Tactic: 7342025736444949634 Time: 0.257072
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:31] [V] [TRT] Tactic: 7472640475524677095 Time: 0.688028
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:31] [V] [TRT] Tactic: 8498373915030836990 Time: 0.676864
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:31] [V] [TRT] Tactic: 8869697132622550639 Time: 1.00021
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:31] [V] [TRT] Tactic: 8918020581761223752 Time: 0.506752
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:31] [V] [TRT] Tactic: -8937725997228636978 Time: 0.701464
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:31] [V] [TRT] Tactic: -8833858409138163072 Time: 0.630916
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:31] [V] [TRT] Tactic: -7989138351613022500 Time: 0.824192
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:31] [V] [TRT] Tactic: -7872883691240863058 Time: 0.79616
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:31] [V] [TRT] Tactic: -7377458734869418330 Time: 0.240772
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:31] [V] [TRT] Tactic: -6729618519651721910 Time: 0.694424
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5893833996418445881 Time: 0.960512
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5701562095007058349 Time: 0.635136
[10/24/2023-13:04:31] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:31] [V] [TRT] Tactic: -5685503422376017600 Time: 0.750976
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:32] [V] [TRT] Tactic: -5521125187060117489 Time: 0.834048
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:32] [V] [TRT] Tactic: -5457304872213719461 Time: 0.241932
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:32] [V] [TRT] Tactic: -4756382386362004279 Time: 0.508032
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:32] [V] [TRT] Tactic: -4615000974950361663 Time: 0.82472
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:32] [V] [TRT] Tactic: -4314913710375142296 Time: 0.866976
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:32] [V] [TRT] Tactic: -3855385237722507464 Time: 0.530596
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:32] [V] [TRT] Tactic: -3697587361057948972 Time: 0.749848
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:32] [V] [TRT] Tactic: -2809379259463049391 Time: 0.528768
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:32] [V] [TRT] Tactic: -2747929399988666512 Time: 0.510252
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:32] [V] [TRT] Tactic: -1472061967969061456 Time: 0.552448
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:32] [V] [TRT] Tactic: -504296718212024303 Time: 0.507904
[10/24/2023-13:04:32] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:32] [V] [TRT] Tactic: -444093195553988951 Time: 0.595084
[10/24/2023-13:04:32] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.240772
[10/24/2023-13:04:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[10/24/2023-13:04:32] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:32] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:32] [V] [TRT] Tactic: 0 Time: 0.890244
[10/24/2023-13:04:32] [V] [TRT] Tactic: 1 Time: 0.88936
[10/24/2023-13:04:32] [V] [TRT] Tactic: 2 Time: 0.773504
[10/24/2023-13:04:32] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17349083136, available: 4294967296
[10/24/2023-13:04:32] [V] [TRT] Tactic: 5 Time: 6.84554
[10/24/2023-13:04:32] [V] [TRT] Tactic: 6 Time: 0.580268
[10/24/2023-13:04:32] [V] [TRT] Tactic: 56 Time: 0.890368
[10/24/2023-13:04:32] [V] [TRT] Tactic: 58 Time: 0.77402
[10/24/2023-13:04:32] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17349083136, available: 4294967296
[10/24/2023-13:04:32] [V] [TRT] Tactic: 61 Time: 6.85016
[10/24/2023-13:04:32] [V] [TRT] Tactic: 62 Time: 0.579968
[10/24/2023-13:04:32] [V] [TRT] Fastest Tactic: 62 Time: 0.579968
[10/24/2023-13:04:32] [V] [TRT] Setting workspace to 17349083136enables more tactics for profiling
[10/24/2023-13:04:32] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:32] [V] [TRT] *************** Autotuning format combination: Half(524288,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:32] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:32] [V] [TRT] Tactic: 524287 Time: 0.343424
[10/24/2023-13:04:32] [V] [TRT] Tactic: 720895 Time: 0.331136
[10/24/2023-13:04:32] [V] [TRT] Tactic: 983039 Time: 0.3268
[10/24/2023-13:04:32] [V] [TRT] Tactic: 1048575 Time: 0.337796
[10/24/2023-13:04:32] [V] [TRT] Tactic: 1703935 Time: 0.337664
[10/24/2023-13:04:32] [V] [TRT] Tactic: 1769471 Time: 0.480512
[10/24/2023-13:04:32] [V] [TRT] Tactic: 1966079 Time: 0.35752
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2031615 Time: 0.346012
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2228223 Time: 0.337792
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2424831 Time: 0.515712
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2621439 Time: 0.37632
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2752511 Time: 0.34944
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2818047 Time: 0.362128
[10/24/2023-13:04:33] [V] [TRT] Tactic: 2883583 Time: 0.366856
[10/24/2023-13:04:33] [V] [TRT] Tactic: 3014655 Time: 0.337548
[10/24/2023-13:04:33] [V] [TRT] Tactic: 3145727 Time: 0.343424
[10/24/2023-13:04:33] [V] [TRT] Tactic: 3473407 Time: 0.33728
[10/24/2023-13:04:33] [V] [TRT] Tactic: 3604479 Time: 0.340224
[10/24/2023-13:04:33] [V] [TRT] Tactic: 3735551 Time: 0.435072
[10/24/2023-13:04:33] [V] [TRT] Tactic: 4390911 Time: 0.368664
[10/24/2023-13:04:33] [V] [TRT] Tactic: 5046271 Time: 0.344192
[10/24/2023-13:04:33] [V] [TRT] Tactic: 5963775 Time: 0.358528
[10/24/2023-13:04:33] [V] [TRT] Tactic: 6160383 Time: 0.361868
[10/24/2023-13:04:33] [V] [TRT] Tactic: 6488063 Time: 0.361748
[10/24/2023-13:04:33] [V] [TRT] Tactic: 6881279 Time: 0.34944
[10/24/2023-13:04:33] [V] [TRT] Tactic: 7274495 Time: 0.406296
[10/24/2023-13:04:33] [V] [TRT] Tactic: 7864319 Time: 0.41024
[10/24/2023-13:04:34] [V] [TRT] Tactic: 7995391 Time: 0.349312
[10/24/2023-13:04:34] [V] [TRT] Tactic: 8585215 Time: 0.34498
[10/24/2023-13:04:34] [V] [TRT] Tactic: 8847359 Time: 0.389384
[10/24/2023-13:04:34] [V] [TRT] Tactic: 8978431 Time: 0.35242
[10/24/2023-13:04:34] [V] [TRT] Tactic: 9043967 Time: 0.351504
[10/24/2023-13:04:34] [V] [TRT] Tactic: 9175039 Time: 0.33984
[10/24/2023-13:04:34] [V] [TRT] Tactic: 9502719 Time: 0.36352
[10/24/2023-13:04:34] [V] [TRT] Tactic: 9830399 Time: 0.359576
[10/24/2023-13:04:34] [V] [TRT] Tactic: 9961471 Time: 0.50048
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10027007 Time: 0.347008
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10092543 Time: 0.368128
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10289151 Time: 0.357888
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10485759 Time: 0.344064
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10682367 Time: 0.388608
[10/24/2023-13:04:34] [V] [TRT] Tactic: 10813439 Time: 0.331236
[10/24/2023-13:04:34] [V] [TRT] Fastest Tactic: 983039 Time: 0.3268
[10/24/2023-13:04:34] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:34] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:34] [V] [TRT] Tactic: 2195670545862694453 Time: 0.321408
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:34] [V] [TRT] Tactic: 3419182076704469245 Time: 0.311936
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:34] [V] [TRT] Tactic: 3891805945559659536 Time: 0.352896
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:34] [V] [TRT] Tactic: 5548126322150286555 Time: 0.30966
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:34] [V] [TRT] Tactic: 6057304366605292508 Time: 0.3072
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:34] [V] [TRT] Tactic: -7928611605886347652 Time: 0.36022
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:34] [V] [TRT] Tactic: -5172391392092686714 Time: 0.323084
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:34] [V] [TRT] Tactic: -4374269919094467161 Time: 0.318592
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:34] [V] [TRT] Tactic: -4083394051665370953 Time: 0.1837
[10/24/2023-13:04:34] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:34] [V] [TRT] Tactic: -1546027692247304867 Time: 0.349188
[10/24/2023-13:04:34] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.1837
[10/24/2023-13:04:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:34] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:34] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:34] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:34] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:35] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:35] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:35] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:35] [V] [TRT] Tactic: 0 Time: 0.957844
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1 Time: 1.82932
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2 Time: 0.900608
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6 Time: 0.585472
[10/24/2023-13:04:35] [V] [TRT] Tactic: 56 Time: 0.957952
[10/24/2023-13:04:35] [V] [TRT] Tactic: 58 Time: 0.900608
[10/24/2023-13:04:35] [V] [TRT] Tactic: 62 Time: 0.584328
[10/24/2023-13:04:35] [V] [TRT] Fastest Tactic: 62 Time: 0.584328
[10/24/2023-13:04:35] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:35] [V] [TRT] Tactic: 254850674756030979 Time: 0.136088
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:35] [V] [TRT] Tactic: 328038211831149625 Time: 0.132364
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:35] [V] [TRT] Tactic: 411553864378931917 Time: 0.142336
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1011057357468998345 Time: 0.112824
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1156328698016730421 Time: 0.102764
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1723736032573714698 Time: 0.12416
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1832046141070096030 Time: 0.126208
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1838082074606840426 Time: 0.129408
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:35] [V] [TRT] Tactic: 1899296423087490472 Time: 0.159748
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2428167804343994714 Time: 0.137344
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2541579301352125276 Time: 0.119728
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2657157263811141609 Time: 0.166024
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2819719497590964443 Time: 0.136336
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2968605903460894194 Time: 0.130588
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:35] [V] [TRT] Tactic: 2986078304285316765 Time: 0.122092
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:35] [V] [TRT] Tactic: 3362537467505018070 Time: 0.112768
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:35] [V] [TRT] Tactic: 3513075359009385578 Time: 0.133648
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:35] [V] [TRT] Tactic: 3573559043797674382 Time: 0.128128
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:35] [V] [TRT] Tactic: 3591970081995419777 Time: 0.182664
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:35] [V] [TRT] Tactic: 3704534001553878387 Time: 0.100352
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:35] [V] [TRT] Tactic: 4278315135102886928 Time: 0.124288
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:35] [V] [TRT] Tactic: 4503233883285355107 Time: 0.18228
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:35] [V] [TRT] Tactic: 4802447371470387646 Time: 0.14056
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5059676457552313631 Time: 0.134784
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5368829646735632944 Time: 0.173976
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5398999388616959893 Time: 0.120704
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5746691132547383910 Time: 0.132096
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5770170567977052602 Time: 0.142852
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:35] [V] [TRT] Tactic: 5953552212833506549 Time: 0.118164
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6034364043891107501 Time: 0.119936
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6074229447555668232 Time: 0.1568
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6154447660803990543 Time: 0.146448
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6325769668000961702 Time: 0.112792
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6350273239113254096 Time: 0.314128
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6377497238381488891 Time: 0.112284
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6446388116965632819 Time: 0.124816
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6468794451065529747 Time: 0.133016
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6642277870194067185 Time: 0.135424
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6859477213531075460 Time: 0.152048
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:35] [V] [TRT] Tactic: 6972489290272968208 Time: 0.106368
[10/24/2023-13:04:35] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:36] [V] [TRT] Tactic: 6979044990896381511 Time: 0.132372
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:36] [V] [TRT] Tactic: 7216571380637776659 Time: 0.111104
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:36] [V] [TRT] Tactic: 7609923741161019135 Time: 0.122624
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:36] [V] [TRT] Tactic: 7705739241028240201 Time: 0.16206
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:36] [V] [TRT] Tactic: 8072087735545283117 Time: 0.1344
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:36] [V] [TRT] Tactic: 8101703987960976805 Time: 0.168452
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:36] [V] [TRT] Tactic: 8170606396342855895 Time: 0.131872
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:36] [V] [TRT] Tactic: 8839784824303350101 Time: 0.107904
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:36] [V] [TRT] Tactic: -9217371357561775773 Time: 0.1696
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:36] [V] [TRT] Tactic: -9009272790678027912 Time: 0.146576
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:36] [V] [TRT] Tactic: -8985224497679592364 Time: 0.1856
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:36] [V] [TRT] Tactic: -8949544755481315679 Time: 0.13248
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:36] [V] [TRT] Tactic: -8759929675070720385 Time: 0.110208
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:36] [V] [TRT] Tactic: -8604374562669615024 Time: 0.15708
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6902925267326201166 Time: 0.30336
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6840588038605932325 Time: 0.125568
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6799856376604253964 Time: 0.13212
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6625722781282978136 Time: 0.18048
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6525498856028268801 Time: 0.118272
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6356316196810535311 Time: 0.174344
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6324345858751792783 Time: 0.182912
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6262400699544994312 Time: 0.13248
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6257787336162086472 Time: 0.103824
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:36] [V] [TRT] Tactic: -6063766379489217211 Time: 0.125312
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5777580938094193096 Time: 0.123776
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5657273398217409378 Time: 0.135168
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5530886555766748586 Time: 0.119552
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5422685219138380548 Time: 0.130316
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5161596964442251102 Time: 0.131604
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:36] [V] [TRT] Tactic: -5127240325355316006 Time: 0.120848
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4825567853927730435 Time: 0.132224
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4796511246675321840 Time: 0.134656
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4706569565442112734 Time: 0.175232
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4566599693570369588 Time: 0.112908
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4409144516525410768 Time: 0.112768
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4379519430184503304 Time: 0.121984
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4152066959007262150 Time: 0.133248
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:36] [V] [TRT] Tactic: -4021926646879732549 Time: 0.124684
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3987638434926559037 Time: 0.135296
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3905653247016903130 Time: 0.123268
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3903974568488493144 Time: 0.131328
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3895429239811098010 Time: 0.12162
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3864869056275745423 Time: 0.138496
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3601464762214218301 Time: 0.150272
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3412636942650049698 Time: 0.124036
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3338665856053412950 Time: 0.11828
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:36] [V] [TRT] Tactic: -3058330359340425555 Time: 0.1312
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2816084650627734155 Time: 0.14592
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2662892962457732243 Time: 0.126976
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2559894581585337900 Time: 0.135936
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2530740716768816092 Time: 0.18358
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2332828394978346992 Time: 0.107024
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2241736083352441442 Time: 0.111
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:36] [V] [TRT] Tactic: -2161909437867201546 Time: 0.284416
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:36] [V] [TRT] Tactic: -1985778916402815946 Time: 0.142084
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:36] [V] [TRT] Tactic: -1500496213132463076 Time: 0.13504
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:36] [V] [TRT] Tactic: -1099247066487349374 Time: 0.155184
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:36] [V] [TRT] Tactic: -910286698936744682 Time: 0.186752
[10/24/2023-13:04:36] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:36] [V] [TRT] Tactic: -606726295133751039 Time: 0.182784
[10/24/2023-13:04:36] [V] [TRT] Fastest Tactic: 3704534001553878387 Time: 0.100352
[10/24/2023-13:04:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3704534001553878387
[10/24/2023-13:04:36] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,512,4) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:36] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:36] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:36] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:36] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:36] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:36] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:37] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:37] [V] [TRT] Tactic: 524287 Time: 0.04622
[10/24/2023-13:04:37] [V] [TRT] Tactic: 720895 Time: 0.068624
[10/24/2023-13:04:37] [V] [TRT] Tactic: 983039 Time: 0.06658
[10/24/2023-13:04:37] [V] [TRT] Tactic: 1048575 Time: 0.043008
[10/24/2023-13:04:37] [V] [TRT] Tactic: 1703935 Time: 0.040704
[10/24/2023-13:04:37] [V] [TRT] Tactic: 1769471 Time: 0.072704
[10/24/2023-13:04:37] [V] [TRT] Tactic: 1966079 Time: 0.078856
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2031615 Time: 0.086016
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2228223 Time: 0.049152
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2424831 Time: 0.050176
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2621439 Time: 0.038064
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2752511 Time: 0.061184
[10/24/2023-13:04:37] [V] [TRT] Tactic: 3014655 Time: 0.045036
[10/24/2023-13:04:37] [V] [TRT] Tactic: 3145727 Time: 0.060588
[10/24/2023-13:04:37] [V] [TRT] Tactic: 3604479 Time: 0.047496
[10/24/2023-13:04:37] [V] [TRT] Tactic: 4390911 Time: 0.08896
[10/24/2023-13:04:37] [V] [TRT] Tactic: 5046271 Time: 0.04124
[10/24/2023-13:04:37] [V] [TRT] Tactic: 5963775 Time: 0.0717
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6160383 Time: 0.045056
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6488063 Time: 0.046976
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6881279 Time: 0.072968
[10/24/2023-13:04:37] [V] [TRT] Tactic: 7274495 Time: 0.068352
[10/24/2023-13:04:37] [V] [TRT] Tactic: 7864319 Time: 0.039808
[10/24/2023-13:04:37] [V] [TRT] Tactic: 7995391 Time: 0.078088
[10/24/2023-13:04:37] [V] [TRT] Tactic: 8585215 Time: 0.051328
[10/24/2023-13:04:37] [V] [TRT] Tactic: 8847359 Time: 0.052096
[10/24/2023-13:04:37] [V] [TRT] Tactic: 8978431 Time: 0.0736
[10/24/2023-13:04:37] [V] [TRT] Tactic: 9043967 Time: 0.041984
[10/24/2023-13:04:37] [V] [TRT] Tactic: 9175039 Time: 0.047
[10/24/2023-13:04:37] [V] [TRT] Tactic: 9502719 Time: 0.08384
[10/24/2023-13:04:37] [V] [TRT] Tactic: 9961471 Time: 0.047104
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10027007 Time: 0.038912
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10092543 Time: 0.08896
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10289151 Time: 0.078976
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10485759 Time: 0.040076
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10682367 Time: 0.037396
[10/24/2023-13:04:37] [V] [TRT] Tactic: 10813439 Time: 0.070144
[10/24/2023-13:04:37] [V] [TRT] Fastest Tactic: 10682367 Time: 0.037396
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:37] [V] [TRT] Tactic: 0 Time: 0.093324
[10/24/2023-13:04:37] [V] [TRT] Tactic: 1 Time: 0.093184
[10/24/2023-13:04:37] [V] [TRT] Tactic: 2 Time: 0.093204
[10/24/2023-13:04:37] [V] [TRT] Tactic: 4 Time: 0.605292
[10/24/2023-13:04:37] [V] [TRT] Tactic: 5 Time: 0.287856
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6 Time: 0.035848
[10/24/2023-13:04:37] [V] [TRT] Tactic: 56 Time: 0.09334
[10/24/2023-13:04:37] [V] [TRT] Tactic: 57 Time: 0.093188
[10/24/2023-13:04:37] [V] [TRT] Tactic: 58 Time: 0.093324
[10/24/2023-13:04:37] [V] [TRT] Tactic: 60 Time: 0.604244
[10/24/2023-13:04:37] [V] [TRT] Tactic: 61 Time: 0.269688
[10/24/2023-13:04:37] [V] [TRT] Tactic: 62 Time: 0.035916
[10/24/2023-13:04:37] [V] [TRT] Tactic: 112 Time: 0.093312
[10/24/2023-13:04:37] [V] [TRT] Tactic: 113 Time: 0.093184
[10/24/2023-13:04:37] [V] [TRT] Tactic: 114 Time: 0.0932
[10/24/2023-13:04:37] [V] [TRT] Tactic: 116 Time: 0.605276
[10/24/2023-13:04:37] [V] [TRT] Tactic: 117 Time: 0.280944
[10/24/2023-13:04:37] [V] [TRT] Tactic: 118 Time: 0.035872
[10/24/2023-13:04:37] [V] [TRT] Fastest Tactic: 6 Time: 0.035848
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:37] [V] [TRT] Tactic: 4549827808004681195 Time: 0.089088
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:37] [V] [TRT] Tactic: 5779835512569528575 Time: 0.146944
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6053873026024413720 Time: 0.153216
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:37] [V] [TRT] Tactic: 6767548733843469815 Time: 0.08616
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:37] [V] [TRT] Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:37] [V] [TRT] Tactic: -1123676555321336786 Time: 0.147728
[10/24/2023-13:04:37] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:37] [V] [TRT] Tactic: -701551393537224327 Time: 0.091704
[10/24/2023-13:04:37] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[10/24/2023-13:04:37] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:37] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:37] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:37] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:38] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:38] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:38] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2086609538387166260 Time: 0.188416
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2860655430572478466 Time: 0.086532
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:38] [V] [TRT] Tactic: 3239733199291090177 Time: 0.188416
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4474630279712975759 Time: 0.0512
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050816
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4517590677127196184 Time: 0.289928
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188416
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4696204239951173149 Time: 0.087044
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:38] [V] [TRT] Tactic: 5778138195697110003 Time: 0.146048
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:38] [V] [TRT] Tactic: 6310198979346901507 Time: 0.182912
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7155825427510256858 Time: 0.142352
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7222247112373541608 Time: 0.124032
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7342025736444949634 Time: 0.062976
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7472640475524677095 Time: 0.191616
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:38] [V] [TRT] Tactic: 8498373915030836990 Time: 0.313856
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:38] [V] [TRT] Tactic: 8869697132622550639 Time: 0.159372
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:38] [V] [TRT] Tactic: 8918020581761223752 Time: 0.141184
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:38] [V] [TRT] Tactic: -8937725997228636978 Time: 0.16576
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:38] [V] [TRT] Tactic: -8833858409138163072 Time: 0.292888
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:38] [V] [TRT] Tactic: -7989138351613022500 Time: 0.1384
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:38] [V] [TRT] Tactic: -7872883691240863058 Time: 0.188544
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:38] [V] [TRT] Tactic: -7377458734869418330 Time: 0.058368
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:38] [V] [TRT] Tactic: -6729618519651721910 Time: 0.189184
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:38] [V] [TRT] Tactic: -5893833996418445881 Time: 0.162816
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:38] [V] [TRT] Tactic: -5701562095007058349 Time: 0.295172
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:38] [V] [TRT] Tactic: -5685503422376017600 Time: 0.121728
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:38] [V] [TRT] Tactic: -5521125187060117489 Time: 0.140416
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:38] [V] [TRT] Tactic: -5457304872213719461 Time: 0.058516
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:38] [V] [TRT] Tactic: -4756382386362004279 Time: 0.086016
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:38] [V] [TRT] Tactic: -4615000974950361663 Time: 0.139136
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:38] [V] [TRT] Tactic: -4314913710375142296 Time: 0.139016
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:38] [V] [TRT] Tactic: -3855385237722507464 Time: 0.147456
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:38] [V] [TRT] Tactic: -3697587361057948972 Time: 0.120964
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:38] [V] [TRT] Tactic: -2809379259463049391 Time: 0.146432
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:38] [V] [TRT] Tactic: -2747929399988666512 Time: 0.287104
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:38] [V] [TRT] Tactic: -1472061967969061456 Time: 0.307456
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:38] [V] [TRT] Tactic: -504296718212024303 Time: 0.14132
[10/24/2023-13:04:38] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:38] [V] [TRT] Tactic: -444093195553988951 Time: 0.190852
[10/24/2023-13:04:38] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050816
[10/24/2023-13:04:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[10/24/2023-13:04:38] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:38] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:38] [V] [TRT] Tactic: 0 Time: 0.098304
[10/24/2023-13:04:38] [V] [TRT] Tactic: 1 Time: 0.09806
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2 Time: 0.098304
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4 Time: 0.604772
[10/24/2023-13:04:38] [V] [TRT] Tactic: 5 Time: 0.331148
[10/24/2023-13:04:38] [V] [TRT] Tactic: 6 Time: 0.541952
[10/24/2023-13:04:38] [V] [TRT] Tactic: 56 Time: 0.098304
[10/24/2023-13:04:38] [V] [TRT] Tactic: 58 Time: 0.098048
[10/24/2023-13:04:38] [V] [TRT] Tactic: 60 Time: 0.604032
[10/24/2023-13:04:38] [V] [TRT] Tactic: 61 Time: 0.368152
[10/24/2023-13:04:38] [V] [TRT] Tactic: 62 Time: 0.541312
[10/24/2023-13:04:38] [V] [TRT] Fastest Tactic: 58 Time: 0.098048
[10/24/2023-13:04:38] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:38] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 58
[10/24/2023-13:04:38] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:38] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:38] [V] [TRT] Tactic: 524287 Time: 0.034816
[10/24/2023-13:04:38] [V] [TRT] Tactic: 720895 Time: 0.053376
[10/24/2023-13:04:38] [V] [TRT] Tactic: 983039 Time: 0.050048
[10/24/2023-13:04:38] [V] [TRT] Tactic: 1048575 Time: 0.033792
[10/24/2023-13:04:38] [V] [TRT] Tactic: 1703935 Time: 0.028672
[10/24/2023-13:04:38] [V] [TRT] Tactic: 1769471 Time: 0.0562
[10/24/2023-13:04:38] [V] [TRT] Tactic: 1966079 Time: 0.058368
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2031615 Time: 0.066784
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2228223 Time: 0.036864
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2424831 Time: 0.038984
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2621439 Time: 0.029224
[10/24/2023-13:04:38] [V] [TRT] Tactic: 2752511 Time: 0.048768
[10/24/2023-13:04:38] [V] [TRT] Tactic: 3014655 Time: 0.03072
[10/24/2023-13:04:38] [V] [TRT] Tactic: 3145727 Time: 0.047104
[10/24/2023-13:04:38] [V] [TRT] Tactic: 3604479 Time: 0.030488
[10/24/2023-13:04:38] [V] [TRT] Tactic: 4390911 Time: 0.064484
[10/24/2023-13:04:38] [V] [TRT] Tactic: 5046271 Time: 0.031764
[10/24/2023-13:04:38] [V] [TRT] Tactic: 5963775 Time: 0.054272
[10/24/2023-13:04:38] [V] [TRT] Tactic: 6160383 Time: 0.032768
[10/24/2023-13:04:38] [V] [TRT] Tactic: 6488063 Time: 0.040092
[10/24/2023-13:04:38] [V] [TRT] Tactic: 6881279 Time: 0.058624
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7274495 Time: 0.050176
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7864319 Time: 0.030592
[10/24/2023-13:04:38] [V] [TRT] Tactic: 7995391 Time: 0.056832
[10/24/2023-13:04:39] [V] [TRT] Tactic: 8585215 Time: 0.039936
[10/24/2023-13:04:39] [V] [TRT] Tactic: 8847359 Time: 0.033536
[10/24/2023-13:04:39] [V] [TRT] Tactic: 8978431 Time: 0.053528
[10/24/2023-13:04:39] [V] [TRT] Tactic: 9043967 Time: 0.032512
[10/24/2023-13:04:39] [V] [TRT] Tactic: 9175039 Time: 0.030592
[10/24/2023-13:04:39] [V] [TRT] Tactic: 9502719 Time: 0.064512
[10/24/2023-13:04:39] [V] [TRT] Tactic: 9961471 Time: 0.036864
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10027007 Time: 0.030592
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10092543 Time: 0.064384
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10289151 Time: 0.058368
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10485759 Time: 0.028672
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10682367 Time: 0.029184
[10/24/2023-13:04:39] [V] [TRT] Tactic: 10813439 Time: 0.050048
[10/24/2023-13:04:39] [V] [TRT] Fastest Tactic: 1703935 Time: 0.028672
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2195670545862694453 Time: 0.040216
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3419182076704469245 Time: 0.058368
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3891805945559659536 Time: 0.101248
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5548126322150286555 Time: 0.057388
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6057304366605292508 Time: 0.05632
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:39] [V] [TRT] Tactic: -7928611605886347652 Time: 0.10332
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:39] [V] [TRT] Tactic: -5172391392092686714 Time: 0.041216
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:39] [V] [TRT] Tactic: -4374269919094467161 Time: 0.036864
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:39] [V] [TRT] Tactic: -4083394051665370953 Time: 0.020488
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:39] [V] [TRT] Tactic: -1546027692247304867 Time: 0.100736
[10/24/2023-13:04:39] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.020488
[10/24/2023-13:04:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:39] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:39] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:39] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:39] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:39] [V] [TRT] Tactic: 254850674756030979 Time: 0.031616
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:39] [V] [TRT] Tactic: 328038211831149625 Time: 0.03072
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:39] [V] [TRT] Tactic: 411553864378931917 Time: 0.022528
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1011057357468998345 Time: 0.034688
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1156328698016730421 Time: 0.032768
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1723736032573714698 Time: 0.033792
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1832046141070096030 Time: 0.0224
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1838082074606840426 Time: 0.022536
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:39] [V] [TRT] Tactic: 1899296423087490472 Time: 0.02752
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2428167804343994714 Time: 0.021504
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033792
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2657157263811141609 Time: 0.028412
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2819719497590964443 Time: 0.041728
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2968605903460894194 Time: 0.022568
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:39] [V] [TRT] Tactic: 2986078304285316765 Time: 0.033796
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3362537467505018070 Time: 0.033664
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3513075359009385578 Time: 0.031744
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3573559043797674382 Time: 0.022528
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3591970081995419777 Time: 0.024576
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:39] [V] [TRT] Tactic: 3704534001553878387 Time: 0.031616
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:39] [V] [TRT] Tactic: 4278315135102886928 Time: 0.036864
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:39] [V] [TRT] Tactic: 4503233883285355107 Time: 0.016384
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:39] [V] [TRT] Tactic: 4802447371470387646 Time: 0.02228
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5059676457552313631 Time: 0.031616
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5368829646735632944 Time: 0.026496
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5398999388616959893 Time: 0.020748
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5746691132547383910 Time: 0.04032
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5770170567977052602 Time: 0.022688
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:39] [V] [TRT] Tactic: 5953552212833506549 Time: 0.019456
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6034364043891107501 Time: 0.035968
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6074229447555668232 Time: 0.02752
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6154447660803990543 Time: 0.022784
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6325769668000961702 Time: 0.033792
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6350273239113254096 Time: 0.022656
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6377497238381488891 Time: 0.033576
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6446388116965632819 Time: 0.022408
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6468794451065529747 Time: 0.023424
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6642277870194067185 Time: 0.03264
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6859477213531075460 Time: 0.026496
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6972489290272968208 Time: 0.032652
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:39] [V] [TRT] Tactic: 6979044990896381511 Time: 0.03072
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:39] [V] [TRT] Tactic: 7216571380637776659 Time: 0.02238
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:39] [V] [TRT] Tactic: 7609923741161019135 Time: 0.021504
[10/24/2023-13:04:39] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:40] [V] [TRT] Tactic: 7705739241028240201 Time: 0.028672
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8072087735545283117 Time: 0.05632
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8101703987960976805 Time: 0.02944
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8170606396342855895 Time: 0.02304
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8839784824303350101 Time: 0.020516
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:40] [V] [TRT] Tactic: -9217371357561775773 Time: 0.029696
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:40] [V] [TRT] Tactic: -9009272790678027912 Time: 0.023424
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:40] [V] [TRT] Tactic: -8985224497679592364 Time: 0.0164
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:40] [V] [TRT] Tactic: -8949544755481315679 Time: 0.023424
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:40] [V] [TRT] Tactic: -8759929675070720385 Time: 0.032768
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:40] [V] [TRT] Tactic: -8604374562669615024 Time: 0.02752
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6902925267326201166 Time: 0.022148
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6840588038605932325 Time: 0.037888
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6799856376604253964 Time: 0.055424
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6625722781282978136 Time: 0.016128
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6525498856028268801 Time: 0.019484
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6356316196810535311 Time: 0.030096
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6324345858751792783 Time: 0.016256
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6262400699544994312 Time: 0.055296
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6257787336162086472 Time: 0.032768
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:40] [V] [TRT] Tactic: -6063766379489217211 Time: 0.02154
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5777580938094193096 Time: 0.03648
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5657273398217409378 Time: 0.03072
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5530886555766748586 Time: 0.033304
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5422685219138380548 Time: 0.02048
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5161596964442251102 Time: 0.039812
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:40] [V] [TRT] Tactic: -5127240325355316006 Time: 0.03648
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4825567853927730435 Time: 0.021376
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4796511246675321840 Time: 0.04096
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4706569565442112734 Time: 0.03072
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4566599693570369588 Time: 0.033792
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4409144516525410768 Time: 0.033792
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4379519430184503304 Time: 0.02152
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4152066959007262150 Time: 0.031736
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:40] [V] [TRT] Tactic: -4021926646879732549 Time: 0.03776
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3987638434926559037 Time: 0.04096
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3905653247016903130 Time: 0.021504
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3903974568488493144 Time: 0.022528
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3895429239811098010 Time: 0.036864
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3864869056275745423 Time: 0.021528
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3601464762214218301 Time: 0.0256
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3412636942650049698 Time: 0.021504
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3338665856053412950 Time: 0.019328
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:40] [V] [TRT] Tactic: -3058330359340425555 Time: 0.039816
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2816084650627734155 Time: 0.023292
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034816
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2559894581585337900 Time: 0.031616
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2530740716768816092 Time: 0.017408
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2332828394978346992 Time: 0.032512
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2241736083352441442 Time: 0.022528
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:40] [V] [TRT] Tactic: -2161909437867201546 Time: 0.0224
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:40] [V] [TRT] Tactic: -1985778916402815946 Time: 0.0224
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:40] [V] [TRT] Tactic: -1500496213132463076 Time: 0.023688
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:40] [V] [TRT] Tactic: -1099247066487349374 Time: 0.026624
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:40] [V] [TRT] Tactic: -910286698936744682 Time: 0.026624
[10/24/2023-13:04:40] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:40] [V] [TRT] Tactic: -606726295133751039 Time: 0.016384
[10/24/2023-13:04:40] [V] [TRT] Fastest Tactic: -6625722781282978136 Time: 0.016128
[10/24/2023-13:04:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6625722781282978136
[10/24/2023-13:04:40] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:40] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CudnnConvolution)
[10/24/2023-13:04:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:40] [V] [TRT] --------------- Timing Runner: /heads_list.0/center/center.1/Conv (CaskConvolution)
[10/24/2023-13:04:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:40] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:40] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:40] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:40] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:40] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:40] [V] [TRT] Tactic: 524287 Time: 0.046244
[10/24/2023-13:04:40] [V] [TRT] Tactic: 1048575 Time: 0.042988
[10/24/2023-13:04:40] [V] [TRT] Tactic: 1703935 Time: 0.04096
[10/24/2023-13:04:40] [V] [TRT] Tactic: 2228223 Time: 0.049152
[10/24/2023-13:04:40] [V] [TRT] Tactic: 2424831 Time: 0.050048
[10/24/2023-13:04:40] [V] [TRT] Tactic: 2621439 Time: 0.037996
[10/24/2023-13:04:40] [V] [TRT] Tactic: 3014655 Time: 0.045056
[10/24/2023-13:04:40] [V] [TRT] Tactic: 3604479 Time: 0.04686
[10/24/2023-13:04:40] [V] [TRT] Tactic: 5046271 Time: 0.041132
[10/24/2023-13:04:40] [V] [TRT] Tactic: 6160383 Time: 0.044316
[10/24/2023-13:04:40] [V] [TRT] Tactic: 6488063 Time: 0.047104
[10/24/2023-13:04:40] [V] [TRT] Tactic: 7864319 Time: 0.03966
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8585215 Time: 0.050324
[10/24/2023-13:04:40] [V] [TRT] Tactic: 8847359 Time: 0.052096
[10/24/2023-13:04:40] [V] [TRT] Tactic: 9043967 Time: 0.041984
[10/24/2023-13:04:41] [V] [TRT] Tactic: 9175039 Time: 0.047616
[10/24/2023-13:04:41] [V] [TRT] Tactic: 9961471 Time: 0.047132
[10/24/2023-13:04:41] [V] [TRT] Tactic: 10027007 Time: 0.038912
[10/24/2023-13:04:41] [V] [TRT] Tactic: 10485759 Time: 0.0389
[10/24/2023-13:04:41] [V] [TRT] Tactic: 10682367 Time: 0.037144
[10/24/2023-13:04:41] [V] [TRT] Fastest Tactic: 10682367 Time: 0.037144
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:41] [V] [TRT] Tactic: 0 Time: 0.093184
[10/24/2023-13:04:41] [V] [TRT] Tactic: 1 Time: 0.088708
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2 Time: 0.093312
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4 Time: 0.427928
[10/24/2023-13:04:41] [V] [TRT] Tactic: 5 Time: 0.244812
[10/24/2023-13:04:41] [V] [TRT] Tactic: 6 Time: 0.035968
[10/24/2023-13:04:41] [V] [TRT] Tactic: 56 Time: 0.093164
[10/24/2023-13:04:41] [V] [TRT] Tactic: 57 Time: 0.088604
[10/24/2023-13:04:41] [V] [TRT] Tactic: 58 Time: 0.093184
[10/24/2023-13:04:41] [V] [TRT] Tactic: 60 Time: 0.428276
[10/24/2023-13:04:41] [V] [TRT] Tactic: 61 Time: 0.230524
[10/24/2023-13:04:41] [V] [TRT] Tactic: 62 Time: 0.03584
[10/24/2023-13:04:41] [V] [TRT] Tactic: 112 Time: 0.093312
[10/24/2023-13:04:41] [V] [TRT] Tactic: 113 Time: 0.093056
[10/24/2023-13:04:41] [V] [TRT] Tactic: 114 Time: 0.093184
[10/24/2023-13:04:41] [V] [TRT] Tactic: 116 Time: 0.427264
[10/24/2023-13:04:41] [V] [TRT] Tactic: 117 Time: 0.271336
[10/24/2023-13:04:41] [V] [TRT] Tactic: 118 Time: 0.03584
[10/24/2023-13:04:41] [V] [TRT] Fastest Tactic: 62 Time: 0.03584
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4549827808004681195 Time: 0.089088
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:41] [V] [TRT] Tactic: 5779835512569528575 Time: 0.146556
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:41] [V] [TRT] Tactic: 6053873026024413720 Time: 0.152984
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:41] [V] [TRT] Tactic: 6767548733843469815 Time: 0.086032
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:41] [V] [TRT] Tactic: -6313876406580483184 Time: 0.076672
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:41] [V] [TRT] Tactic: -1123676555321336786 Time: 0.1476
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:41] [V] [TRT] Tactic: -701551393537224327 Time: 0.091912
[10/24/2023-13:04:41] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.076672
[10/24/2023-13:04:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:41] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:41] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2086609538387166260 Time: 0.188288
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2860655430572478466 Time: 0.086424
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:41] [V] [TRT] Tactic: 3239733199291090177 Time: 0.188416
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4474630279712975759 Time: 0.05108
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4479823862704990365 Time: 0.051072
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4517590677127196184 Time: 0.292096
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188416
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4696204239951173149 Time: 0.087168
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:41] [V] [TRT] Tactic: 5778138195697110003 Time: 0.146316
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:41] [V] [TRT] Tactic: 6310198979346901507 Time: 0.182784
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:41] [V] [TRT] Tactic: 7155825427510256858 Time: 0.142336
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:41] [V] [TRT] Tactic: 7222247112373541608 Time: 0.124064
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:41] [V] [TRT] Tactic: 7342025736444949634 Time: 0.062776
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:41] [V] [TRT] Tactic: 7472640475524677095 Time: 0.191488
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:41] [V] [TRT] Tactic: 8498373915030836990 Time: 0.31538
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:41] [V] [TRT] Tactic: 8869697132622550639 Time: 0.159524
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:41] [V] [TRT] Tactic: 8918020581761223752 Time: 0.141188
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:41] [V] [TRT] Tactic: -8937725997228636978 Time: 0.165888
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:41] [V] [TRT] Tactic: -8833858409138163072 Time: 0.292872
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:41] [V] [TRT] Tactic: -7989138351613022500 Time: 0.138644
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:41] [V] [TRT] Tactic: -7872883691240863058 Time: 0.188568
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:41] [V] [TRT] Tactic: -7377458734869418330 Time: 0.058368
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:41] [V] [TRT] Tactic: -6729618519651721910 Time: 0.18944
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:41] [V] [TRT] Tactic: -5893833996418445881 Time: 0.16282
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:41] [V] [TRT] Tactic: -5701562095007058349 Time: 0.29508
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:41] [V] [TRT] Tactic: -5685503422376017600 Time: 0.121728
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:41] [V] [TRT] Tactic: -5521125187060117489 Time: 0.140416
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:41] [V] [TRT] Tactic: -5457304872213719461 Time: 0.058376
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:41] [V] [TRT] Tactic: -4756382386362004279 Time: 0.086016
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:41] [V] [TRT] Tactic: -4615000974950361663 Time: 0.139264
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:41] [V] [TRT] Tactic: -4314913710375142296 Time: 0.138908
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:41] [V] [TRT] Tactic: -3855385237722507464 Time: 0.147456
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:41] [V] [TRT] Tactic: -3697587361057948972 Time: 0.12098
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:41] [V] [TRT] Tactic: -2809379259463049391 Time: 0.146432
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:41] [V] [TRT] Tactic: -2747929399988666512 Time: 0.289024
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:41] [V] [TRT] Tactic: -1472061967969061456 Time: 0.3076
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:41] [V] [TRT] Tactic: -504296718212024303 Time: 0.141312
[10/24/2023-13:04:41] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:41] [V] [TRT] Tactic: -444093195553988951 Time: 0.19086
[10/24/2023-13:04:41] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.051072
[10/24/2023-13:04:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[10/24/2023-13:04:41] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:41] [V] [TRT] Tactic: 0 Time: 0.097408
[10/24/2023-13:04:41] [V] [TRT] Tactic: 1 Time: 0.097408
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2 Time: 0.09728
[10/24/2023-13:04:41] [V] [TRT] Tactic: 4 Time: 0.426228
[10/24/2023-13:04:41] [V] [TRT] Tactic: 5 Time: 0.25406
[10/24/2023-13:04:41] [V] [TRT] Tactic: 6 Time: 0.541312
[10/24/2023-13:04:41] [V] [TRT] Tactic: 56 Time: 0.097536
[10/24/2023-13:04:41] [V] [TRT] Tactic: 58 Time: 0.097536
[10/24/2023-13:04:41] [V] [TRT] Tactic: 60 Time: 0.425216
[10/24/2023-13:04:41] [V] [TRT] Tactic: 61 Time: 0.256784
[10/24/2023-13:04:41] [V] [TRT] Tactic: 62 Time: 0.541432
[10/24/2023-13:04:41] [V] [TRT] Fastest Tactic: 2 Time: 0.09728
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[10/24/2023-13:04:41] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:41] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:41] [V] [TRT] Tactic: 524287 Time: 0.03626
[10/24/2023-13:04:41] [V] [TRT] Tactic: 1048575 Time: 0.035328
[10/24/2023-13:04:41] [V] [TRT] Tactic: 1703935 Time: 0.029312
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2228223 Time: 0.037912
[10/24/2023-13:04:41] [V] [TRT] Tactic: 2424831 Time: 0.041856
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2621439 Time: 0.029868
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3014655 Time: 0.032512
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3604479 Time: 0.031616
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5046271 Time: 0.033536
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6160383 Time: 0.03456
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6488063 Time: 0.042496
[10/24/2023-13:04:42] [V] [TRT] Tactic: 7864319 Time: 0.03164
[10/24/2023-13:04:42] [V] [TRT] Tactic: 8585215 Time: 0.041984
[10/24/2023-13:04:42] [V] [TRT] Tactic: 8847359 Time: 0.034432
[10/24/2023-13:04:42] [V] [TRT] Tactic: 9043967 Time: 0.033816
[10/24/2023-13:04:42] [V] [TRT] Tactic: 9175039 Time: 0.031744
[10/24/2023-13:04:42] [V] [TRT] Tactic: 9961471 Time: 0.037888
[10/24/2023-13:04:42] [V] [TRT] Tactic: 10027007 Time: 0.032028
[10/24/2023-13:04:42] [V] [TRT] Tactic: 10485759 Time: 0.030096
[10/24/2023-13:04:42] [V] [TRT] Tactic: 10682367 Time: 0.029696
[10/24/2023-13:04:42] [V] [TRT] Fastest Tactic: 1703935 Time: 0.029312
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2195670545862694453 Time: 0.040192
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3419182076704469245 Time: 0.058372
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3891805945559659536 Time: 0.10112
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5548126322150286555 Time: 0.057484
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6057304366605292508 Time: 0.05632
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:42] [V] [TRT] Tactic: -7928611605886347652 Time: 0.103308
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:42] [V] [TRT] Tactic: -5172391392092686714 Time: 0.041472
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:42] [V] [TRT] Tactic: -4374269919094467161 Time: 0.036864
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:42] [V] [TRT] Tactic: -4083394051665370953 Time: 0.020616
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:42] [V] [TRT] Tactic: -1546027692247304867 Time: 0.100352
[10/24/2023-13:04:42] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.020616
[10/24/2023-13:04:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:42] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:42] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:42] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:42] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:42] [V] [TRT] Tactic: 254850674756030979 Time: 0.031636
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:42] [V] [TRT] Tactic: 328038211831149625 Time: 0.030592
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:42] [V] [TRT] Tactic: 411553864378931917 Time: 0.02254
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1011057357468998345 Time: 0.034816
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1156328698016730421 Time: 0.03264
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1723736032573714698 Time: 0.033792
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1832046141070096030 Time: 0.022148
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1838082074606840426 Time: 0.02256
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:42] [V] [TRT] Tactic: 1899296423087490472 Time: 0.02754
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2428167804343994714 Time: 0.021376
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033664
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2657157263811141609 Time: 0.028544
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2819719497590964443 Time: 0.041856
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2968605903460894194 Time: 0.022816
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:42] [V] [TRT] Tactic: 2986078304285316765 Time: 0.033792
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3362537467505018070 Time: 0.033792
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3513075359009385578 Time: 0.031748
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3573559043797674382 Time: 0.022656
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3591970081995419777 Time: 0.024576
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:42] [V] [TRT] Tactic: 3704534001553878387 Time: 0.031616
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:42] [V] [TRT] Tactic: 4278315135102886928 Time: 0.036864
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:42] [V] [TRT] Tactic: 4503233883285355107 Time: 0.016384
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:42] [V] [TRT] Tactic: 4802447371470387646 Time: 0.022528
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5059676457552313631 Time: 0.03112
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5368829646735632944 Time: 0.026496
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5398999388616959893 Time: 0.020608
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5746691132547383910 Time: 0.040608
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5770170567977052602 Time: 0.02254
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:42] [V] [TRT] Tactic: 5953552212833506549 Time: 0.019456
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6034364043891107501 Time: 0.03584
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6074229447555668232 Time: 0.027392
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6154447660803990543 Time: 0.022572
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6325769668000961702 Time: 0.033792
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6350273239113254096 Time: 0.022784
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6377497238381488891 Time: 0.033792
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6446388116965632819 Time: 0.0224
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6468794451065529747 Time: 0.023424
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6642277870194067185 Time: 0.032768
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6859477213531075460 Time: 0.026496
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6972489290272968208 Time: 0.03264
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:42] [V] [TRT] Tactic: 6979044990896381511 Time: 0.03072
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:42] [V] [TRT] Tactic: 7216571380637776659 Time: 0.022528
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:42] [V] [TRT] Tactic: 7609923741161019135 Time: 0.021632
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:42] [V] [TRT] Tactic: 7705739241028240201 Time: 0.028544
[10/24/2023-13:04:42] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:43] [V] [TRT] Tactic: 8072087735545283117 Time: 0.05632
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:43] [V] [TRT] Tactic: 8101703987960976805 Time: 0.029312
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:43] [V] [TRT] Tactic: 8170606396342855895 Time: 0.022784
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:43] [V] [TRT] Tactic: 8839784824303350101 Time: 0.020556
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:43] [V] [TRT] Tactic: -9217371357561775773 Time: 0.029568
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:43] [V] [TRT] Tactic: -9009272790678027912 Time: 0.023296
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:43] [V] [TRT] Tactic: -8985224497679592364 Time: 0.01652
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:43] [V] [TRT] Tactic: -8949544755481315679 Time: 0.023436
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:43] [V] [TRT] Tactic: -8759929675070720385 Time: 0.032776
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:43] [V] [TRT] Tactic: -8604374562669615024 Time: 0.027264
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6902925267326201166 Time: 0.021928
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6840588038605932325 Time: 0.037888
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6799856376604253964 Time: 0.055424
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6625722781282978136 Time: 0.015744
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6525498856028268801 Time: 0.019456
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6356316196810535311 Time: 0.029952
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6324345858751792783 Time: 0.016364
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6262400699544994312 Time: 0.055296
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6257787336162086472 Time: 0.032768
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:43] [V] [TRT] Tactic: -6063766379489217211 Time: 0.021664
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5777580938094193096 Time: 0.036352
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5657273398217409378 Time: 0.03072
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5530886555766748586 Time: 0.03346
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5422685219138380548 Time: 0.02048
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5161596964442251102 Time: 0.039936
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:43] [V] [TRT] Tactic: -5127240325355316006 Time: 0.03648
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4825567853927730435 Time: 0.021376
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4796511246675321840 Time: 0.040832
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4706569565442112734 Time: 0.03072
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4566599693570369588 Time: 0.033792
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4409144516525410768 Time: 0.033772
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4379519430184503304 Time: 0.021632
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4152066959007262150 Time: 0.031744
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:43] [V] [TRT] Tactic: -4021926646879732549 Time: 0.03776
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3987638434926559037 Time: 0.04096
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3905653247016903130 Time: 0.021504
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3903974568488493144 Time: 0.022528
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3895429239811098010 Time: 0.036864
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3864869056275745423 Time: 0.021512
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3601464762214218301 Time: 0.0256
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3412636942650049698 Time: 0.021504
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3338665856053412950 Time: 0.019456
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:43] [V] [TRT] Tactic: -3058330359340425555 Time: 0.039808
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2816084650627734155 Time: 0.023424
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034816
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2559894581585337900 Time: 0.031616
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2530740716768816092 Time: 0.017408
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2332828394978346992 Time: 0.03266
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2241736083352441442 Time: 0.022528
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:43] [V] [TRT] Tactic: -2161909437867201546 Time: 0.022528
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:43] [V] [TRT] Tactic: -1985778916402815946 Time: 0.022528
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:43] [V] [TRT] Tactic: -1500496213132463076 Time: 0.023684
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:43] [V] [TRT] Tactic: -1099247066487349374 Time: 0.026624
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:43] [V] [TRT] Tactic: -910286698936744682 Time: 0.026624
[10/24/2023-13:04:43] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:43] [V] [TRT] Tactic: -606726295133751039 Time: 0.016412
[10/24/2023-13:04:43] [V] [TRT] Fastest Tactic: -6625722781282978136 Time: 0.015744
[10/24/2023-13:04:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6625722781282978136
[10/24/2023-13:04:43] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:43] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CudnnConvolution)
[10/24/2023-13:04:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:43] [V] [TRT] --------------- Timing Runner: /heads_list.0/center_z/center_z.1/Conv (CaskConvolution)
[10/24/2023-13:04:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:43] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:43] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:43] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:43] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:43] [V] [TRT] Tactic: 524287 Time: 0.046088
[10/24/2023-13:04:43] [V] [TRT] Tactic: 1048575 Time: 0.043008
[10/24/2023-13:04:43] [V] [TRT] Tactic: 1703935 Time: 0.041088
[10/24/2023-13:04:43] [V] [TRT] Tactic: 2228223 Time: 0.049036
[10/24/2023-13:04:43] [V] [TRT] Tactic: 2424831 Time: 0.050824
[10/24/2023-13:04:43] [V] [TRT] Tactic: 2621439 Time: 0.038528
[10/24/2023-13:04:43] [V] [TRT] Tactic: 3014655 Time: 0.045056
[10/24/2023-13:04:43] [V] [TRT] Tactic: 3604479 Time: 0.04762
[10/24/2023-13:04:43] [V] [TRT] Tactic: 5046271 Time: 0.041856
[10/24/2023-13:04:43] [V] [TRT] Tactic: 6160383 Time: 0.044928
[10/24/2023-13:04:43] [V] [TRT] Tactic: 6488063 Time: 0.047104
[10/24/2023-13:04:43] [V] [TRT] Tactic: 7864319 Time: 0.039936
[10/24/2023-13:04:44] [V] [TRT] Tactic: 8585215 Time: 0.050816
[10/24/2023-13:04:44] [V] [TRT] Tactic: 8847359 Time: 0.05212
[10/24/2023-13:04:44] [V] [TRT] Tactic: 9043967 Time: 0.042004
[10/24/2023-13:04:44] [V] [TRT] Tactic: 9175039 Time: 0.047872
[10/24/2023-13:04:44] [V] [TRT] Tactic: 9961471 Time: 0.048
[10/24/2023-13:04:44] [V] [TRT] Tactic: 10027007 Time: 0.038912
[10/24/2023-13:04:44] [V] [TRT] Tactic: 10485759 Time: 0.040452
[10/24/2023-13:04:44] [V] [TRT] Tactic: 10682367 Time: 0.03776
[10/24/2023-13:04:44] [V] [TRT] Fastest Tactic: 10682367 Time: 0.03776
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:44] [V] [TRT] Tactic: 0 Time: 0.093568
[10/24/2023-13:04:44] [V] [TRT] Tactic: 1 Time: 0.09384
[10/24/2023-13:04:44] [V] [TRT] Tactic: 2 Time: 0.093824
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4 Time: 0.78912
[10/24/2023-13:04:44] [V] [TRT] Tactic: 5 Time: 0.348932
[10/24/2023-13:04:44] [V] [TRT] Tactic: 6 Time: 0.03584
[10/24/2023-13:04:44] [V] [TRT] Tactic: 56 Time: 0.093824
[10/24/2023-13:04:44] [V] [TRT] Tactic: 57 Time: 0.093824
[10/24/2023-13:04:44] [V] [TRT] Tactic: 58 Time: 0.09346
[10/24/2023-13:04:44] [V] [TRT] Tactic: 60 Time: 0.789512
[10/24/2023-13:04:44] [V] [TRT] Tactic: 61 Time: 0.274808
[10/24/2023-13:04:44] [V] [TRT] Tactic: 62 Time: 0.03584
[10/24/2023-13:04:44] [V] [TRT] Tactic: 112 Time: 0.093568
[10/24/2023-13:04:44] [V] [TRT] Tactic: 113 Time: 0.09408
[10/24/2023-13:04:44] [V] [TRT] Tactic: 114 Time: 0.093568
[10/24/2023-13:04:44] [V] [TRT] Tactic: 116 Time: 0.78848
[10/24/2023-13:04:44] [V] [TRT] Tactic: 117 Time: 0.28796
[10/24/2023-13:04:44] [V] [TRT] Tactic: 118 Time: 0.03584
[10/24/2023-13:04:44] [V] [TRT] Fastest Tactic: 6 Time: 0.03584
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4549827808004681195 Time: 0.089088
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:44] [V] [TRT] Tactic: 5779835512569528575 Time: 0.146688
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:44] [V] [TRT] Tactic: 6053873026024413720 Time: 0.152832
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:44] [V] [TRT] Tactic: 6767548733843469815 Time: 0.086144
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:44] [V] [TRT] Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:44] [V] [TRT] Tactic: -1123676555321336786 Time: 0.148096
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:44] [V] [TRT] Tactic: -701551393537224327 Time: 0.091904
[10/24/2023-13:04:44] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[10/24/2023-13:04:44] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:44] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:44] [V] [TRT] Tactic: 2086609538387166260 Time: 0.188416
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:44] [V] [TRT] Tactic: 2860655430572478466 Time: 0.086656
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:44] [V] [TRT] Tactic: 3239733199291090177 Time: 0.18842
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4474630279712975759 Time: 0.0512
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4479823862704990365 Time: 0.0512
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4517590677127196184 Time: 0.290176
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188288
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4696204239951173149 Time: 0.087076
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:44] [V] [TRT] Tactic: 5778138195697110003 Time: 0.14656
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:44] [V] [TRT] Tactic: 6310198979346901507 Time: 0.183168
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:44] [V] [TRT] Tactic: 7155825427510256858 Time: 0.142596
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:44] [V] [TRT] Tactic: 7222247112373541608 Time: 0.123912
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:44] [V] [TRT] Tactic: 7342025736444949634 Time: 0.062992
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:44] [V] [TRT] Tactic: 7472640475524677095 Time: 0.191764
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:44] [V] [TRT] Tactic: 8498373915030836990 Time: 0.31424
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:44] [V] [TRT] Tactic: 8869697132622550639 Time: 0.159744
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:44] [V] [TRT] Tactic: 8918020581761223752 Time: 0.141068
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:44] [V] [TRT] Tactic: -8937725997228636978 Time: 0.165888
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:44] [V] [TRT] Tactic: -8833858409138163072 Time: 0.29632
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:44] [V] [TRT] Tactic: -7989138351613022500 Time: 0.138644
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:44] [V] [TRT] Tactic: -7872883691240863058 Time: 0.188544
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:44] [V] [TRT] Tactic: -7377458734869418330 Time: 0.058368
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:44] [V] [TRT] Tactic: -6729618519651721910 Time: 0.18944
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:44] [V] [TRT] Tactic: -5893833996418445881 Time: 0.162696
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:44] [V] [TRT] Tactic: -5701562095007058349 Time: 0.29492
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:44] [V] [TRT] Tactic: -5685503422376017600 Time: 0.121728
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:44] [V] [TRT] Tactic: -5521125187060117489 Time: 0.140304
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:44] [V] [TRT] Tactic: -5457304872213719461 Time: 0.058496
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:44] [V] [TRT] Tactic: -4756382386362004279 Time: 0.086016
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:44] [V] [TRT] Tactic: -4615000974950361663 Time: 0.139008
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:44] [V] [TRT] Tactic: -4314913710375142296 Time: 0.1394
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:44] [V] [TRT] Tactic: -3855385237722507464 Time: 0.147456
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:44] [V] [TRT] Tactic: -3697587361057948972 Time: 0.121088
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:44] [V] [TRT] Tactic: -2809379259463049391 Time: 0.146432
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:44] [V] [TRT] Tactic: -2747929399988666512 Time: 0.289288
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:44] [V] [TRT] Tactic: -1472061967969061456 Time: 0.305944
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:44] [V] [TRT] Tactic: -504296718212024303 Time: 0.141312
[10/24/2023-13:04:44] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:44] [V] [TRT] Tactic: -444093195553988951 Time: 0.190848
[10/24/2023-13:04:44] [V] [TRT] Fastest Tactic: 4474630279712975759 Time: 0.0512
[10/24/2023-13:04:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4474630279712975759
[10/24/2023-13:04:44] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:44] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:44] [V] [TRT] Tactic: 0 Time: 0.19712
[10/24/2023-13:04:44] [V] [TRT] Tactic: 1 Time: 0.088064
[10/24/2023-13:04:44] [V] [TRT] Tactic: 2 Time: 0.22784
[10/24/2023-13:04:44] [V] [TRT] Tactic: 4 Time: 0.788604
[10/24/2023-13:04:44] [V] [TRT] Tactic: 5 Time: 0.336192
[10/24/2023-13:04:44] [V] [TRT] Tactic: 6 Time: 0.542032
[10/24/2023-13:04:44] [V] [TRT] Tactic: 56 Time: 0.196864
[10/24/2023-13:04:44] [V] [TRT] Tactic: 58 Time: 0.228352
[10/24/2023-13:04:44] [V] [TRT] Tactic: 60 Time: 0.789096
[10/24/2023-13:04:44] [V] [TRT] Tactic: 61 Time: 0.288368
[10/24/2023-13:04:45] [V] [TRT] Tactic: 62 Time: 0.542
[10/24/2023-13:04:45] [V] [TRT] Fastest Tactic: 1 Time: 0.088064
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:04:45] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:45] [V] [TRT] Tactic: 524287 Time: 0.036132
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1048575 Time: 0.035348
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1703935 Time: 0.029696
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2228223 Time: 0.038016
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2424831 Time: 0.041984
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2621439 Time: 0.030592
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3014655 Time: 0.03264
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3604479 Time: 0.031616
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5046271 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6160383 Time: 0.034816
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6488063 Time: 0.042496
[10/24/2023-13:04:45] [V] [TRT] Tactic: 7864319 Time: 0.031744
[10/24/2023-13:04:45] [V] [TRT] Tactic: 8585215 Time: 0.041984
[10/24/2023-13:04:45] [V] [TRT] Tactic: 8847359 Time: 0.034568
[10/24/2023-13:04:45] [V] [TRT] Tactic: 9043967 Time: 0.033816
[10/24/2023-13:04:45] [V] [TRT] Tactic: 9175039 Time: 0.031744
[10/24/2023-13:04:45] [V] [TRT] Tactic: 9961471 Time: 0.038192
[10/24/2023-13:04:45] [V] [TRT] Tactic: 10027007 Time: 0.032384
[10/24/2023-13:04:45] [V] [TRT] Tactic: 10485759 Time: 0.030228
[10/24/2023-13:04:45] [V] [TRT] Tactic: 10682367 Time: 0.03044
[10/24/2023-13:04:45] [V] [TRT] Fastest Tactic: 1703935 Time: 0.029696
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2195670545862694453 Time: 0.040204
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3419182076704469245 Time: 0.058368
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3891805945559659536 Time: 0.100992
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5548126322150286555 Time: 0.05736
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6057304366605292508 Time: 0.05632
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:45] [V] [TRT] Tactic: -7928611605886347652 Time: 0.103296
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:45] [V] [TRT] Tactic: -5172391392092686714 Time: 0.041624
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:45] [V] [TRT] Tactic: -4374269919094467161 Time: 0.036864
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:45] [V] [TRT] Tactic: -4083394051665370953 Time: 0.020496
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:45] [V] [TRT] Tactic: -1546027692247304867 Time: 0.100352
[10/24/2023-13:04:45] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.020496
[10/24/2023-13:04:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:45] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:45] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:45] [V] [TRT] Tactic: 254850674756030979 Time: 0.031744
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:45] [V] [TRT] Tactic: 328038211831149625 Time: 0.030592
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:45] [V] [TRT] Tactic: 411553864378931917 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1011057357468998345 Time: 0.034816
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1156328698016730421 Time: 0.032512
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1723736032573714698 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1832046141070096030 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1838082074606840426 Time: 0.022576
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:45] [V] [TRT] Tactic: 1899296423087490472 Time: 0.027528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2428167804343994714 Time: 0.021504
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2657157263811141609 Time: 0.028544
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2819719497590964443 Time: 0.0416
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2968605903460894194 Time: 0.022612
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:45] [V] [TRT] Tactic: 2986078304285316765 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3362537467505018070 Time: 0.033408
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3513075359009385578 Time: 0.031744
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3573559043797674382 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3591970081995419777 Time: 0.024576
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:45] [V] [TRT] Tactic: 3704534001553878387 Time: 0.031616
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:45] [V] [TRT] Tactic: 4278315135102886928 Time: 0.036872
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:45] [V] [TRT] Tactic: 4503233883285355107 Time: 0.016256
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:45] [V] [TRT] Tactic: 4802447371470387646 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5059676457552313631 Time: 0.031616
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5368829646735632944 Time: 0.026508
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5398999388616959893 Time: 0.020736
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5746691132547383910 Time: 0.04096
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5770170567977052602 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:45] [V] [TRT] Tactic: 5953552212833506549 Time: 0.019456
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6034364043891107501 Time: 0.03584
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6074229447555668232 Time: 0.02752
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6154447660803990543 Time: 0.02254
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6325769668000961702 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6350273239113254096 Time: 0.022528
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6377497238381488891 Time: 0.033792
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6446388116965632819 Time: 0.022264
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6468794451065529747 Time: 0.023424
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6642277870194067185 Time: 0.032768
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6859477213531075460 Time: 0.026496
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6972489290272968208 Time: 0.032512
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:45] [V] [TRT] Tactic: 6979044990896381511 Time: 0.03072
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:45] [V] [TRT] Tactic: 7216571380637776659 Time: 0.0224
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:45] [V] [TRT] Tactic: 7609923741161019135 Time: 0.021524
[10/24/2023-13:04:45] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:46] [V] [TRT] Tactic: 7705739241028240201 Time: 0.028672
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:46] [V] [TRT] Tactic: 8072087735545283117 Time: 0.056192
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:46] [V] [TRT] Tactic: 8101703987960976805 Time: 0.029184
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:46] [V] [TRT] Tactic: 8170606396342855895 Time: 0.022796
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:46] [V] [TRT] Tactic: 8839784824303350101 Time: 0.020508
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:46] [V] [TRT] Tactic: -9217371357561775773 Time: 0.029696
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:46] [V] [TRT] Tactic: -9009272790678027912 Time: 0.023296
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:46] [V] [TRT] Tactic: -8985224497679592364 Time: 0.016284
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:46] [V] [TRT] Tactic: -8949544755481315679 Time: 0.023552
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:46] [V] [TRT] Tactic: -8759929675070720385 Time: 0.032768
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:46] [V] [TRT] Tactic: -8604374562669615024 Time: 0.027264
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6902925267326201166 Time: 0.022272
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6840588038605932325 Time: 0.037888
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6799856376604253964 Time: 0.055552
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6625722781282978136 Time: 0.016128
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6525498856028268801 Time: 0.019456
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6356316196810535311 Time: 0.029964
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6324345858751792783 Time: 0.016256
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6262400699544994312 Time: 0.055296
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6257787336162086472 Time: 0.032768
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:46] [V] [TRT] Tactic: -6063766379489217211 Time: 0.021708
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5777580938094193096 Time: 0.036376
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5657273398217409378 Time: 0.03074
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5530886555766748586 Time: 0.033536
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5422685219138380548 Time: 0.02048
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5161596964442251102 Time: 0.039936
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:46] [V] [TRT] Tactic: -5127240325355316006 Time: 0.036352
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4825567853927730435 Time: 0.021376
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4796511246675321840 Time: 0.040832
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4706569565442112734 Time: 0.03072
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4566599693570369588 Time: 0.033792
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4409144516525410768 Time: 0.033664
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4379519430184503304 Time: 0.021504
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4152066959007262150 Time: 0.031744
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:46] [V] [TRT] Tactic: -4021926646879732549 Time: 0.037272
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3987638434926559037 Time: 0.04096
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3905653247016903130 Time: 0.021376
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3903974568488493144 Time: 0.022552
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3895429239811098010 Time: 0.036868
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3864869056275745423 Time: 0.021524
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3601464762214218301 Time: 0.0256
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3412636942650049698 Time: 0.021504
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3338665856053412950 Time: 0.019456
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:46] [V] [TRT] Tactic: -3058330359340425555 Time: 0.03968
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2816084650627734155 Time: 0.023312
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034816
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2559894581585337900 Time: 0.031616
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2530740716768816092 Time: 0.01742
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2332828394978346992 Time: 0.032768
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2241736083352441442 Time: 0.022528
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:46] [V] [TRT] Tactic: -2161909437867201546 Time: 0.022528
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:46] [V] [TRT] Tactic: -1985778916402815946 Time: 0.022528
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:46] [V] [TRT] Tactic: -1500496213132463076 Time: 0.023704
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:46] [V] [TRT] Tactic: -1099247066487349374 Time: 0.026604
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:46] [V] [TRT] Tactic: -910286698936744682 Time: 0.026624
[10/24/2023-13:04:46] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:46] [V] [TRT] Tactic: -606726295133751039 Time: 0.016384
[10/24/2023-13:04:46] [V] [TRT] Fastest Tactic: -6625722781282978136 Time: 0.016128
[10/24/2023-13:04:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6625722781282978136
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:46] [V] [TRT] --------------- Timing Runner: /heads_list.0/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(1048576,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,2048,16) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,512,4) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:46] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,2048,16) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,512,4) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,16384,128,1) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,8192,64) -> Float(8388608,1,65536,512) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,2048,16) -> Float(2097152,1:4,16384,128) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384,128,1) -> Half(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,16384:2,128,1) -> Half(4194304,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Float(8388608,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Half(1048576,1:8,8192,64) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,512,4) -> Half(524288,1:16,4096,32) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,16384,128,1) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(8388608,1,65536,512) -> Float(16384,1,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(2097152,1:4,16384,128) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(8388608,16384,128,1) -> Half(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Float(16384,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(1048576,1:8,8192,64) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Half(524288,1:16,4096,32) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:47] [V] [TRT] *************** Autotuning format combination: Float(1048576,16384,128,1) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:04:47] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:47] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:47] [V] [TRT] Tactic: 524287 Time: 0.304512
[10/24/2023-13:04:47] [V] [TRT] Tactic: 720895 Time: 0.26884
[10/24/2023-13:04:47] [V] [TRT] Tactic: 983039 Time: 0.259712
[10/24/2023-13:04:47] [V] [TRT] Tactic: 1048575 Time: 0.278936
[10/24/2023-13:04:47] [V] [TRT] Tactic: 1703935 Time: 0.26446
[10/24/2023-13:04:47] [V] [TRT] Tactic: 1769471 Time: 0.355712
[10/24/2023-13:04:47] [V] [TRT] Tactic: 1966079 Time: 0.315916
[10/24/2023-13:04:47] [V] [TRT] Tactic: 2031615 Time: 0.309096
[10/24/2023-13:04:47] [V] [TRT] Tactic: 2228223 Time: 0.290188
[10/24/2023-13:04:47] [V] [TRT] Tactic: 2424831 Time: 0.38336
[10/24/2023-13:04:47] [V] [TRT] Tactic: 2621439 Time: 0.291712
[10/24/2023-13:04:48] [V] [TRT] Tactic: 2752511 Time: 0.303488
[10/24/2023-13:04:48] [V] [TRT] Tactic: 2818047 Time: 0.352896
[10/24/2023-13:04:48] [V] [TRT] Tactic: 2883583 Time: 0.363288
[10/24/2023-13:04:48] [V] [TRT] Tactic: 3014655 Time: 0.263016
[10/24/2023-13:04:48] [V] [TRT] Tactic: 3145727 Time: 0.284672
[10/24/2023-13:04:48] [V] [TRT] Tactic: 3473407 Time: 0.338176
[10/24/2023-13:04:48] [V] [TRT] Tactic: 3604479 Time: 0.281248
[10/24/2023-13:04:48] [V] [TRT] Tactic: 3735551 Time: 0.38848
[10/24/2023-13:04:48] [V] [TRT] Tactic: 4390911 Time: 0.339072
[10/24/2023-13:04:48] [V] [TRT] Tactic: 5046271 Time: 0.270232
[10/24/2023-13:04:48] [V] [TRT] Tactic: 5963775 Time: 0.307732
[10/24/2023-13:04:48] [V] [TRT] Tactic: 6160383 Time: 0.296192
[10/24/2023-13:04:48] [V] [TRT] Tactic: 6488063 Time: 0.269696
[10/24/2023-13:04:48] [V] [TRT] Tactic: 6881279 Time: 0.306176
[10/24/2023-13:04:48] [V] [TRT] Tactic: 7274495 Time: 0.328064
[10/24/2023-13:04:48] [V] [TRT] Tactic: 7864319 Time: 0.303648
[10/24/2023-13:04:48] [V] [TRT] Tactic: 7995391 Time: 0.277512
[10/24/2023-13:04:48] [V] [TRT] Tactic: 8585215 Time: 0.291968
[10/24/2023-13:04:48] [V] [TRT] Tactic: 8847359 Time: 0.395776
[10/24/2023-13:04:48] [V] [TRT] Tactic: 8978431 Time: 0.30912
[10/24/2023-13:04:48] [V] [TRT] Tactic: 9043967 Time: 0.26074
[10/24/2023-13:04:48] [V] [TRT] Tactic: 9175039 Time: 0.28098
[10/24/2023-13:04:48] [V] [TRT] Tactic: 9502719 Time: 0.319872
[10/24/2023-13:04:48] [V] [TRT] Tactic: 9830399 Time: 0.352272
[10/24/2023-13:04:48] [V] [TRT] Tactic: 9961471 Time: 0.385536
[10/24/2023-13:04:48] [V] [TRT] Tactic: 10027007 Time: 0.264832
[10/24/2023-13:04:49] [V] [TRT] Tactic: 10092543 Time: 0.339736
[10/24/2023-13:04:49] [V] [TRT] Tactic: 10289151 Time: 0.316688
[10/24/2023-13:04:49] [V] [TRT] Tactic: 10485759 Time: 0.260864
[10/24/2023-13:04:49] [V] [TRT] Tactic: 10682367 Time: 0.282504
[10/24/2023-13:04:49] [V] [TRT] Tactic: 10813439 Time: 0.264624
[10/24/2023-13:04:49] [V] [TRT] Fastest Tactic: 983039 Time: 0.259712
[10/24/2023-13:04:49] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:49] [V] [TRT] Tactic: 0 Time: 0.508928
[10/24/2023-13:04:49] [V] [TRT] Tactic: 1 Time: 0.280832
[10/24/2023-13:04:49] [V] [TRT] Tactic: 2 Time: 0.532744
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8691449856, available: 4294967296
[10/24/2023-13:04:49] [V] [TRT] Tactic: 5 Time: 3.60871
[10/24/2023-13:04:49] [V] [TRT] Tactic: 6 Time: 0.300416
[10/24/2023-13:04:49] [V] [TRT] Tactic: 56 Time: 0.509952
[10/24/2023-13:04:49] [V] [TRT] Tactic: 57 Time: 0.279812
[10/24/2023-13:04:49] [V] [TRT] Tactic: 58 Time: 0.532736
[10/24/2023-13:04:49] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8691449856, available: 4294967296
[10/24/2023-13:04:49] [V] [TRT] Tactic: 61 Time: 3.60986
[10/24/2023-13:04:49] [V] [TRT] Tactic: 62 Time: 0.301312
[10/24/2023-13:04:49] [V] [TRT] Tactic: 112 Time: 0.510984
[10/24/2023-13:04:49] [V] [TRT] Tactic: 113 Time: 0.413204
[10/24/2023-13:04:49] [V] [TRT] Tactic: 114 Time: 0.532992
[10/24/2023-13:04:49] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8691449856, available: 4294967296
[10/24/2023-13:04:49] [V] [TRT] Tactic: 117 Time: 3.60714
[10/24/2023-13:04:49] [V] [TRT] Tactic: 118 Time: 0.302856
[10/24/2023-13:04:49] [V] [TRT] Fastest Tactic: 57 Time: 0.279812
[10/24/2023-13:04:49] [V] [TRT] Setting workspace to 8691449856enables more tactics for profiling
[10/24/2023-13:04:49] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4549827808004681195 Time: 0.28672
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:49] [V] [TRT] Tactic: 5779835512569528575 Time: 0.291988
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:49] [V] [TRT] Tactic: 6053873026024413720 Time: 0.314496
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:49] [V] [TRT] Tactic: 6767548733843469815 Time: 0.28352
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:49] [V] [TRT] Tactic: -6313876406580483184 Time: 0.322176
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:49] [V] [TRT] Tactic: -1123676555321336786 Time: 0.294556
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:49] [V] [TRT] Tactic: -701551393537224327 Time: 0.293128
[10/24/2023-13:04:49] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 0.28352
[10/24/2023-13:04:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 983039
[10/24/2023-13:04:49] [V] [TRT] *************** Autotuning format combination: Float(1048576,1,8192,64) -> Float(4194304,1,32768,256) ***************
[10/24/2023-13:04:49] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:49] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:49] [V] [TRT] Tactic: 2086609538387166260 Time: 0.327936
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:49] [V] [TRT] Tactic: 2860655430572478466 Time: 0.28032
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:49] [V] [TRT] Tactic: 3239733199291090177 Time: 0.327972
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4474630279712975759 Time: 0.286088
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4479823862704990365 Time: 0.281728
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4517590677127196184 Time: 0.303616
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4634080872644479428 Time: 0.397696
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:49] [V] [TRT] Tactic: 4696204239951173149 Time: 0.281472
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:49] [V] [TRT] Tactic: 5778138195697110003 Time: 0.301696
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:49] [V] [TRT] Tactic: 6310198979346901507 Time: 0.385152
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:49] [V] [TRT] Tactic: 7155825427510256858 Time: 0.293532
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:49] [V] [TRT] Tactic: 7222247112373541608 Time: 0.411904
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:49] [V] [TRT] Tactic: 7472640475524677095 Time: 0.40256
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:49] [V] [TRT] Tactic: 8498373915030836990 Time: 0.343168
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:49] [V] [TRT] Tactic: 8869697132622550639 Time: 0.578304
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:49] [V] [TRT] Tactic: 8918020581761223752 Time: 0.290688
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:49] [V] [TRT] Tactic: -8937725997228636978 Time: 0.352268
[10/24/2023-13:04:49] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:50] [V] [TRT] Tactic: -8833858409138163072 Time: 0.32
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:50] [V] [TRT] Tactic: -7989138351613022500 Time: 0.43328
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:50] [V] [TRT] Tactic: -7872883691240863058 Time: 0.402048
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:50] [V] [TRT] Tactic: -6729618519651721910 Time: 0.39872
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5893833996418445881 Time: 0.555656
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5701562095007058349 Time: 0.322048
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5685503422376017600 Time: 0.410368
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5521125187060117489 Time: 0.4384
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4756382386362004279 Time: 0.278016
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4615000974950361663 Time: 0.433408
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4314913710375142296 Time: 0.502144
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:50] [V] [TRT] Tactic: -3855385237722507464 Time: 0.304416
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:50] [V] [TRT] Tactic: -3697587361057948972 Time: 0.410148
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:50] [V] [TRT] Tactic: -2809379259463049391 Time: 0.303896
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:50] [V] [TRT] Tactic: -2747929399988666512 Time: 0.300304
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:50] [V] [TRT] Tactic: -1472061967969061456 Time: 0.321664
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:50] [V] [TRT] Tactic: -504296718212024303 Time: 0.291216
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:50] [V] [TRT] Tactic: -444093195553988951 Time: 0.326164
[10/24/2023-13:04:50] [V] [TRT] Fastest Tactic: -4756382386362004279 Time: 0.278016
[10/24/2023-13:04:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4756382386362004279
[10/24/2023-13:04:50] [V] [TRT] *************** Autotuning format combination: Float(262144,1:4,2048,16) -> Float(1048576,1:4,8192,64) ***************
[10/24/2023-13:04:50] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:50] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:50] [V] [TRT] Tactic: 2086609538387166260 Time: 0.327816
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:50] [V] [TRT] Tactic: 2860655430572478466 Time: 0.280236
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:50] [V] [TRT] Tactic: 3239733199291090177 Time: 0.327948
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4474630279712975759 Time: 0.285964
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4479823862704990365 Time: 0.281748
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4517590677127196184 Time: 0.303232
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4634080872644479428 Time: 0.39668
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4696204239951173149 Time: 0.281344
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:50] [V] [TRT] Tactic: 5778138195697110003 Time: 0.301952
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:50] [V] [TRT] Tactic: 6310198979346901507 Time: 0.384512
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:50] [V] [TRT] Tactic: 7155825427510256858 Time: 0.293532
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:50] [V] [TRT] Tactic: 7222247112373541608 Time: 0.411904
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:50] [V] [TRT] Tactic: 7342025736444949634 Time: 0.147364
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:50] [V] [TRT] Tactic: 7472640475524677095 Time: 0.403716
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:50] [V] [TRT] Tactic: 8498373915030836990 Time: 0.342916
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:50] [V] [TRT] Tactic: 8869697132622550639 Time: 0.578304
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:50] [V] [TRT] Tactic: 8918020581761223752 Time: 0.290688
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:50] [V] [TRT] Tactic: -8937725997228636978 Time: 0.353048
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:50] [V] [TRT] Tactic: -8833858409138163072 Time: 0.320028
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:50] [V] [TRT] Tactic: -7989138351613022500 Time: 0.433156
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:50] [V] [TRT] Tactic: -7872883691240863058 Time: 0.402056
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:50] [V] [TRT] Tactic: -7377458734869418330 Time: 0.138376
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:50] [V] [TRT] Tactic: -6729618519651721910 Time: 0.401408
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5893833996418445881 Time: 0.55296
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5701562095007058349 Time: 0.321948
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5685503422376017600 Time: 0.41052
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5521125187060117489 Time: 0.4384
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:50] [V] [TRT] Tactic: -5457304872213719461 Time: 0.138368
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4756382386362004279 Time: 0.278024
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4615000974950361663 Time: 0.433408
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:50] [V] [TRT] Tactic: -4314913710375142296 Time: 0.502272
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:50] [V] [TRT] Tactic: -3855385237722507464 Time: 0.304016
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:50] [V] [TRT] Tactic: -3697587361057948972 Time: 0.410004
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:50] [V] [TRT] Tactic: -2809379259463049391 Time: 0.303488
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:50] [V] [TRT] Tactic: -2747929399988666512 Time: 0.29952
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:50] [V] [TRT] Tactic: -1472061967969061456 Time: 0.322432
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:50] [V] [TRT] Tactic: -504296718212024303 Time: 0.291072
[10/24/2023-13:04:50] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:50] [V] [TRT] Tactic: -444093195553988951 Time: 0.326028
[10/24/2023-13:04:50] [V] [TRT] Fastest Tactic: -5457304872213719461 Time: 0.138368
[10/24/2023-13:04:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5457304872213719461
[10/24/2023-13:04:50] [V] [TRT] *************** Autotuning format combination: Half(1048576,16384,128,1) -> Half(4194304,16384,128,1) ***************
[10/24/2023-13:04:50] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:50] [V] [TRT] Tactic: 0 Time: 0.460544
[10/24/2023-13:04:50] [V] [TRT] Tactic: 1 Time: 0.460032
[10/24/2023-13:04:50] [V] [TRT] Tactic: 2 Time: 0.442752
[10/24/2023-13:04:50] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8691449856, available: 4294967296
[10/24/2023-13:04:51] [V] [TRT] Tactic: 5 Time: 3.53698
[10/24/2023-13:04:51] [V] [TRT] Tactic: 6 Time: 0.311808
[10/24/2023-13:04:51] [V] [TRT] Tactic: 56 Time: 0.460172
[10/24/2023-13:04:51] [V] [TRT] Tactic: 58 Time: 0.44252
[10/24/2023-13:04:51] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8691449856, available: 4294967296
[10/24/2023-13:04:51] [V] [TRT] Tactic: 61 Time: 3.53657
[10/24/2023-13:04:51] [V] [TRT] Tactic: 62 Time: 0.309516
[10/24/2023-13:04:51] [V] [TRT] Fastest Tactic: 62 Time: 0.309516
[10/24/2023-13:04:51] [V] [TRT] Setting workspace to 8691449856enables more tactics for profiling
[10/24/2023-13:04:51] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:51] [V] [TRT] *************** Autotuning format combination: Half(524288,16384:2,128,1) -> Half(2097152,16384:2,128,1) ***************
[10/24/2023-13:04:51] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (FusedConvActConvolution)
[10/24/2023-13:04:51] [V] [TRT] Tactic: 524287 Time: 0.186628
[10/24/2023-13:04:51] [V] [TRT] Tactic: 720895 Time: 0.177256
[10/24/2023-13:04:51] [V] [TRT] Tactic: 983039 Time: 0.171032
[10/24/2023-13:04:51] [V] [TRT] Tactic: 1048575 Time: 0.177024
[10/24/2023-13:04:51] [V] [TRT] Tactic: 1703935 Time: 0.17408
[10/24/2023-13:04:51] [V] [TRT] Tactic: 1769471 Time: 0.252304
[10/24/2023-13:04:51] [V] [TRT] Tactic: 1966079 Time: 0.19984
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2031615 Time: 0.190996
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2228223 Time: 0.177644
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2424831 Time: 0.264448
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2621439 Time: 0.193948
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2752511 Time: 0.185344
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2818047 Time: 0.191768
[10/24/2023-13:04:51] [V] [TRT] Tactic: 2883583 Time: 0.194944
[10/24/2023-13:04:51] [V] [TRT] Tactic: 3014655 Time: 0.174208
[10/24/2023-13:04:51] [V] [TRT] Tactic: 3145727 Time: 0.181032
[10/24/2023-13:04:51] [V] [TRT] Tactic: 3473407 Time: 0.17856
[10/24/2023-13:04:51] [V] [TRT] Tactic: 3604479 Time: 0.176256
[10/24/2023-13:04:51] [V] [TRT] Tactic: 3735551 Time: 0.2112
[10/24/2023-13:04:51] [V] [TRT] Tactic: 4390911 Time: 0.197508
[10/24/2023-13:04:51] [V] [TRT] Tactic: 5046271 Time: 0.178048
[10/24/2023-13:04:51] [V] [TRT] Tactic: 5963775 Time: 0.19968
[10/24/2023-13:04:52] [V] [TRT] Tactic: 6160383 Time: 0.193048
[10/24/2023-13:04:52] [V] [TRT] Tactic: 6488063 Time: 0.192384
[10/24/2023-13:04:52] [V] [TRT] Tactic: 6881279 Time: 0.185344
[10/24/2023-13:04:52] [V] [TRT] Tactic: 7274495 Time: 0.210688
[10/24/2023-13:04:52] [V] [TRT] Tactic: 7864319 Time: 0.21048
[10/24/2023-13:04:52] [V] [TRT] Tactic: 7995391 Time: 0.191872
[10/24/2023-13:04:52] [V] [TRT] Tactic: 8585215 Time: 0.181888
[10/24/2023-13:04:52] [V] [TRT] Tactic: 8847359 Time: 0.200832
[10/24/2023-13:04:52] [V] [TRT] Tactic: 8978431 Time: 0.196616
[10/24/2023-13:04:52] [V] [TRT] Tactic: 9043967 Time: 0.1824
[10/24/2023-13:04:52] [V] [TRT] Tactic: 9175039 Time: 0.176396
[10/24/2023-13:04:52] [V] [TRT] Tactic: 9502719 Time: 0.19456
[10/24/2023-13:04:52] [V] [TRT] Tactic: 9830399 Time: 0.190244
[10/24/2023-13:04:52] [V] [TRT] Tactic: 9961471 Time: 0.256128
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10027007 Time: 0.1809
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10092543 Time: 0.19776
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10289151 Time: 0.200184
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10485759 Time: 0.178176
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10682367 Time: 0.200832
[10/24/2023-13:04:52] [V] [TRT] Tactic: 10813439 Time: 0.176256
[10/24/2023-13:04:52] [V] [TRT] Fastest Tactic: 983039 Time: 0.171032
[10/24/2023-13:04:52] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:52] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:52] [V] [TRT] Tactic: 2195670545862694453 Time: 0.17886
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:52] [V] [TRT] Tactic: 3419182076704469245 Time: 0.174336
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:52] [V] [TRT] Tactic: 3891805945559659536 Time: 0.202524
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:52] [V] [TRT] Tactic: 5548126322150286555 Time: 0.173064
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:52] [V] [TRT] Tactic: 6057304366605292508 Time: 0.171008
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:52] [V] [TRT] Tactic: -7928611605886347652 Time: 0.206848
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:52] [V] [TRT] Tactic: -5172391392092686714 Time: 0.180608
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:52] [V] [TRT] Tactic: -4374269919094467161 Time: 0.176768
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:52] [V] [TRT] Tactic: -4083394051665370953 Time: 0.099456
[10/24/2023-13:04:52] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:52] [V] [TRT] Tactic: -1546027692247304867 Time: 0.20096
[10/24/2023-13:04:52] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.099456
[10/24/2023-13:04:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:52] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Float(4194304,16384,128,1) ***************
[10/24/2023-13:04:52] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:52] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:52] [V] [TRT] *************** Autotuning format combination: Half(131072,1:8,1024,8) -> Half(524288,1:8,4096,32) ***************
[10/24/2023-13:04:53] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudaDepthwiseConvolution)
[10/24/2023-13:04:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:53] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:53] [V] [TRT] Tactic: 0 Time: 0.525568
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1 Time: 0.958592
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2 Time: 0.536192
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6 Time: 0.310408
[10/24/2023-13:04:53] [V] [TRT] Tactic: 56 Time: 0.526336
[10/24/2023-13:04:53] [V] [TRT] Tactic: 58 Time: 0.53696
[10/24/2023-13:04:53] [V] [TRT] Tactic: 62 Time: 0.310532
[10/24/2023-13:04:53] [V] [TRT] Fastest Tactic: 6 Time: 0.310408
[10/24/2023-13:04:53] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:53] [V] [TRT] Tactic: 254850674756030979 Time: 0.071808
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:53] [V] [TRT] Tactic: 328038211831149625 Time: 0.068628
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:53] [V] [TRT] Tactic: 411553864378931917 Time: 0.076544
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1011057357468998345 Time: 0.06952
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1156328698016730421 Time: 0.063232
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1723736032573714698 Time: 0.069008
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1832046141070096030 Time: 0.071044
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1838082074606840426 Time: 0.07296
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:53] [V] [TRT] Tactic: 1899296423087490472 Time: 0.085888
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2428167804343994714 Time: 0.073088
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2541579301352125276 Time: 0.07232
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2657157263811141609 Time: 0.089088
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2819719497590964443 Time: 0.078848
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2968605903460894194 Time: 0.073088
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:53] [V] [TRT] Tactic: 2986078304285316765 Time: 0.0722
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:53] [V] [TRT] Tactic: 3362537467505018070 Time: 0.067584
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:53] [V] [TRT] Tactic: 3513075359009385578 Time: 0.070928
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:53] [V] [TRT] Tactic: 3573559043797674382 Time: 0.071808
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:53] [V] [TRT] Tactic: 3591970081995419777 Time: 0.095624
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:53] [V] [TRT] Tactic: 3704534001553878387 Time: 0.061312
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:53] [V] [TRT] Tactic: 4278315135102886928 Time: 0.07232
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:53] [V] [TRT] Tactic: 4503233883285355107 Time: 0.096128
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:53] [V] [TRT] Tactic: 4802447371470387646 Time: 0.082436
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5059676457552313631 Time: 0.070664
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5368829646735632944 Time: 0.089884
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5398999388616959893 Time: 0.07232
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5746691132547383910 Time: 0.077184
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5770170567977052602 Time: 0.083464
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:53] [V] [TRT] Tactic: 5953552212833506549 Time: 0.071808
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6034364043891107501 Time: 0.070144
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6074229447555668232 Time: 0.084232
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6154447660803990543 Time: 0.077208
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6325769668000961702 Time: 0.067072
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6350273239113254096 Time: 0.146456
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6377497238381488891 Time: 0.067968
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6446388116965632819 Time: 0.070156
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6468794451065529747 Time: 0.07424
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6642277870194067185 Time: 0.071832
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6859477213531075460 Time: 0.08192
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6972489290272968208 Time: 0.065056
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:53] [V] [TRT] Tactic: 6979044990896381511 Time: 0.06912
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:53] [V] [TRT] Tactic: 7216571380637776659 Time: 0.06784
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:53] [V] [TRT] Tactic: 7609923741161019135 Time: 0.069376
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:53] [V] [TRT] Tactic: 7705739241028240201 Time: 0.0873
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:53] [V] [TRT] Tactic: 8072087735545283117 Time: 0.069892
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:53] [V] [TRT] Tactic: 8101703987960976805 Time: 0.09024
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:53] [V] [TRT] Tactic: 8170606396342855895 Time: 0.07374
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:53] [V] [TRT] Tactic: 8839784824303350101 Time: 0.065948
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:53] [V] [TRT] Tactic: -9217371357561775773 Time: 0.090368
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:53] [V] [TRT] Tactic: -9009272790678027912 Time: 0.08578
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:53] [V] [TRT] Tactic: -8985224497679592364 Time: 0.098304
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:53] [V] [TRT] Tactic: -8949544755481315679 Time: 0.074112
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:53] [V] [TRT] Tactic: -8759929675070720385 Time: 0.067712
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:53] [V] [TRT] Tactic: -8604374562669615024 Time: 0.084868
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6902925267326201166 Time: 0.144768
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6840588038605932325 Time: 0.07296
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6799856376604253964 Time: 0.068612
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6625722781282978136 Time: 0.096532
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6525498856028268801 Time: 0.072704
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6356316196810535311 Time: 0.093084
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:53] [V] [TRT] Tactic: -6324345858751792783 Time: 0.097664
[10/24/2023-13:04:53] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:54] [V] [TRT] Tactic: -6262400699544994312 Time: 0.068096
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:54] [V] [TRT] Tactic: -6257787336162086472 Time: 0.06336
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:54] [V] [TRT] Tactic: -6063766379489217211 Time: 0.070288
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5777580938094193096 Time: 0.068992
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5657273398217409378 Time: 0.06976
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5530886555766748586 Time: 0.071296
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5422685219138380548 Time: 0.071296
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5161596964442251102 Time: 0.076928
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:54] [V] [TRT] Tactic: -5127240325355316006 Time: 0.0704
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4825567853927730435 Time: 0.07296
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4796511246675321840 Time: 0.07872
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4706569565442112734 Time: 0.093488
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4566599693570369588 Time: 0.067456
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4409144516525410768 Time: 0.067968
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4379519430184503304 Time: 0.069516
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4152066959007262150 Time: 0.070572
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:54] [V] [TRT] Tactic: -4021926646879732549 Time: 0.072456
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3987638434926559037 Time: 0.078612
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3905653247016903130 Time: 0.073472
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3903974568488493144 Time: 0.073372
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3895429239811098010 Time: 0.070668
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3864869056275745423 Time: 0.081024
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3601464762214218301 Time: 0.081024
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3412636942650049698 Time: 0.073856
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3338665856053412950 Time: 0.071552
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:54] [V] [TRT] Tactic: -3058330359340425555 Time: 0.076544
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2816084650627734155 Time: 0.08576
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2662892962457732243 Time: 0.070152
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2559894581585337900 Time: 0.07168
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2530740716768816092 Time: 0.101276
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2332828394978346992 Time: 0.065196
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2241736083352441442 Time: 0.067848
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:54] [V] [TRT] Tactic: -2161909437867201546 Time: 0.135296
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:54] [V] [TRT] Tactic: -1985778916402815946 Time: 0.082944
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:54] [V] [TRT] Tactic: -1500496213132463076 Time: 0.075264
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:54] [V] [TRT] Tactic: -1099247066487349374 Time: 0.08412
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:54] [V] [TRT] Tactic: -910286698936744682 Time: 0.098688
[10/24/2023-13:04:54] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:54] [V] [TRT] Tactic: -606726295133751039 Time: 0.097664
[10/24/2023-13:04:54] [V] [TRT] Fastest Tactic: 3704534001553878387 Time: 0.061312
[10/24/2023-13:04:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3704534001553878387
[10/24/2023-13:04:54] [V] [TRT] *************** Autotuning format combination: Half(65536,1:16,512,4) -> Half(262144,1:16,2048,16) ***************
[10/24/2023-13:04:54] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CudnnConvolution)
[10/24/2023-13:04:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:54] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu (CaskConvolution)
[10/24/2023-13:04:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:54] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:54] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:54] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:54] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:54] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:54] [V] [TRT] Tactic: 524287 Time: 0.045952
[10/24/2023-13:04:54] [V] [TRT] Tactic: 1048575 Time: 0.043012
[10/24/2023-13:04:54] [V] [TRT] Tactic: 1703935 Time: 0.04098
[10/24/2023-13:04:54] [V] [TRT] Tactic: 2228223 Time: 0.048976
[10/24/2023-13:04:54] [V] [TRT] Tactic: 2424831 Time: 0.050564
[10/24/2023-13:04:54] [V] [TRT] Tactic: 2621439 Time: 0.038424
[10/24/2023-13:04:54] [V] [TRT] Tactic: 3014655 Time: 0.045056
[10/24/2023-13:04:54] [V] [TRT] Tactic: 3604479 Time: 0.047616
[10/24/2023-13:04:54] [V] [TRT] Tactic: 5046271 Time: 0.041372
[10/24/2023-13:04:54] [V] [TRT] Tactic: 6160383 Time: 0.044544
[10/24/2023-13:04:54] [V] [TRT] Tactic: 6488063 Time: 0.047
[10/24/2023-13:04:54] [V] [TRT] Tactic: 7864319 Time: 0.039936
[10/24/2023-13:04:54] [V] [TRT] Tactic: 8585215 Time: 0.051348
[10/24/2023-13:04:54] [V] [TRT] Tactic: 8847359 Time: 0.0521
[10/24/2023-13:04:54] [V] [TRT] Tactic: 9043967 Time: 0.042376
[10/24/2023-13:04:55] [V] [TRT] Tactic: 9175039 Time: 0.047488
[10/24/2023-13:04:55] [V] [TRT] Tactic: 9961471 Time: 0.047744
[10/24/2023-13:04:55] [V] [TRT] Tactic: 10027007 Time: 0.038912
[10/24/2023-13:04:55] [V] [TRT] Tactic: 10485759 Time: 0.039832
[10/24/2023-13:04:55] [V] [TRT] Tactic: 10682367 Time: 0.03778
[10/24/2023-13:04:55] [V] [TRT] Fastest Tactic: 10682367 Time: 0.03778
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:55] [V] [TRT] Tactic: 0 Time: 0.093696
[10/24/2023-13:04:55] [V] [TRT] Tactic: 1 Time: 0.093568
[10/24/2023-13:04:55] [V] [TRT] Tactic: 2 Time: 0.093952
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4 Time: 0.78834
[10/24/2023-13:04:55] [V] [TRT] Tactic: 5 Time: 0.283776
[10/24/2023-13:04:55] [V] [TRT] Tactic: 6 Time: 0.035968
[10/24/2023-13:04:55] [V] [TRT] Tactic: 56 Time: 0.093952
[10/24/2023-13:04:55] [V] [TRT] Tactic: 57 Time: 0.093824
[10/24/2023-13:04:55] [V] [TRT] Tactic: 58 Time: 0.093696
[10/24/2023-13:04:55] [V] [TRT] Tactic: 60 Time: 0.789648
[10/24/2023-13:04:55] [V] [TRT] Tactic: 61 Time: 0.314496
[10/24/2023-13:04:55] [V] [TRT] Tactic: 62 Time: 0.03584
[10/24/2023-13:04:55] [V] [TRT] Tactic: 112 Time: 0.093824
[10/24/2023-13:04:55] [V] [TRT] Tactic: 113 Time: 0.093696
[10/24/2023-13:04:55] [V] [TRT] Tactic: 114 Time: 0.093912
[10/24/2023-13:04:55] [V] [TRT] Tactic: 116 Time: 0.788872
[10/24/2023-13:04:55] [V] [TRT] Tactic: 117 Time: 0.26356
[10/24/2023-13:04:55] [V] [TRT] Tactic: 118 Time: 0.03586
[10/24/2023-13:04:55] [V] [TRT] Fastest Tactic: 62 Time: 0.03584
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4549827808004681195 Time: 0.089088
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:55] [V] [TRT] Tactic: 5779835512569528575 Time: 0.1467
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:55] [V] [TRT] Tactic: 6053873026024413720 Time: 0.153244
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:55] [V] [TRT] Tactic: 6767548733843469815 Time: 0.086056
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:55] [V] [TRT] Tactic: -6313876406580483184 Time: 0.077072
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:55] [V] [TRT] Tactic: -1123676555321336786 Time: 0.14786
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:55] [V] [TRT] Tactic: -701551393537224327 Time: 0.091904
[10/24/2023-13:04:55] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.077072
[10/24/2023-13:04:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:55] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(49152,1,384,3) ***************
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:55] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:55] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:55] [V] [TRT] Tactic: 2086609538387166260 Time: 0.188416
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:55] [V] [TRT] Tactic: 2860655430572478466 Time: 0.086424
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:55] [V] [TRT] Tactic: 3239733199291090177 Time: 0.188288
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4474630279712975759 Time: 0.0512
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050944
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4517590677127196184 Time: 0.290176
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188288
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:55] [V] [TRT] Tactic: 4696204239951173149 Time: 0.087272
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:55] [V] [TRT] Tactic: 5778138195697110003 Time: 0.146304
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:55] [V] [TRT] Tactic: 6310198979346901507 Time: 0.182528
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:04:55] [V] [TRT] Tactic: 7155825427510256858 Time: 0.14234
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:04:55] [V] [TRT] Tactic: 7222247112373541608 Time: 0.124044
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:04:55] [V] [TRT] Tactic: 7342025736444949634 Time: 0.06276
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:04:55] [V] [TRT] Tactic: 7472640475524677095 Time: 0.192
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:04:55] [V] [TRT] Tactic: 8498373915030836990 Time: 0.313496
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:04:55] [V] [TRT] Tactic: 8869697132622550639 Time: 0.158872
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:04:55] [V] [TRT] Tactic: 8918020581761223752 Time: 0.141184
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:04:55] [V] [TRT] Tactic: -8937725997228636978 Time: 0.165888
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:04:55] [V] [TRT] Tactic: -8833858409138163072 Time: 0.292748
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:04:55] [V] [TRT] Tactic: -7989138351613022500 Time: 0.138496
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:04:55] [V] [TRT] Tactic: -7872883691240863058 Time: 0.188416
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:04:55] [V] [TRT] Tactic: -7377458734869418330 Time: 0.05824
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:04:55] [V] [TRT] Tactic: -6729618519651721910 Time: 0.189184
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:04:55] [V] [TRT] Tactic: -5893833996418445881 Time: 0.162176
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:04:55] [V] [TRT] Tactic: -5701562095007058349 Time: 0.295064
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:04:55] [V] [TRT] Tactic: -5685503422376017600 Time: 0.121728
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:04:55] [V] [TRT] Tactic: -5521125187060117489 Time: 0.140416
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:04:55] [V] [TRT] Tactic: -5457304872213719461 Time: 0.058376
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:04:55] [V] [TRT] Tactic: -4756382386362004279 Time: 0.086016
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:04:55] [V] [TRT] Tactic: -4615000974950361663 Time: 0.139008
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:04:55] [V] [TRT] Tactic: -4314913710375142296 Time: 0.138644
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:04:55] [V] [TRT] Tactic: -3855385237722507464 Time: 0.147456
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:04:55] [V] [TRT] Tactic: -3697587361057948972 Time: 0.120832
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:04:55] [V] [TRT] Tactic: -2809379259463049391 Time: 0.146452
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:04:55] [V] [TRT] Tactic: -2747929399988666512 Time: 0.28736
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:04:55] [V] [TRT] Tactic: -1472061967969061456 Time: 0.305664
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:04:55] [V] [TRT] Tactic: -504296718212024303 Time: 0.141316
[10/24/2023-13:04:55] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:04:55] [V] [TRT] Tactic: -444093195553988951 Time: 0.191244
[10/24/2023-13:04:55] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050944
[10/24/2023-13:04:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[10/24/2023-13:04:55] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(49152,16384,128,1) ***************
[10/24/2023-13:04:56] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:56] [V] [TRT] Tactic: 0 Time: 0.196736
[10/24/2023-13:04:56] [V] [TRT] Tactic: 1 Time: 0.08256
[10/24/2023-13:04:56] [V] [TRT] Tactic: 2 Time: 0.22948
[10/24/2023-13:04:56] [V] [TRT] Tactic: 4 Time: 0.788352
[10/24/2023-13:04:56] [V] [TRT] Tactic: 5 Time: 0.324096
[10/24/2023-13:04:56] [V] [TRT] Tactic: 6 Time: 0.542844
[10/24/2023-13:04:56] [V] [TRT] Tactic: 56 Time: 0.197224
[10/24/2023-13:04:56] [V] [TRT] Tactic: 58 Time: 0.22912
[10/24/2023-13:04:56] [V] [TRT] Tactic: 60 Time: 0.787768
[10/24/2023-13:04:56] [V] [TRT] Tactic: 61 Time: 0.298392
[10/24/2023-13:04:56] [V] [TRT] Tactic: 62 Time: 0.549648
[10/24/2023-13:04:56] [V] [TRT] Fastest Tactic: 1 Time: 0.08256
[10/24/2023-13:04:56] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:56] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:04:56] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(32768,16384:2,128,1) ***************
[10/24/2023-13:04:56] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:56] [V] [TRT] Tactic: 524287 Time: 0.036224
[10/24/2023-13:04:56] [V] [TRT] Tactic: 1048575 Time: 0.035328
[10/24/2023-13:04:56] [V] [TRT] Tactic: 1703935 Time: 0.029568
[10/24/2023-13:04:56] [V] [TRT] Tactic: 2228223 Time: 0.038016
[10/24/2023-13:04:56] [V] [TRT] Tactic: 2424831 Time: 0.041856
[10/24/2023-13:04:56] [V] [TRT] Tactic: 2621439 Time: 0.030592
[10/24/2023-13:04:56] [V] [TRT] Tactic: 3014655 Time: 0.032512
[10/24/2023-13:04:56] [V] [TRT] Tactic: 3604479 Time: 0.031744
[10/24/2023-13:04:56] [V] [TRT] Tactic: 5046271 Time: 0.033792
[10/24/2023-13:04:56] [V] [TRT] Tactic: 6160383 Time: 0.034816
[10/24/2023-13:04:56] [V] [TRT] Tactic: 6488063 Time: 0.04224
[10/24/2023-13:04:56] [V] [TRT] Tactic: 7864319 Time: 0.031744
[10/24/2023-13:04:56] [V] [TRT] Tactic: 8585215 Time: 0.041984
[10/24/2023-13:04:56] [V] [TRT] Tactic: 8847359 Time: 0.034688
[10/24/2023-13:04:56] [V] [TRT] Tactic: 9043967 Time: 0.033792
[10/24/2023-13:04:56] [V] [TRT] Tactic: 9175039 Time: 0.031512
[10/24/2023-13:04:56] [V] [TRT] Tactic: 9961471 Time: 0.037912
[10/24/2023-13:04:56] [V] [TRT] Tactic: 10027007 Time: 0.03202
[10/24/2023-13:04:56] [V] [TRT] Tactic: 10485759 Time: 0.030352
[10/24/2023-13:04:56] [V] [TRT] Tactic: 10682367 Time: 0.030444
[10/24/2023-13:04:56] [V] [TRT] Fastest Tactic: 1703935 Time: 0.029568
[10/24/2023-13:04:56] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:56] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:56] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:04:56] [V] [TRT] Tactic: 2195670545862694453 Time: 0.040084
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:04:56] [V] [TRT] Tactic: 3419182076704469245 Time: 0.058388
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:04:56] [V] [TRT] Tactic: 3891805945559659536 Time: 0.101248
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:04:56] [V] [TRT] Tactic: 5548126322150286555 Time: 0.05736
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:04:56] [V] [TRT] Tactic: 6057304366605292508 Time: 0.05632
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:04:56] [V] [TRT] Tactic: -7928611605886347652 Time: 0.103296
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:04:56] [V] [TRT] Tactic: -5172391392092686714 Time: 0.041216
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:04:56] [V] [TRT] Tactic: -4374269919094467161 Time: 0.036844
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:04:56] [V] [TRT] Tactic: -4083394051665370953 Time: 0.020616
[10/24/2023-13:04:56] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:04:56] [V] [TRT] Tactic: -1546027692247304867 Time: 0.100352
[10/24/2023-13:04:56] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.020616
[10/24/2023-13:04:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:04:56] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Float(49152,16384,128,1) ***************
[10/24/2023-13:04:57] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:57] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:57] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:57] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:04:57] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:57] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:57] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:04:57] [V] [TRT] Tactic: 254850674756030979 Time: 0.031724
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:04:57] [V] [TRT] Tactic: 328038211831149625 Time: 0.03072
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:04:57] [V] [TRT] Tactic: 411553864378931917 Time: 0.022528
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1011057357468998345 Time: 0.034816
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1156328698016730421 Time: 0.032652
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1723736032573714698 Time: 0.033792
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1832046141070096030 Time: 0.0224
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1838082074606840426 Time: 0.022784
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:04:57] [V] [TRT] Tactic: 1899296423087490472 Time: 0.027648
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2428167804343994714 Time: 0.021504
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033792
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2657157263811141609 Time: 0.028204
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2819719497590964443 Time: 0.041856
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2968605903460894194 Time: 0.022804
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:04:57] [V] [TRT] Tactic: 2986078304285316765 Time: 0.033792
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:04:57] [V] [TRT] Tactic: 3362537467505018070 Time: 0.033536
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:04:57] [V] [TRT] Tactic: 3513075359009385578 Time: 0.031744
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:04:57] [V] [TRT] Tactic: 3573559043797674382 Time: 0.022548
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:04:57] [V] [TRT] Tactic: 3591970081995419777 Time: 0.024576
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:04:57] [V] [TRT] Tactic: 3704534001553878387 Time: 0.031616
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:04:57] [V] [TRT] Tactic: 4278315135102886928 Time: 0.036864
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:04:57] [V] [TRT] Tactic: 4503233883285355107 Time: 0.016384
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:04:57] [V] [TRT] Tactic: 4802447371470387646 Time: 0.022528
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5059676457552313631 Time: 0.031404
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5368829646735632944 Time: 0.026368
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5398999388616959893 Time: 0.02092
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5746691132547383910 Time: 0.040576
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5770170567977052602 Time: 0.023176
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:04:57] [V] [TRT] Tactic: 5953552212833506549 Time: 0.019456
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6034364043891107501 Time: 0.035908
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6074229447555668232 Time: 0.027648
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6154447660803990543 Time: 0.022784
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6325769668000961702 Time: 0.033792
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6350273239113254096 Time: 0.022784
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6377497238381488891 Time: 0.033792
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6446388116965632819 Time: 0.0224
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6468794451065529747 Time: 0.023424
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6642277870194067185 Time: 0.032648
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6859477213531075460 Time: 0.026368
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6972489290272968208 Time: 0.03264
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:04:57] [V] [TRT] Tactic: 6979044990896381511 Time: 0.03072
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:04:57] [V] [TRT] Tactic: 7216571380637776659 Time: 0.022528
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:04:57] [V] [TRT] Tactic: 7609923741161019135 Time: 0.022144
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:04:57] [V] [TRT] Tactic: 7705739241028240201 Time: 0.028544
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:04:57] [V] [TRT] Tactic: 8072087735545283117 Time: 0.05632
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:04:57] [V] [TRT] Tactic: 8101703987960976805 Time: 0.02944
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:04:57] [V] [TRT] Tactic: 8170606396342855895 Time: 0.023168
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:04:57] [V] [TRT] Tactic: 8839784824303350101 Time: 0.020644
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:04:57] [V] [TRT] Tactic: -9217371357561775773 Time: 0.029696
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:04:57] [V] [TRT] Tactic: -9009272790678027912 Time: 0.023552
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:04:57] [V] [TRT] Tactic: -8985224497679592364 Time: 0.016384
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:04:57] [V] [TRT] Tactic: -8949544755481315679 Time: 0.023552
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:04:57] [V] [TRT] Tactic: -8759929675070720385 Time: 0.032776
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:04:57] [V] [TRT] Tactic: -8604374562669615024 Time: 0.02752
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6902925267326201166 Time: 0.021656
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6840588038605932325 Time: 0.037888
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6799856376604253964 Time: 0.055576
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6625722781282978136 Time: 0.016384
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6525498856028268801 Time: 0.019456
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6356316196810535311 Time: 0.029972
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:04:57] [V] [TRT] Tactic: -6324345858751792783 Time: 0.016384
[10/24/2023-13:04:57] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:04:58] [V] [TRT] Tactic: -6262400699544994312 Time: 0.055296
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:04:58] [V] [TRT] Tactic: -6257787336162086472 Time: 0.032768
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:04:58] [V] [TRT] Tactic: -6063766379489217211 Time: 0.021656
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5777580938094193096 Time: 0.03648
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5657273398217409378 Time: 0.03072
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5530886555766748586 Time: 0.033664
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5422685219138380548 Time: 0.020736
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5161596964442251102 Time: 0.039936
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:04:58] [V] [TRT] Tactic: -5127240325355316006 Time: 0.03626
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4825567853927730435 Time: 0.021376
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4796511246675321840 Time: 0.04096
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4706569565442112734 Time: 0.03072
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4566599693570369588 Time: 0.033792
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4409144516525410768 Time: 0.033792
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4379519430184503304 Time: 0.021652
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4152066959007262150 Time: 0.031744
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:04:58] [V] [TRT] Tactic: -4021926646879732549 Time: 0.037528
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3987638434926559037 Time: 0.04096
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3905653247016903130 Time: 0.021376
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3903974568488493144 Time: 0.022656
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3895429239811098010 Time: 0.036868
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3864869056275745423 Time: 0.021904
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3601464762214218301 Time: 0.0256
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3412636942650049698 Time: 0.021504
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3338665856053412950 Time: 0.019456
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:04:58] [V] [TRT] Tactic: -3058330359340425555 Time: 0.039808
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2816084650627734155 Time: 0.023552
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034816
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2559894581585337900 Time: 0.031744
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2530740716768816092 Time: 0.017408
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2332828394978346992 Time: 0.032668
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2241736083352441442 Time: 0.022528
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:04:58] [V] [TRT] Tactic: -2161909437867201546 Time: 0.022528
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:04:58] [V] [TRT] Tactic: -1985778916402815946 Time: 0.022528
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:04:58] [V] [TRT] Tactic: -1500496213132463076 Time: 0.023984
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:04:58] [V] [TRT] Tactic: -1099247066487349374 Time: 0.026624
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:04:58] [V] [TRT] Tactic: -910286698936744682 Time: 0.026624
[10/24/2023-13:04:58] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:04:58] [V] [TRT] Tactic: -606726295133751039 Time: 0.017152
[10/24/2023-13:04:58] [V] [TRT] Fastest Tactic: 4503233883285355107 Time: 0.016384
[10/24/2023-13:04:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4503233883285355107
[10/24/2023-13:04:58] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:04:58] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CudnnConvolution)
[10/24/2023-13:04:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:58] [V] [TRT] --------------- Timing Runner: /heads_list.5/dim/dim.1/Conv (CaskConvolution)
[10/24/2023-13:04:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:58] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:04:58] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:04:58] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:04:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:58] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (FusedConvActConvolution)
[10/24/2023-13:04:58] [V] [TRT] Tactic: 524287 Time: 0.046368
[10/24/2023-13:04:58] [V] [TRT] Tactic: 720895 Time: 0.068764
[10/24/2023-13:04:58] [V] [TRT] Tactic: 983039 Time: 0.06656
[10/24/2023-13:04:58] [V] [TRT] Tactic: 1048575 Time: 0.042752
[10/24/2023-13:04:58] [V] [TRT] Tactic: 1703935 Time: 0.04096
[10/24/2023-13:04:59] [V] [TRT] Tactic: 1769471 Time: 0.072704
[10/24/2023-13:04:59] [V] [TRT] Tactic: 1966079 Time: 0.078976
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2031615 Time: 0.085892
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2228223 Time: 0.048904
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2424831 Time: 0.050176
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2621439 Time: 0.038144
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2752511 Time: 0.061312
[10/24/2023-13:04:59] [V] [TRT] Tactic: 3014655 Time: 0.045056
[10/24/2023-13:04:59] [V] [TRT] Tactic: 3145727 Time: 0.060592
[10/24/2023-13:04:59] [V] [TRT] Tactic: 3604479 Time: 0.047232
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4390911 Time: 0.088832
[10/24/2023-13:04:59] [V] [TRT] Tactic: 5046271 Time: 0.0416
[10/24/2023-13:04:59] [V] [TRT] Tactic: 5963775 Time: 0.071688
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6160383 Time: 0.044928
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6488063 Time: 0.047104
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6881279 Time: 0.072704
[10/24/2023-13:04:59] [V] [TRT] Tactic: 7274495 Time: 0.068224
[10/24/2023-13:04:59] [V] [TRT] Tactic: 7864319 Time: 0.039936
[10/24/2023-13:04:59] [V] [TRT] Tactic: 7995391 Time: 0.078208
[10/24/2023-13:04:59] [V] [TRT] Tactic: 8585215 Time: 0.05056
[10/24/2023-13:04:59] [V] [TRT] Tactic: 8847359 Time: 0.052224
[10/24/2023-13:04:59] [V] [TRT] Tactic: 8978431 Time: 0.073344
[10/24/2023-13:04:59] [V] [TRT] Tactic: 9043967 Time: 0.041856
[10/24/2023-13:04:59] [V] [TRT] Tactic: 9175039 Time: 0.047376
[10/24/2023-13:04:59] [V] [TRT] Tactic: 9502719 Time: 0.083984
[10/24/2023-13:04:59] [V] [TRT] Tactic: 9961471 Time: 0.047104
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10027007 Time: 0.038916
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10092543 Time: 0.08898
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10289151 Time: 0.079104
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10485759 Time: 0.03904
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10682367 Time: 0.037524
[10/24/2023-13:04:59] [V] [TRT] Tactic: 10813439 Time: 0.070152
[10/24/2023-13:04:59] [V] [TRT] Fastest Tactic: 10682367 Time: 0.037524
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:04:59] [V] [TRT] Tactic: 0 Time: 0.093196
[10/24/2023-13:04:59] [V] [TRT] Tactic: 1 Time: 0.09346
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2 Time: 0.093452
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4 Time: 0.603372
[10/24/2023-13:04:59] [V] [TRT] Tactic: 5 Time: 0.264816
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6 Time: 0.035868
[10/24/2023-13:04:59] [V] [TRT] Tactic: 56 Time: 0.093196
[10/24/2023-13:04:59] [V] [TRT] Tactic: 57 Time: 0.0932
[10/24/2023-13:04:59] [V] [TRT] Tactic: 58 Time: 0.09332
[10/24/2023-13:04:59] [V] [TRT] Tactic: 60 Time: 0.604024
[10/24/2023-13:04:59] [V] [TRT] Tactic: 61 Time: 0.340476
[10/24/2023-13:04:59] [V] [TRT] Tactic: 62 Time: 0.035852
[10/24/2023-13:04:59] [V] [TRT] Tactic: 112 Time: 0.093208
[10/24/2023-13:04:59] [V] [TRT] Tactic: 113 Time: 0.093212
[10/24/2023-13:04:59] [V] [TRT] Tactic: 114 Time: 0.093196
[10/24/2023-13:04:59] [V] [TRT] Tactic: 116 Time: 0.603124
[10/24/2023-13:04:59] [V] [TRT] Tactic: 117 Time: 0.275572
[10/24/2023-13:04:59] [V] [TRT] Tactic: 118 Time: 0.035852
[10/24/2023-13:04:59] [V] [TRT] Fastest Tactic: 62 Time: 0.035852
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4549827808004681195 Time: 0.08896
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[10/24/2023-13:04:59] [V] [TRT] Tactic: 5779835512569528575 Time: 0.1467
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6053873026024413720 Time: 0.153344
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6767548733843469815 Time: 0.086144
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[10/24/2023-13:04:59] [V] [TRT] Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[10/24/2023-13:04:59] [V] [TRT] Tactic: -1123676555321336786 Time: 0.147968
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[10/24/2023-13:04:59] [V] [TRT] Tactic: -701551393537224327 Time: 0.09166
[10/24/2023-13:04:59] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.0768
[10/24/2023-13:04:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[10/24/2023-13:04:59] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(32768,1,256,2) ***************
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:04:59] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:04:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:59] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:04:59] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:04:59] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2086609538387166260 Time: 0.188416
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[10/24/2023-13:04:59] [V] [TRT] Tactic: 2860655430572478466 Time: 0.086308
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[10/24/2023-13:04:59] [V] [TRT] Tactic: 3239733199291090177 Time: 0.188416
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4474630279712975759 Time: 0.051328
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4479823862704990365 Time: 0.0512
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4517590677127196184 Time: 0.290176
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4634080872644479428 Time: 0.188184
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[10/24/2023-13:04:59] [V] [TRT] Tactic: 4696204239951173149 Time: 0.08718
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[10/24/2023-13:04:59] [V] [TRT] Tactic: 5778138195697110003 Time: 0.146176
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[10/24/2023-13:04:59] [V] [TRT] Tactic: 6310198979346901507 Time: 0.182408
[10/24/2023-13:04:59] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7155825427510256858 Time: 0.142336
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7222247112373541608 Time: 0.124188
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7342025736444949634 Time: 0.062732
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7472640475524677095 Time: 0.191768
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8498373915030836990 Time: 0.313624
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8869697132622550639 Time: 0.158976
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8918020581761223752 Time: 0.14116
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[10/24/2023-13:05:00] [V] [TRT] Tactic: -8937725997228636978 Time: 0.165888
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[10/24/2023-13:05:00] [V] [TRT] Tactic: -8833858409138163072 Time: 0.292864
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[10/24/2023-13:05:00] [V] [TRT] Tactic: -7989138351613022500 Time: 0.138368
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[10/24/2023-13:05:00] [V] [TRT] Tactic: -7872883691240863058 Time: 0.188176
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[10/24/2023-13:05:00] [V] [TRT] Tactic: -7377458734869418330 Time: 0.058368
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[10/24/2023-13:05:00] [V] [TRT] Tactic: -6729618519651721910 Time: 0.189056
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[10/24/2023-13:05:00] [V] [TRT] Tactic: -5893833996418445881 Time: 0.162448
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[10/24/2023-13:05:00] [V] [TRT] Tactic: -5701562095007058349 Time: 0.296452
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[10/24/2023-13:05:00] [V] [TRT] Tactic: -5685503422376017600 Time: 0.121728
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[10/24/2023-13:05:00] [V] [TRT] Tactic: -5521125187060117489 Time: 0.140416
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[10/24/2023-13:05:00] [V] [TRT] Tactic: -5457304872213719461 Time: 0.058368
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[10/24/2023-13:05:00] [V] [TRT] Tactic: -4756382386362004279 Time: 0.086016
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[10/24/2023-13:05:00] [V] [TRT] Tactic: -4615000974950361663 Time: 0.139264
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[10/24/2023-13:05:00] [V] [TRT] Tactic: -4314913710375142296 Time: 0.13888
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[10/24/2023-13:05:00] [V] [TRT] Tactic: -3855385237722507464 Time: 0.147456
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[10/24/2023-13:05:00] [V] [TRT] Tactic: -3697587361057948972 Time: 0.120832
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[10/24/2023-13:05:00] [V] [TRT] Tactic: -2809379259463049391 Time: 0.146432
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[10/24/2023-13:05:00] [V] [TRT] Tactic: -2747929399988666512 Time: 0.289432
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[10/24/2023-13:05:00] [V] [TRT] Tactic: -1472061967969061456 Time: 0.307328
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[10/24/2023-13:05:00] [V] [TRT] Tactic: -504296718212024303 Time: 0.14144
[10/24/2023-13:05:00] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[10/24/2023-13:05:00] [V] [TRT] Tactic: -444093195553988951 Time: 0.190876
[10/24/2023-13:05:00] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.0512
[10/24/2023-13:05:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[10/24/2023-13:05:00] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:05:00] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:05:00] [V] [TRT] Tactic: 0 Time: 0.098304
[10/24/2023-13:05:00] [V] [TRT] Tactic: 1 Time: 0.097944
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2 Time: 0.098176
[10/24/2023-13:05:00] [V] [TRT] Tactic: 4 Time: 0.60376
[10/24/2023-13:05:00] [V] [TRT] Tactic: 5 Time: 0.27954
[10/24/2023-13:05:00] [V] [TRT] Tactic: 6 Time: 0.541052
[10/24/2023-13:05:00] [V] [TRT] Tactic: 56 Time: 0.098048
[10/24/2023-13:05:00] [V] [TRT] Tactic: 58 Time: 0.098176
[10/24/2023-13:05:00] [V] [TRT] Tactic: 60 Time: 0.60478
[10/24/2023-13:05:00] [V] [TRT] Tactic: 61 Time: 0.321936
[10/24/2023-13:05:00] [V] [TRT] Tactic: 62 Time: 0.541568
[10/24/2023-13:05:00] [V] [TRT] Fastest Tactic: 1 Time: 0.097944
[10/24/2023-13:05:00] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:05:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[10/24/2023-13:05:00] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:05:00] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (FusedConvActConvolution)
[10/24/2023-13:05:00] [V] [TRT] Tactic: 524287 Time: 0.034816
[10/24/2023-13:05:00] [V] [TRT] Tactic: 720895 Time: 0.053524
[10/24/2023-13:05:00] [V] [TRT] Tactic: 983039 Time: 0.050048
[10/24/2023-13:05:00] [V] [TRT] Tactic: 1048575 Time: 0.03376
[10/24/2023-13:05:00] [V] [TRT] Tactic: 1703935 Time: 0.028672
[10/24/2023-13:05:00] [V] [TRT] Tactic: 1769471 Time: 0.05632
[10/24/2023-13:05:00] [V] [TRT] Tactic: 1966079 Time: 0.058368
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2031615 Time: 0.066984
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2228223 Time: 0.03684
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2424831 Time: 0.039056
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2621439 Time: 0.029312
[10/24/2023-13:05:00] [V] [TRT] Tactic: 2752511 Time: 0.049128
[10/24/2023-13:05:00] [V] [TRT] Tactic: 3014655 Time: 0.030592
[10/24/2023-13:05:00] [V] [TRT] Tactic: 3145727 Time: 0.047224
[10/24/2023-13:05:00] [V] [TRT] Tactic: 3604479 Time: 0.030464
[10/24/2023-13:05:00] [V] [TRT] Tactic: 4390911 Time: 0.064492
[10/24/2023-13:05:00] [V] [TRT] Tactic: 5046271 Time: 0.031756
[10/24/2023-13:05:00] [V] [TRT] Tactic: 5963775 Time: 0.054272
[10/24/2023-13:05:00] [V] [TRT] Tactic: 6160383 Time: 0.032768
[10/24/2023-13:05:00] [V] [TRT] Tactic: 6488063 Time: 0.039952
[10/24/2023-13:05:00] [V] [TRT] Tactic: 6881279 Time: 0.058632
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7274495 Time: 0.050156
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7864319 Time: 0.030464
[10/24/2023-13:05:00] [V] [TRT] Tactic: 7995391 Time: 0.056972
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8585215 Time: 0.039936
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8847359 Time: 0.033664
[10/24/2023-13:05:00] [V] [TRT] Tactic: 8978431 Time: 0.053632
[10/24/2023-13:05:00] [V] [TRT] Tactic: 9043967 Time: 0.03262
[10/24/2023-13:05:00] [V] [TRT] Tactic: 9175039 Time: 0.030352
[10/24/2023-13:05:00] [V] [TRT] Tactic: 9502719 Time: 0.064516
[10/24/2023-13:05:00] [V] [TRT] Tactic: 9961471 Time: 0.036844
[10/24/2023-13:05:00] [V] [TRT] Tactic: 10027007 Time: 0.0306
[10/24/2023-13:05:01] [V] [TRT] Tactic: 10092543 Time: 0.064512
[10/24/2023-13:05:01] [V] [TRT] Tactic: 10289151 Time: 0.058376
[10/24/2023-13:05:01] [V] [TRT] Tactic: 10485759 Time: 0.028928
[10/24/2023-13:05:01] [V] [TRT] Tactic: 10682367 Time: 0.029312
[10/24/2023-13:05:01] [V] [TRT] Tactic: 10813439 Time: 0.050048
[10/24/2023-13:05:01] [V] [TRT] Fastest Tactic: 1703935 Time: 0.028672
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:05:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2195670545862694453 Time: 0.04008
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3419182076704469245 Time: 0.058368
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3891805945559659536 Time: 0.10112
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5548126322150286555 Time: 0.057504
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6057304366605292508 Time: 0.05632
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[10/24/2023-13:05:01] [V] [TRT] Tactic: -7928611605886347652 Time: 0.103424
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[10/24/2023-13:05:01] [V] [TRT] Tactic: -5172391392092686714 Time: 0.041112
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[10/24/2023-13:05:01] [V] [TRT] Tactic: -4374269919094467161 Time: 0.036864
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[10/24/2023-13:05:01] [V] [TRT] Tactic: -4083394051665370953 Time: 0.020508
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[10/24/2023-13:05:01] [V] [TRT] Tactic: -1546027692247304867 Time: 0.100368
[10/24/2023-13:05:01] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.020508
[10/24/2023-13:05:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[10/24/2023-13:05:01] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:05:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:05:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:01] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudaDepthwiseConvolution)
[10/24/2023-13:05:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:05:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:01] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[10/24/2023-13:05:01] [V] [TRT] Tactic: 254850674756030979 Time: 0.031744
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[10/24/2023-13:05:01] [V] [TRT] Tactic: 328038211831149625 Time: 0.03072
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[10/24/2023-13:05:01] [V] [TRT] Tactic: 411553864378931917 Time: 0.02254
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1011057357468998345 Time: 0.034816
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1156328698016730421 Time: 0.032768
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1723736032573714698 Time: 0.033792
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1832046141070096030 Time: 0.022408
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1838082074606840426 Time: 0.022656
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[10/24/2023-13:05:01] [V] [TRT] Tactic: 1899296423087490472 Time: 0.027412
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2428167804343994714 Time: 0.021504
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033792
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2657157263811141609 Time: 0.028416
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2819719497590964443 Time: 0.041756
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2968605903460894194 Time: 0.022804
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[10/24/2023-13:05:01] [V] [TRT] Tactic: 2986078304285316765 Time: 0.033792
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3362537467505018070 Time: 0.033664
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3513075359009385578 Time: 0.031768
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3573559043797674382 Time: 0.022656
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3591970081995419777 Time: 0.024576
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:01] [V] [TRT] Tactic: 3704534001553878387 Time: 0.031744
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[10/24/2023-13:05:01] [V] [TRT] Tactic: 4278315135102886928 Time: 0.036864
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:05:01] [V] [TRT] Tactic: 4503233883285355107 Time: 0.016384
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[10/24/2023-13:05:01] [V] [TRT] Tactic: 4802447371470387646 Time: 0.022528
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5059676457552313631 Time: 0.031128
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5368829646735632944 Time: 0.026496
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5398999388616959893 Time: 0.020916
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5746691132547383910 Time: 0.040472
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5770170567977052602 Time: 0.022812
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[10/24/2023-13:05:01] [V] [TRT] Tactic: 5953552212833506549 Time: 0.019456
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6034364043891107501 Time: 0.035864
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6074229447555668232 Time: 0.027544
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6154447660803990543 Time: 0.022684
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6325769668000961702 Time: 0.033792
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6350273239113254096 Time: 0.022672
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6377497238381488891 Time: 0.033664
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6446388116965632819 Time: 0.0224
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6468794451065529747 Time: 0.023552
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6642277870194067185 Time: 0.03264
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6859477213531075460 Time: 0.026624
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6972489290272968208 Time: 0.032768
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:01] [V] [TRT] Tactic: 6979044990896381511 Time: 0.03072
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[10/24/2023-13:05:01] [V] [TRT] Tactic: 7216571380637776659 Time: 0.022528
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[10/24/2023-13:05:01] [V] [TRT] Tactic: 7609923741161019135 Time: 0.02176
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[10/24/2023-13:05:01] [V] [TRT] Tactic: 7705739241028240201 Time: 0.028564
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[10/24/2023-13:05:01] [V] [TRT] Tactic: 8072087735545283117 Time: 0.05632
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[10/24/2023-13:05:01] [V] [TRT] Tactic: 8101703987960976805 Time: 0.029448
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:05:01] [V] [TRT] Tactic: 8170606396342855895 Time: 0.02306
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[10/24/2023-13:05:01] [V] [TRT] Tactic: 8839784824303350101 Time: 0.020508
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[10/24/2023-13:05:01] [V] [TRT] Tactic: -9217371357561775773 Time: 0.029696
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[10/24/2023-13:05:01] [V] [TRT] Tactic: -9009272790678027912 Time: 0.023552
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[10/24/2023-13:05:01] [V] [TRT] Tactic: -8985224497679592364 Time: 0.016412
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[10/24/2023-13:05:01] [V] [TRT] Tactic: -8949544755481315679 Time: 0.023552
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[10/24/2023-13:05:01] [V] [TRT] Tactic: -8759929675070720385 Time: 0.032772
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[10/24/2023-13:05:01] [V] [TRT] Tactic: -8604374562669615024 Time: 0.02752
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[10/24/2023-13:05:01] [V] [TRT] Tactic: -6902925267326201166 Time: 0.021644
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[10/24/2023-13:05:01] [V] [TRT] Tactic: -6840588038605932325 Time: 0.037888
[10/24/2023-13:05:01] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6799856376604253964 Time: 0.055584
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6625722781282978136 Time: 0.016168
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6525498856028268801 Time: 0.019456
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6356316196810535311 Time: 0.029848
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6324345858751792783 Time: 0.016384
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6262400699544994312 Time: 0.055296
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6257787336162086472 Time: 0.032768
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[10/24/2023-13:05:02] [V] [TRT] Tactic: -6063766379489217211 Time: 0.022016
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5777580938094193096 Time: 0.03648
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5657273398217409378 Time: 0.03072
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5530886555766748586 Time: 0.033536
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5422685219138380548 Time: 0.020648
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5161596964442251102 Time: 0.039936
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[10/24/2023-13:05:02] [V] [TRT] Tactic: -5127240325355316006 Time: 0.036588
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4825567853927730435 Time: 0.021504
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4796511246675321840 Time: 0.040704
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4706569565442112734 Time: 0.030592
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4566599693570369588 Time: 0.033796
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4409144516525410768 Time: 0.033792
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4379519430184503304 Time: 0.021516
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4152066959007262150 Time: 0.031744
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[10/24/2023-13:05:02] [V] [TRT] Tactic: -4021926646879732549 Time: 0.037632
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3987638434926559037 Time: 0.040788
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3905653247016903130 Time: 0.021376
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3903974568488493144 Time: 0.022544
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3895429239811098010 Time: 0.036864
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3864869056275745423 Time: 0.022156
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3601464762214218301 Time: 0.0256
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3412636942650049698 Time: 0.021504
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3338665856053412950 Time: 0.019456
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[10/24/2023-13:05:02] [V] [TRT] Tactic: -3058330359340425555 Time: 0.03968
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2816084650627734155 Time: 0.023552
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034816
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2559894581585337900 Time: 0.031744
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2530740716768816092 Time: 0.017296
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2332828394978346992 Time: 0.032768
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2241736083352441442 Time: 0.022528
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[10/24/2023-13:05:02] [V] [TRT] Tactic: -2161909437867201546 Time: 0.022528
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[10/24/2023-13:05:02] [V] [TRT] Tactic: -1985778916402815946 Time: 0.022548
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[10/24/2023-13:05:02] [V] [TRT] Tactic: -1500496213132463076 Time: 0.023744
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[10/24/2023-13:05:02] [V] [TRT] Tactic: -1099247066487349374 Time: 0.026624
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[10/24/2023-13:05:02] [V] [TRT] Tactic: -910286698936744682 Time: 0.026624
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[10/24/2023-13:05:02] [V] [TRT] Tactic: -606726295133751039 Time: 0.016896
[10/24/2023-13:05:02] [V] [TRT] Fastest Tactic: -6625722781282978136 Time: 0.016168
[10/24/2023-13:05:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CudnnConvolution)
[10/24/2023-13:05:02] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:02] [V] [TRT] --------------- Timing Runner: /heads_list.5/rot/rot.1/Conv (CaskConvolution)
[10/24/2023-13:05:02] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[10/24/2023-13:05:02] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(32768,1,256,2) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] =============== Computing costs for 
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(4194304,16384,128,1) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(4194304,1,32768,256) -> Float(32768,1,256,2) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Float(1048576,1:4,8192,64) -> Float(16384,1:4,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(4194304,16384,128,1) -> Half(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(2097152,16384:2,128,1) -> Half(16384,16384:2,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Float(32768,16384,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(524288,1:8,4096,32) -> Half(16384,1:8,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] *************** Autotuning format combination: Half(262144,1:16,2048,16) -> Half(16384,1:16,128,1) ***************
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu (input) from Half(4194304,16384,128,1) to Half(524288,1:8,4096,32)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) ((Unnamed Layer* 24) [Shuffle]_output) from Half(256,1,1,1) to Half(32,1:8,32,32)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) ((Unnamed Layer* 25) [Shuffle]_output) from Half(256,1,1,1) to Half(32,1:8,32,32)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])) ((Unnamed Layer* 58) [Shuffle]_output) from Half(256,1,1,1) to Half(32,1:8,32,32)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])) ((Unnamed Layer* 59) [Shuffle]_output) from Half(256,1,1,1) to Half(32,1:8,32,32)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/center/center.1/Conv (reg_0) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv (height_0) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/dim/dim.1/Conv (dim_0) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/rot/rot.1/Conv (rot_0) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/vel/vel.1/Conv (vel_0) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.0/hm/hm.1/Conv (hm_0) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/center/center.1/Conv (reg_1) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv (height_1) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/dim/dim.1/Conv (dim_1) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/rot/rot.1/Conv (rot_1) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/vel/vel.1/Conv (vel_1) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.1/hm/hm.1/Conv (hm_1) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/center/center.1/Conv (reg_2) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv (height_2) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/dim/dim.1/Conv (dim_2) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/rot/rot.1/Conv (rot_2) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/vel/vel.1/Conv (vel_2) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.2/hm/hm.1/Conv (hm_2) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/center/center.1/Conv (reg_3) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv (height_3) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/dim/dim.1/Conv (dim_3) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/rot/rot.1/Conv (rot_3) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/vel/vel.1/Conv (vel_3) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.3/hm/hm.1/Conv (hm_3) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/center/center.1/Conv (reg_4) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv (height_4) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/dim/dim.1/Conv (dim_4) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/rot/rot.1/Conv (rot_4) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/vel/vel.1/Conv (vel_4) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.4/hm/hm.1/Conv (hm_4) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/center/center.1/Conv (reg_5) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv (height_5) from Half(16384,1:8,128,1) to Half(16384,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/dim/dim.1/Conv (dim_5) from Half(16384,1:8,128,1) to Half(49152,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/rot/rot.1/Conv (rot_5) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/vel/vel.1/Conv (vel_5) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to /heads_list.5/hm/hm.1/Conv (hm_5) from Half(16384,1:8,128,1) to Half(32768,16384,128,1)
[10/24/2023-13:05:02] [V] [TRT] Formats and tactics selection completed in 147.367 seconds.
[10/24/2023-13:05:02] [V] [TRT] After reformat layers: 105 layers
[10/24/2023-13:05:02] [I] [TRT] [BlockAssignment] Algorithm Linear took 0.008845ms to assign 65 blocks to 65 nodes requiring 4478470144 bytes.
[10/24/2023-13:05:02] [V] [TRT] Pre-optimized block assignment.
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 2097152
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 512
[10/24/2023-13:05:02] [V] [TRT] Block size 512
[10/24/2023-13:05:02] [V] [TRT] Block size 512
[10/24/2023-13:05:02] [V] [TRT] Block size 512
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 262144
[10/24/2023-13:05:02] [V] [TRT] Block size 4294967296
[10/24/2023-13:05:02] [I] [TRT] Total Activation Memory: 183502848
[10/24/2023-13:05:02] [I] [TRT] Detected 1 inputs and 36 output network tensors.
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.7/Conv + /backbone_2d/blocks.0/blocks.0.9/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.10/Conv + /backbone_2d/blocks.0/blocks.0.12/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.13/Conv + /backbone_2d/blocks.0/blocks.0.15/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.0/blocks.0.16/Conv + /backbone_2d/blocks.0/blocks.0.18/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.7/Conv + /backbone_2d/blocks.1/blocks.1.9/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.10/Conv + /backbone_2d/blocks.1/blocks.1.12/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.13/Conv + /backbone_2d/blocks.1/blocks.1.15/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] /backbone_2d/blocks.1/blocks.1.16/Conv + /backbone_2d/blocks.1/blocks.1.18/Relu Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[10/24/2023-13:05:02] [V] [TRT] /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.0/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.1/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.2/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.3/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.4/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/center/center.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/center_z/center_z.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/dim/dim.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/rot/rot.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/vel/vel.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] /heads_list.5/hm/hm.1/Conv Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.0.1.running_mean + (Unnamed Layer* 24) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.0.1.running_var + (Unnamed Layer* 25) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu Host Persistent: 2400 Device Persistent: 590848 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.7/Conv + /backbone_2d/blocks.0/blocks.0.9/Relu Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.10/Conv + /backbone_2d/blocks.0/blocks.0.12/Relu Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.13/Conv + /backbone_2d/blocks.0/blocks.0.15/Relu Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.0/blocks.0.16/Conv + /backbone_2d/blocks.0/blocks.0.18/Relu Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose Host Persistent: 0 Device Persistent: 0 Scratch Memory: 12582912
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu Host Persistent: 2400 Device Persistent: 591360 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu Host Persistent: 2400 Device Persistent: 1181184 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.7/Conv + /backbone_2d/blocks.1/blocks.1.9/Relu Host Persistent: 2400 Device Persistent: 1181184 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.10/Conv + /backbone_2d/blocks.1/blocks.1.12/Relu Host Persistent: 2400 Device Persistent: 1181184 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.13/Conv + /backbone_2d/blocks.1/blocks.1.15/Relu Host Persistent: 2400 Device Persistent: 1181184 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/blocks.1/blocks.1.16/Conv + /backbone_2d/blocks.1/blocks.1.18/Relu Host Persistent: 2400 Device Persistent: 1181184 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose Host Persistent: 0 Device Persistent: 0 Scratch Memory: 10485760
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.1.1.running_mean + (Unnamed Layer* 58) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.1.1.running_var + (Unnamed Layer* 59) [Shuffle] Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])) Host Persistent: 476 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu Host Persistent: 1664 Device Persistent: 688640 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu Host Persistent: 1664 Device Persistent: 689664 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.0/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu Host Persistent: 1664 Device Persistent: 689664 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.1/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu Host Persistent: 1664 Device Persistent: 689664 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.2/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.3/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu Host Persistent: 1664 Device Persistent: 689664 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.4/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/center/center.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center/center.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/center_z/center_z.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu Host Persistent: 1664 Device Persistent: 394240 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/dim/dim.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/dim/dim.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/rot/rot.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/rot/rot.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/vel/vel.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/vel/vel.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: /heads_list.5/hm/hm.1/Conv Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[10/24/2023-13:05:02] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/hm/hm.1/Conv Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[10/24/2023-13:05:02] [I] [TRT] Total Host Persistent Memory: 126144
[10/24/2023-13:05:02] [I] [TRT] Total Device Persistent Memory: 12759552
[10/24/2023-13:05:02] [I] [TRT] Total Scratch Memory: 12582912
[10/24/2023-13:05:02] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 9 MiB, GPU 52 MiB
[10/24/2023-13:05:02] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 2.06572ms to assign 5 blocks to 66 nodes requiring 39846400 bytes.
[10/24/2023-13:05:02] [V] [TRT] Optimized block assignment.
[10/24/2023-13:05:02] [V] [TRT] Block size 16777216
[10/24/2023-13:05:02] [V] [TRT] Block size 10485760
[10/24/2023-13:05:02] [V] [TRT] Block size 8388608
[10/24/2023-13:05:02] [V] [TRT] Block size 4194304
[10/24/2023-13:05:02] [V] [TRT] Block size 512
[10/24/2023-13:05:02] [V] [TRT] Total Activation Memory: 39846400
[10/24/2023-13:05:02] [V] [TRT] Using cublasLt as a tactic source
[10/24/2023-13:05:02] [W] [TRT] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.1 but loaded cuBLAS/cuBLAS LT 11.5.2
[10/24/2023-13:05:02] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2556, GPU 30575 (MiB)
[10/24/2023-13:05:02] [V] [TRT] Using cuDNN as a tactic source
[10/24/2023-13:05:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2556, GPU 30585 (MiB)
[10/24/2023-13:05:02] [V] [TRT] Engine generation completed in 148.985 seconds.
[10/24/2023-13:05:02] [V] [TRT] Deleting timing cache: 732 entries, 3146 hits
[10/24/2023-13:05:02] [V] [TRT] Engine Layer Information:
Layer(Constant): model.backbone_2d.deblocks.0.1.running_mean + (Unnamed Layer* 24) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 24) [Shuffle]_output[Half(1,256,1,1)]
Layer(Constant): model.backbone_2d.deblocks.0.1.running_var + (Unnamed Layer* 25) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 25) [Shuffle]_output[Half(1,256,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, Tactic: 0, input[Half(1,256,128,128)] -> Reformatted Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu[Half(1,256,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, Tactic: -4566599693570369588, Reformatted Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu[Half(1,256,128,128)] -> /backbone_2d/blocks.0/blocks.0.3/Relu_output_0[Half(1,128,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu, Tactic: 6979044990896381511, /backbone_2d/blocks.0/blocks.0.3/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.0/blocks.0.6/Relu_output_0[Half(1,128,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.7/Conv + /backbone_2d/blocks.0/blocks.0.9/Relu, Tactic: 6979044990896381511, /backbone_2d/blocks.0/blocks.0.6/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.0/blocks.0.9/Relu_output_0[Half(1,128,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.10/Conv + /backbone_2d/blocks.0/blocks.0.12/Relu, Tactic: 6979044990896381511, /backbone_2d/blocks.0/blocks.0.9/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.0/blocks.0.12/Relu_output_0[Half(1,128,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.13/Conv + /backbone_2d/blocks.0/blocks.0.15/Relu, Tactic: 6979044990896381511, /backbone_2d/blocks.0/blocks.0.12/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.0/blocks.0.15/Relu_output_0[Half(1,128,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.0/blocks.0.16/Conv + /backbone_2d/blocks.0/blocks.0.18/Relu, Tactic: 6979044990896381511, /backbone_2d/blocks.0/blocks.0.15/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.0/blocks.0.18/Relu_output_0[Half(1,128,128,128)]
Layer(GemmDeconvolution): /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose, Tactic: 0, /backbone_2d/blocks.0/blocks.0.18/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0[Half(1,256,128,128)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Tactic: 0, (Unnamed Layer* 24) [Shuffle]_output[Half(1,256,1,1)] -> Reformatted Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))[Half(1,256,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Tactic: 0, (Unnamed Layer* 25) [Shuffle]_output[Half(1,256,1,1)] -> Reformatted Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))[Half(1,256,1,1)]
Layer(PointWiseV2): PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Tactic: 21, /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0[Half(1,256,128,128)], Reformatted Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))[Half(1,256,1,1)], Reformatted Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))[Half(1,256,1,1)] -> (Unnamed Layer* 30) [ElementWise]_output[Half(1,256,128,128)]
Layer(Scale): model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu, Tactic: 0, (Unnamed Layer* 30) [ElementWise]_output[Half(1,256,128,128)] -> /backbone_2d/Concat_output_0[Half(1,256,128,128)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu, Tactic: -2332828394978346992, /backbone_2d/blocks.0/blocks.0.18/Relu_output_0[Half(1,128,128,128)] -> /backbone_2d/blocks.1/blocks.1.3/Relu_output_0[Half(1,256,64,64)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu, Tactic: -3338665856053412950, /backbone_2d/blocks.1/blocks.1.3/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/blocks.1/blocks.1.6/Relu_output_0[Half(1,256,64,64)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.7/Conv + /backbone_2d/blocks.1/blocks.1.9/Relu, Tactic: -3338665856053412950, /backbone_2d/blocks.1/blocks.1.6/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/blocks.1/blocks.1.9/Relu_output_0[Half(1,256,64,64)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.10/Conv + /backbone_2d/blocks.1/blocks.1.12/Relu, Tactic: -3338665856053412950, /backbone_2d/blocks.1/blocks.1.9/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/blocks.1/blocks.1.12/Relu_output_0[Half(1,256,64,64)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.13/Conv + /backbone_2d/blocks.1/blocks.1.15/Relu, Tactic: -3338665856053412950, /backbone_2d/blocks.1/blocks.1.12/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/blocks.1/blocks.1.15/Relu_output_0[Half(1,256,64,64)]
Layer(CaskConvolution): /backbone_2d/blocks.1/blocks.1.16/Conv + /backbone_2d/blocks.1/blocks.1.18/Relu, Tactic: -3338665856053412950, /backbone_2d/blocks.1/blocks.1.15/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/blocks.1/blocks.1.18/Relu_output_0[Half(1,256,64,64)]
Layer(GemmDeconvolution): /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose, Tactic: 0, /backbone_2d/blocks.1/blocks.1.18/Relu_output_0[Half(1,256,64,64)] -> /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0[Half(1,256,128,128)]
Layer(Constant): model.backbone_2d.deblocks.1.1.running_mean + (Unnamed Layer* 58) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 58) [Shuffle]_output[Half(1,256,1,1)]
Layer(Constant): model.backbone_2d.deblocks.1.1.running_var + (Unnamed Layer* 59) [Shuffle], Tactic: 0,  -> (Unnamed Layer* 59) [Shuffle]_output[Half(1,256,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Tactic: 0, (Unnamed Layer* 58) [Shuffle]_output[Half(1,256,1,1)] -> Reformatted Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))[Half(1,256,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Tactic: 0, (Unnamed Layer* 59) [Shuffle]_output[Half(1,256,1,1)] -> Reformatted Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))[Half(1,256,1,1)]
Layer(PointWiseV2): PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Tactic: 21, /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0[Half(1,256,128,128)], Reformatted Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))[Half(1,256,1,1)], Reformatted Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))[Half(1,256,1,1)] -> (Unnamed Layer* 64) [ElementWise]_output[Half(1,256,128,128)]
Layer(Scale): model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu, Tactic: 0, (Unnamed Layer* 64) [ElementWise]_output[Half(1,256,128,128)] -> /backbone_2d/Concat_output_0[Half(1,256,128,128)]
Layer(CaskConvolution): /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu, Tactic: 8170606396342855895, /backbone_2d/Concat_output_0[Half(1,512,128,128)] -> /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)]
Layer(CaskConvolution): /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Tactic: 3704534001553878387, /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)] -> /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,512,128,128)]
Layer(CaskConvolution): /heads_list.0/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/center/center.1/Conv[Half(1,2,128,128)] -> reg_0[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.0/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_0[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.0/dim/dim.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_0[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.0/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_0[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.0/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_0[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.0/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.0/hm/hm.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.0/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.0/hm/hm.1/Conv[Half(1,1,128,128)] -> hm_0[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.1/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/center/center.1/Conv[Half(1,2,128,128)] -> reg_1[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.1/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_1[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Tactic: 3704534001553878387, /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)] -> /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,512,128,128)]
Layer(CaskConvolution): /heads_list.1/dim/dim.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_1[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.1/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_1[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.1/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_1[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.1/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.1/hm/hm.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.1/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.1/hm/hm.1/Conv[Half(1,2,128,128)] -> hm_1[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.2/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/center/center.1/Conv[Half(1,2,128,128)] -> reg_2[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.2/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_2[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.2/dim/dim.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_2[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.2/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_2[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Tactic: 3704534001553878387, /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)] -> /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,512,128,128)]
Layer(CaskConvolution): /heads_list.2/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_2[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.2/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.2/hm/hm.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.2/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.2/hm/hm.1/Conv[Half(1,2,128,128)] -> hm_2[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.3/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/center/center.1/Conv[Half(1,2,128,128)] -> reg_3[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.3/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_3[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.3/dim/dim.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_3[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.3/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_3[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.3/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_3[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.3/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.3/hm/hm.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.3/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.3/hm/hm.1/Conv[Half(1,1,128,128)] -> hm_3[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Tactic: 3704534001553878387, /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)] -> /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,512,128,128)]
Layer(CaskConvolution): /heads_list.4/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/center/center.1/Conv[Half(1,2,128,128)] -> reg_4[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.4/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_4[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.4/dim/dim.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_4[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.4/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_4[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.4/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_4[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.4/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.4/hm/hm.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.4/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.4/hm/hm.1/Conv[Half(1,2,128,128)] -> hm_4[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.5/center/center.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/center/center.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center/center.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/center/center.1/Conv[Half(1,2,128,128)] -> reg_5[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.5/center_z/center_z.1/Conv, Tactic: -6625722781282978136, /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv[Half(1,1,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv[Half(1,1,128,128)] -> height_5[Half(1,1,128,128)]
Layer(CaskConvolution): /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Tactic: 3704534001553878387, /shared_conv/shared_conv.2/Relu_output_0[Half(1,64,128,128)] -> /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu[Half(1,256,128,128)]
Layer(CaskConvolution): /heads_list.5/dim/dim.1/Conv, Tactic: 4503233883285355107, /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/dim/dim.1/Conv[Half(1,3,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/dim/dim.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/dim/dim.1/Conv[Half(1,3,128,128)] -> dim_5[Half(1,3,128,128)]
Layer(CaskConvolution): /heads_list.5/rot/rot.1/Conv, Tactic: -6625722781282978136, /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/rot/rot.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/rot/rot.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/rot/rot.1/Conv[Half(1,2,128,128)] -> rot_5[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.5/vel/vel.1/Conv, Tactic: -6625722781282978136, /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/vel/vel.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/vel/vel.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/vel/vel.1/Conv[Half(1,2,128,128)] -> vel_5[Half(1,2,128,128)]
Layer(CaskConvolution): /heads_list.5/hm/hm.1/Conv, Tactic: -6625722781282978136, /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu[Half(1,64,128,128)] -> Reformatted Output Tensor 0 to /heads_list.5/hm/hm.1/Conv[Half(1,2,128,128)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to /heads_list.5/hm/hm.1/Conv, Tactic: 0, Reformatted Output Tensor 0 to /heads_list.5/hm/hm.1/Conv[Half(1,2,128,128)] -> hm_5[Half(1,2,128,128)]
[10/24/2023-13:05:02] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 2555 MiB, GPU 30551 MiB
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2565, GPU 30535 (MiB)
[10/24/2023-13:05:03] [I] [TRT] Loaded engine size: 13 MiB
[10/24/2023-13:05:03] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 2565 MiB, GPU 30535 MiB
[10/24/2023-13:05:03] [V] [TRT] Using cublasLt as a tactic source
[10/24/2023-13:05:03] [W] [TRT] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.1 but loaded cuBLAS/cuBLAS LT 11.5.2
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2567, GPU 30561 (MiB)
[10/24/2023-13:05:03] [V] [TRT] Using cuDNN as a tactic source
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2567, GPU 30569 (MiB)
[10/24/2023-13:05:03] [V] [TRT] Deserialization required 14792 microseconds.
[10/24/2023-13:05:03] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 2567 MiB, GPU 30551 MiB
[10/24/2023-13:05:03] [I] Engine built in 153.574 sec.
[10/24/2023-13:05:03] [I] Layer Information:
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2315, GPU 30505 (MiB)
[10/24/2023-13:05:03] [I] Layers:
Name: model.backbone_2d.deblocks.0.1.running_mean + (Unnamed Layer* 24) [Shuffle], LayerType: Constant, Inputs: [], Outputs: [ { Name: (Unnamed Layer* 24) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], ParameterType: Constant, weights: {"Type": "Half", "Count": 256}, dimensions: [1,256,1,1], TacticValue: 0x0
Name: model.backbone_2d.deblocks.0.1.running_var + (Unnamed Layer* 25) [Shuffle], LayerType: Constant, Inputs: [], Outputs: [ { Name: (Unnamed Layer* 25) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], ParameterType: Constant, weights: {"Type": "Half", "Count": 256}, dimensions: [1,256,1,1], TacticValue: 0x0
Name: Reformatting CopyNode for Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, LayerType: Reformat, Inputs: [ { Name: input, Dimensions: [1,256,128,128], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, LayerType: CaskConvolution, Inputs: [ { Name: Reformatted Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.3/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xc0a02dc6095497cc
Name: /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.3/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.6/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47
Name: /backbone_2d/blocks.0/blocks.0.7/Conv + /backbone_2d/blocks.0/blocks.0.9/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.6/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.9/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47
Name: /backbone_2d/blocks.0/blocks.0.10/Conv + /backbone_2d/blocks.0/blocks.0.12/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.9/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.12/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47
Name: /backbone_2d/blocks.0/blocks.0.13/Conv + /backbone_2d/blocks.0/blocks.0.15/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.12/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.15/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47
Name: /backbone_2d/blocks.0/blocks.0.16/Conv + /backbone_2d/blocks.0/blocks.0.18/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.15/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47
Name: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose, LayerType: GemmDeconvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 32768}, Bias: {"Type": "Half", "Count": 0}, AllowSparse: 0, Activation: NONE, TacticValue: 0x0
Name: Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), LayerType: Reformat, Inputs: [ { Name: (Unnamed Layer* 24) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), LayerType: Reformat, Inputs: [ { Name: (Unnamed Layer* 25) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), LayerType: PointWiseV2, Inputs: [ { Name: /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }, { Name: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }, { Name: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: (Unnamed Layer* 30) [ElementWise]_output, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 3, InputArgs: ["arg0", "arg1", "arg2"], NbOutputVars: 1, OutputVars: ["var3"], NbParams: 0, Params: [], NbLiterals: 2, Literals: ["0.000000e+00f", "1.000000e-03f"], NbOperations: 4, Operations: ["const auto var0 = pwgen::iMinus(arg0, arg1);", "const auto var1 = pwgen::iPlus(arg2, literal1);", "const auto var2 = pwgen::iSqrt(var1);", "const auto var3 = pwgen::iDiv(var0, var2);"], TacticValue: 0x15
Name: model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu, LayerType: Scale, Inputs: [ { Name: (Unnamed Layer* 30) [ElementWise]_output, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/Concat_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Scale, Mode: CHANNEL, Shift: {"Type": "Half", "Count": 256}, Scale: {"Type": "Half", "Count": 256}, Power: {"Type": "Half", "Count": 0}, Activation: RELU, ChannelAxis: 1, TacticValue: 0x0
Name: /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.0/blocks.0.18/Relu_output_0, Dimensions: [1,128,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.3/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16, TacticValue: 0xdfa020ef435ef810
Name: /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.3/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.6/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xd1aaad17ca35fbaa
Name: /backbone_2d/blocks.1/blocks.1.7/Conv + /backbone_2d/blocks.1/blocks.1.9/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.6/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.9/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xd1aaad17ca35fbaa
Name: /backbone_2d/blocks.1/blocks.1.10/Conv + /backbone_2d/blocks.1/blocks.1.12/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.9/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.12/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xd1aaad17ca35fbaa
Name: /backbone_2d/blocks.1/blocks.1.13/Conv + /backbone_2d/blocks.1/blocks.1.15/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.12/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.15/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xd1aaad17ca35fbaa
Name: /backbone_2d/blocks.1/blocks.1.16/Conv + /backbone_2d/blocks.1/blocks.1.18/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.15/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/blocks.1/blocks.1.18/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xd1aaad17ca35fbaa
Name: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose, LayerType: GemmDeconvolution, Inputs: [ { Name: /backbone_2d/blocks.1/blocks.1.18/Relu_output_0, Dimensions: [1,256,64,64], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [2,2], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 262144}, Bias: {"Type": "Half", "Count": 0}, AllowSparse: 0, Activation: NONE, TacticValue: 0x0
Name: model.backbone_2d.deblocks.1.1.running_mean + (Unnamed Layer* 58) [Shuffle], LayerType: Constant, Inputs: [], Outputs: [ { Name: (Unnamed Layer* 58) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], ParameterType: Constant, weights: {"Type": "Half", "Count": 256}, dimensions: [1,256,1,1], TacticValue: 0x0
Name: model.backbone_2d.deblocks.1.1.running_var + (Unnamed Layer* 59) [Shuffle], LayerType: Constant, Inputs: [], Outputs: [ { Name: (Unnamed Layer* 59) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], ParameterType: Constant, weights: {"Type": "Half", "Count": 256}, dimensions: [1,256,1,1], TacticValue: 0x0
Name: Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), LayerType: Reformat, Inputs: [ { Name: (Unnamed Layer* 58) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), LayerType: Reformat, Inputs: [ { Name: (Unnamed Layer* 59) [Shuffle]_output, Dimensions: [1,256,1,1], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), LayerType: PointWiseV2, Inputs: [ { Name: /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }, { Name: Reformatted Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }, { Name: Reformatted Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise])), Dimensions: [1,256,1,1], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: (Unnamed Layer* 64) [ElementWise]_output, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: PointWise, ParameterSubType: PointWiseExpression, NbInputArgs: 3, InputArgs: ["arg0", "arg1", "arg2"], NbOutputVars: 1, OutputVars: ["var3"], NbParams: 0, Params: [], NbLiterals: 2, Literals: ["0.000000e+00f", "1.000000e-03f"], NbOperations: 4, Operations: ["const auto var0 = pwgen::iMinus(arg0, arg1);", "const auto var1 = pwgen::iPlus(arg2, literal1);", "const auto var2 = pwgen::iSqrt(var1);", "const auto var3 = pwgen::iDiv(var0, var2);"], TacticValue: 0x15
Name: model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu, LayerType: Scale, Inputs: [ { Name: (Unnamed Layer* 64) [ElementWise]_output, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /backbone_2d/Concat_output_0, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Scale, Mode: CHANNEL, Shift: {"Type": "Half", "Count": 256}, Scale: {"Type": "Half", "Count": 256}, Power: {"Type": "Half", "Count": 0}, Activation: RELU, ChannelAxis: 1, TacticValue: 0x0
Name: /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /backbone_2d/Concat_output_0, Dimensions: [1,512,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 64}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1, TacticValue: 0x7163d33a4d8ce8d7
Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,512,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1, TacticValue: 0x3369260c04f9ad73
Name: /heads_list.0/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_0, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.0/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_0, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.0/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_0, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.0/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_0, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.0/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_0, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.0/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/hm/hm.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.0/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.0/hm/hm.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_0, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_1, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_1, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,512,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1, TacticValue: 0x3369260c04f9ad73
Name: /heads_list.1/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_1, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_1, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_1, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.1/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.1/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.1/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_1, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_2, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_2, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_2, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_2, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,512,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1, TacticValue: 0x3369260c04f9ad73
Name: /heads_list.2/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_2, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.2/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.2/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.2/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_2, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_3, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_3, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_3, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_3, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_3, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.3/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/hm/hm.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.3/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.3/hm/hm.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_3, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,512,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1, TacticValue: 0x3369260c04f9ad73
Name: /heads_list.4/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_4, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_4, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_4, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_4, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_4, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.4/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.4/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.4/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_4, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/center/center.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center/center.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/center/center.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_5, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/center_z/center_z.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv, Dimensions: [1,1,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_5, Dimensions: [1,1,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, LayerType: CaskConvolution, Inputs: [ { Name: /shared_conv/shared_conv.2/Relu_output_0, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Dimensions: [1,256,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1, TacticValue: 0x3369260c04f9ad73
Name: /heads_list.5/dim/dim.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/dim/dim.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/dim/dim.1/Conv, Dimensions: [1,3,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_5, Dimensions: [1,3,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/rot/rot.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/rot/rot.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/rot/rot.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_5, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/vel/vel.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/vel/vel.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/vel/vel.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_5, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: /heads_list.5/hm/hm.1/Conv, LayerType: CaskConvolution, Inputs: [ { Name: /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu, Dimensions: [1,64,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8
Name: Reformatting CopyNode for Output Tensor 0 to /heads_list.5/hm/hm.1/Conv, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to /heads_list.5/hm/hm.1/Conv, Dimensions: [1,2,128,128], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_5, Dimensions: [1,2,128,128], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0

Bindings:
input
reg_0
height_0
dim_0
rot_0
vel_0
hm_0
reg_1
height_1
dim_1
rot_1
vel_1
hm_1
reg_2
height_2
dim_2
rot_2
vel_2
hm_2
reg_3
height_3
dim_3
rot_3
vel_3
hm_3
reg_4
height_4
dim_4
rot_4
vel_4
hm_4
reg_5
height_5
dim_5
rot_5
vel_5
hm_5
[10/24/2023-13:05:03] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 2315 MiB, GPU 30505 MiB
[10/24/2023-13:05:03] [V] [TRT] Using cublasLt as a tactic source
[10/24/2023-13:05:03] [W] [TRT] TensorRT was linked against cuBLAS/cuBLAS LT 11.6.1 but loaded cuBLAS/cuBLAS LT 11.5.2
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2315, GPU 30515 (MiB)
[10/24/2023-13:05:03] [V] [TRT] Using cuDNN as a tactic source
[10/24/2023-13:05:03] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2315, GPU 30523 (MiB)
[10/24/2023-13:05:03] [V] [TRT] Total per-runner device memory is 12759552
[10/24/2023-13:05:03] [V] [TRT] Total per-runner host memory is 126144
[10/24/2023-13:05:03] [V] [TRT] Allocated activation device memory of size 39846400
[10/24/2023-13:05:03] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2315 MiB, GPU 30577 MiB
[10/24/2023-13:05:03] [I] Using random values for input input
[10/24/2023-13:05:03] [I] Created input binding for input with dimensions 1x256x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_0
[10/24/2023-13:05:03] [I] Created output binding for reg_0 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_0
[10/24/2023-13:05:03] [I] Created output binding for height_0 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_0
[10/24/2023-13:05:03] [I] Created output binding for dim_0 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_0
[10/24/2023-13:05:03] [I] Created output binding for rot_0 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_0
[10/24/2023-13:05:03] [I] Created output binding for vel_0 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_0
[10/24/2023-13:05:03] [I] Created output binding for hm_0 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_1
[10/24/2023-13:05:03] [I] Created output binding for reg_1 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_1
[10/24/2023-13:05:03] [I] Created output binding for height_1 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_1
[10/24/2023-13:05:03] [I] Created output binding for dim_1 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_1
[10/24/2023-13:05:03] [I] Created output binding for rot_1 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_1
[10/24/2023-13:05:03] [I] Created output binding for vel_1 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_1
[10/24/2023-13:05:03] [I] Created output binding for hm_1 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_2
[10/24/2023-13:05:03] [I] Created output binding for reg_2 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_2
[10/24/2023-13:05:03] [I] Created output binding for height_2 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_2
[10/24/2023-13:05:03] [I] Created output binding for dim_2 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_2
[10/24/2023-13:05:03] [I] Created output binding for rot_2 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_2
[10/24/2023-13:05:03] [I] Created output binding for vel_2 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_2
[10/24/2023-13:05:03] [I] Created output binding for hm_2 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_3
[10/24/2023-13:05:03] [I] Created output binding for reg_3 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_3
[10/24/2023-13:05:03] [I] Created output binding for height_3 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_3
[10/24/2023-13:05:03] [I] Created output binding for dim_3 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_3
[10/24/2023-13:05:03] [I] Created output binding for rot_3 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_3
[10/24/2023-13:05:03] [I] Created output binding for vel_3 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_3
[10/24/2023-13:05:03] [I] Created output binding for hm_3 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_4
[10/24/2023-13:05:03] [I] Created output binding for reg_4 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_4
[10/24/2023-13:05:03] [I] Created output binding for height_4 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_4
[10/24/2023-13:05:03] [I] Created output binding for dim_4 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_4
[10/24/2023-13:05:03] [I] Created output binding for rot_4 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_4
[10/24/2023-13:05:03] [I] Created output binding for vel_4 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_4
[10/24/2023-13:05:03] [I] Created output binding for hm_4 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output reg_5
[10/24/2023-13:05:03] [I] Created output binding for reg_5 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output height_5
[10/24/2023-13:05:03] [I] Created output binding for height_5 with dimensions 1x1x128x128
[10/24/2023-13:05:03] [I] Using random values for output dim_5
[10/24/2023-13:05:03] [I] Created output binding for dim_5 with dimensions 1x3x128x128
[10/24/2023-13:05:03] [I] Using random values for output rot_5
[10/24/2023-13:05:03] [I] Created output binding for rot_5 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output vel_5
[10/24/2023-13:05:03] [I] Created output binding for vel_5 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Using random values for output hm_5
[10/24/2023-13:05:03] [I] Created output binding for hm_5 with dimensions 1x2x128x128
[10/24/2023-13:05:03] [I] Starting inference
[10/24/2023-13:05:06] [I] Warmup completed 87 queries over 200 ms
[10/24/2023-13:05:06] [I] Timing trace has 1177 queries over 3.00677 s
[10/24/2023-13:05:06] [I] 
[10/24/2023-13:05:06] [I] === Trace details ===
[10/24/2023-13:05:06] [I] Trace averages of 10 runs:
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27348 ms - Host latency: 2.80192 ms (end to end 4.38069 ms, enqueue 0.699632 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27441 ms - Host latency: 2.79786 ms (end to end 4.39436 ms, enqueue 0.688986 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27533 ms - Host latency: 2.79911 ms (end to end 4.41303 ms, enqueue 0.668623 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27655 ms - Host latency: 2.80059 ms (end to end 4.37654 ms, enqueue 0.686688 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27154 ms - Host latency: 2.79778 ms (end to end 4.38637 ms, enqueue 0.73085 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27441 ms - Host latency: 2.80173 ms (end to end 4.40961 ms, enqueue 0.710617 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27461 ms - Host latency: 2.80346 ms (end to end 4.39604 ms, enqueue 0.767636 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27656 ms - Host latency: 2.80304 ms (end to end 4.42224 ms, enqueue 0.679236 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27431 ms - Host latency: 2.79745 ms (end to end 4.42202 ms, enqueue 0.613458 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.26949 ms - Host latency: 2.79603 ms (end to end 4.3804 ms, enqueue 0.751645 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27338 ms - Host latency: 2.79876 ms (end to end 4.39147 ms, enqueue 0.647705 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27133 ms - Host latency: 2.79657 ms (end to end 4.37849 ms, enqueue 0.69697 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27256 ms - Host latency: 2.79724 ms (end to end 4.40683 ms, enqueue 0.675552 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27175 ms - Host latency: 2.79538 ms (end to end 4.39362 ms, enqueue 0.674173 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27164 ms - Host latency: 2.79724 ms (end to end 4.3928 ms, enqueue 0.71153 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27206 ms - Host latency: 2.79857 ms (end to end 4.40143 ms, enqueue 0.735437 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27378 ms - Host latency: 2.80184 ms (end to end 4.38668 ms, enqueue 0.716083 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2738 ms - Host latency: 2.80355 ms (end to end 4.40694 ms, enqueue 0.706415 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27266 ms - Host latency: 2.79701 ms (end to end 4.39907 ms, enqueue 0.59187 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27443 ms - Host latency: 2.80027 ms (end to end 4.41386 ms, enqueue 0.689996 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27502 ms - Host latency: 2.803 ms (end to end 4.40807 ms, enqueue 0.714941 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27275 ms - Host latency: 2.80088 ms (end to end 4.37382 ms, enqueue 0.957623 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27533 ms - Host latency: 2.8001 ms (end to end 4.40021 ms, enqueue 0.700562 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2742 ms - Host latency: 2.80054 ms (end to end 4.39349 ms, enqueue 0.737604 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27401 ms - Host latency: 2.80104 ms (end to end 4.41031 ms, enqueue 0.706934 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2741 ms - Host latency: 2.79741 ms (end to end 4.38535 ms, enqueue 0.63446 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27369 ms - Host latency: 2.80039 ms (end to end 4.39391 ms, enqueue 0.757465 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27473 ms - Host latency: 2.80031 ms (end to end 4.39034 ms, enqueue 0.721936 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27247 ms - Host latency: 2.7962 ms (end to end 4.37721 ms, enqueue 0.607556 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27276 ms - Host latency: 2.7965 ms (end to end 4.42548 ms, enqueue 0.665167 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27339 ms - Host latency: 2.79922 ms (end to end 4.37865 ms, enqueue 0.76015 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27552 ms - Host latency: 2.79984 ms (end to end 4.39151 ms, enqueue 0.65816 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27308 ms - Host latency: 2.79962 ms (end to end 4.40823 ms, enqueue 0.720551 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27545 ms - Host latency: 2.79948 ms (end to end 4.39954 ms, enqueue 0.652185 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27299 ms - Host latency: 2.79702 ms (end to end 4.42365 ms, enqueue 0.692285 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27317 ms - Host latency: 2.79864 ms (end to end 4.35196 ms, enqueue 0.722705 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27318 ms - Host latency: 2.80172 ms (end to end 4.39907 ms, enqueue 0.731152 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.274 ms - Host latency: 2.80115 ms (end to end 4.35013 ms, enqueue 0.686353 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2731 ms - Host latency: 2.79991 ms (end to end 4.39358 ms, enqueue 0.679468 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2749 ms - Host latency: 2.80144 ms (end to end 4.39094 ms, enqueue 0.680225 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27286 ms - Host latency: 2.79966 ms (end to end 4.39963 ms, enqueue 0.675244 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27828 ms - Host latency: 2.80476 ms (end to end 4.41525 ms, enqueue 0.708716 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27587 ms - Host latency: 2.80378 ms (end to end 4.3895 ms, enqueue 0.702209 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27275 ms - Host latency: 2.79685 ms (end to end 4.38966 ms, enqueue 0.690942 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27307 ms - Host latency: 2.79849 ms (end to end 4.39749 ms, enqueue 0.659814 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27399 ms - Host latency: 2.79857 ms (end to end 4.40812 ms, enqueue 0.686682 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27443 ms - Host latency: 2.79767 ms (end to end 4.39619 ms, enqueue 0.681482 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27491 ms - Host latency: 2.79965 ms (end to end 4.41173 ms, enqueue 0.700586 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27389 ms - Host latency: 2.796 ms (end to end 4.3949 ms, enqueue 0.631287 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27083 ms - Host latency: 2.79163 ms (end to end 4.05223 ms, enqueue 0.752063 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27347 ms - Host latency: 2.7995 ms (end to end 4.22274 ms, enqueue 0.803748 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27375 ms - Host latency: 2.79722 ms (end to end 4.21649 ms, enqueue 0.769421 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27308 ms - Host latency: 2.80071 ms (end to end 4.40979 ms, enqueue 0.714282 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27266 ms - Host latency: 2.79784 ms (end to end 3.95796 ms, enqueue 0.895898 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27841 ms - Host latency: 2.81481 ms (end to end 4.32274 ms, enqueue 0.945337 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27809 ms - Host latency: 2.81987 ms (end to end 4.40472 ms, enqueue 0.764941 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27946 ms - Host latency: 2.8432 ms (end to end 4.41753 ms, enqueue 0.804102 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27782 ms - Host latency: 2.92971 ms (end to end 4.37437 ms, enqueue 0.833948 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28147 ms - Host latency: 3.01974 ms (end to end 4.37168 ms, enqueue 0.771143 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28596 ms - Host latency: 3.05562 ms (end to end 4.34501 ms, enqueue 0.884241 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2834 ms - Host latency: 3.05135 ms (end to end 4.39297 ms, enqueue 0.755151 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28503 ms - Host latency: 3.0536 ms (end to end 4.28729 ms, enqueue 0.787671 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28412 ms - Host latency: 3.05195 ms (end to end 4.40239 ms, enqueue 0.759631 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28507 ms - Host latency: 3.05261 ms (end to end 4.34576 ms, enqueue 0.787756 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28564 ms - Host latency: 3.05319 ms (end to end 4.34167 ms, enqueue 0.825647 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28486 ms - Host latency: 3.05376 ms (end to end 4.36447 ms, enqueue 0.834265 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28423 ms - Host latency: 3.05106 ms (end to end 4.36196 ms, enqueue 0.767371 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28477 ms - Host latency: 3.05323 ms (end to end 4.38733 ms, enqueue 0.842334 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28269 ms - Host latency: 3.04977 ms (end to end 4.34507 ms, enqueue 0.764612 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2833 ms - Host latency: 3.05176 ms (end to end 4.37771 ms, enqueue 0.793152 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28309 ms - Host latency: 3.04988 ms (end to end 4.38708 ms, enqueue 0.770288 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28445 ms - Host latency: 3.0542 ms (end to end 4.37437 ms, enqueue 0.792322 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28372 ms - Host latency: 3.04995 ms (end to end 4.38887 ms, enqueue 0.765454 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28181 ms - Host latency: 3.04832 ms (end to end 4.32218 ms, enqueue 0.78512 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28362 ms - Host latency: 3.05334 ms (end to end 4.32952 ms, enqueue 0.814673 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28171 ms - Host latency: 3.05015 ms (end to end 4.35115 ms, enqueue 0.805566 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28335 ms - Host latency: 3.05203 ms (end to end 4.35212 ms, enqueue 0.905054 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28506 ms - Host latency: 3.05308 ms (end to end 4.35237 ms, enqueue 0.822168 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28337 ms - Host latency: 3.04858 ms (end to end 4.35127 ms, enqueue 0.72312 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28521 ms - Host latency: 3.05232 ms (end to end 4.36792 ms, enqueue 0.755225 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28381 ms - Host latency: 3.05034 ms (end to end 4.36768 ms, enqueue 0.771875 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28569 ms - Host latency: 3.05305 ms (end to end 4.35391 ms, enqueue 0.779541 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2823 ms - Host latency: 3.04771 ms (end to end 4.34314 ms, enqueue 0.784375 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28193 ms - Host latency: 3.05022 ms (end to end 4.32515 ms, enqueue 0.801221 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2835 ms - Host latency: 3.04963 ms (end to end 4.36206 ms, enqueue 0.72229 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28608 ms - Host latency: 3.05347 ms (end to end 4.34348 ms, enqueue 0.74021 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28286 ms - Host latency: 3.05022 ms (end to end 4.33286 ms, enqueue 0.776147 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28486 ms - Host latency: 3.05178 ms (end to end 4.3416 ms, enqueue 0.771143 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28538 ms - Host latency: 3.05222 ms (end to end 4.36538 ms, enqueue 0.790552 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28428 ms - Host latency: 3.04958 ms (end to end 4.20686 ms, enqueue 0.80061 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28562 ms - Host latency: 3.05266 ms (end to end 4.32288 ms, enqueue 0.781226 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2832 ms - Host latency: 3.05149 ms (end to end 4.38208 ms, enqueue 0.833813 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28486 ms - Host latency: 3.07017 ms (end to end 4.31211 ms, enqueue 0.796777 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27686 ms - Host latency: 2.88516 ms (end to end 4.15459 ms, enqueue 0.801733 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27471 ms - Host latency: 2.79739 ms (end to end 3.88491 ms, enqueue 1.01904 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27905 ms - Host latency: 2.80859 ms (end to end 4.4095 ms, enqueue 0.74751 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27783 ms - Host latency: 2.80947 ms (end to end 4.40542 ms, enqueue 0.753223 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2781 ms - Host latency: 2.80601 ms (end to end 4.40061 ms, enqueue 0.699951 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27302 ms - Host latency: 2.80815 ms (end to end 4.4053 ms, enqueue 0.692676 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27432 ms - Host latency: 2.8157 ms (end to end 4.40205 ms, enqueue 0.782471 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27463 ms - Host latency: 2.83025 ms (end to end 4.38135 ms, enqueue 0.770923 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.27541 ms - Host latency: 2.89031 ms (end to end 4.37864 ms, enqueue 0.834326 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28066 ms - Host latency: 2.99604 ms (end to end 4.40972 ms, enqueue 0.746436 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2833 ms - Host latency: 3.05347 ms (end to end 4.42273 ms, enqueue 0.794141 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28486 ms - Host latency: 3.05581 ms (end to end 4.41228 ms, enqueue 0.839111 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28254 ms - Host latency: 3.05283 ms (end to end 4.36445 ms, enqueue 0.857104 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28306 ms - Host latency: 3.04995 ms (end to end 4.43857 ms, enqueue 0.772192 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28125 ms - Host latency: 3.05066 ms (end to end 4.4217 ms, enqueue 0.78252 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.2824 ms - Host latency: 3.0511 ms (end to end 4.44233 ms, enqueue 0.81814 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28352 ms - Host latency: 3.05071 ms (end to end 4.42661 ms, enqueue 0.811035 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28325 ms - Host latency: 3.05437 ms (end to end 4.36157 ms, enqueue 0.884863 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28355 ms - Host latency: 3.05232 ms (end to end 4.43215 ms, enqueue 0.858179 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28208 ms - Host latency: 3.05056 ms (end to end 4.43374 ms, enqueue 0.802051 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28355 ms - Host latency: 3.05244 ms (end to end 4.4439 ms, enqueue 0.805298 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28364 ms - Host latency: 3.05183 ms (end to end 4.38835 ms, enqueue 0.816943 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28467 ms - Host latency: 3.05544 ms (end to end 4.43381 ms, enqueue 0.813501 ms)
[10/24/2023-13:05:06] [I] Average on 10 runs - GPU latency: 2.28413 ms - Host latency: 3.05608 ms (end to end 4.41638 ms, enqueue 0.908618 ms)
[10/24/2023-13:05:06] [I] 
[10/24/2023-13:05:06] [I] === Performance summary ===
[10/24/2023-13:05:06] [I] Throughput: 391.45 qps
[10/24/2023-13:05:06] [I] Latency: min = 2.75952 ms, max = 3.16772 ms, mean = 2.91149 ms, median = 2.81549 ms, percentile(99%) = 3.06519 ms
[10/24/2023-13:05:06] [I] End-to-End Host Latency: min = 2.79663 ms, max = 4.58691 ms, mean = 4.36865 ms, median = 4.40411 ms, percentile(99%) = 4.47522 ms
[10/24/2023-13:05:06] [I] Enqueue Time: min = 0.451111 ms, max = 1.29163 ms, mean = 0.75686 ms, median = 0.710449 ms, percentile(99%) = 1.18188 ms
[10/24/2023-13:05:06] [I] H2D Latency: min = 0.348999 ms, max = 0.603271 ms, mean = 0.439756 ms, median = 0.368896 ms, percentile(99%) = 0.54834 ms
[10/24/2023-13:05:06] [I] GPU Compute Time: min = 2.26196 ms, max = 2.29785 ms, mean = 2.27835 ms, median = 2.27737 ms, percentile(99%) = 2.29272 ms
[10/24/2023-13:05:06] [I] D2H Latency: min = 0.143677 ms, max = 0.333008 ms, mean = 0.193385 ms, median = 0.171143 ms, percentile(99%) = 0.23291 ms
[10/24/2023-13:05:06] [I] Total Host Walltime: 3.00677 s
[10/24/2023-13:05:06] [I] Total GPU Compute Time: 2.68161 s
[10/24/2023-13:05:06] [I] Explanations of the performance metrics are printed in the verbose logs.
[10/24/2023-13:05:06] [V] 
[10/24/2023-13:05:06] [V] === Explanations of the performance metrics ===
[10/24/2023-13:05:06] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[10/24/2023-13:05:06] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[10/24/2023-13:05:06] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[10/24/2023-13:05:06] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[10/24/2023-13:05:06] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[10/24/2023-13:05:06] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[10/24/2023-13:05:06] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[10/24/2023-13:05:06] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[10/24/2023-13:05:06] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[10/24/2023-13:05:06] [I] 
[10/24/2023-13:05:09] [I] 
[10/24/2023-13:05:09] [I] === Profile (836 iterations ) ===
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Layer   Time (ms)   Avg. Time (ms)   Time %
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     model.backbone_2d.deblocks.0.1.running_mean + (Unnamed Layer* 24) [Shuffle]        1.94           0.0023      0.1
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      model.backbone_2d.deblocks.0.1.running_var + (Unnamed Layer* 25) [Shuffle]        1.66           0.0020      0.1
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Reformatting CopyNode for Input Tensor 0 to /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu       29.04           0.0347      1.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /backbone_2d/blocks.0/blocks.0.0/Pad + /backbone_2d/blocks.0/blocks.0.1/Conv + /backbone_2d/blocks.0/blocks.0.3/Relu       91.13           0.1090      3.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /backbone_2d/blocks.0/blocks.0.4/Conv + /backbone_2d/blocks.0/blocks.0.6/Relu       48.40           0.0579      1.9
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /backbone_2d/blocks.0/blocks.0.7/Conv + /backbone_2d/blocks.0/blocks.0.9/Relu       48.31           0.0578      1.9
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.0/blocks.0.10/Conv + /backbone_2d/blocks.0/blocks.0.12/Relu       48.10           0.0575      1.9
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.0/blocks.0.13/Conv + /backbone_2d/blocks.0/blocks.0.15/Relu       48.09           0.0575      1.9
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.0/blocks.0.16/Conv + /backbone_2d/blocks.0/blocks.0.18/Relu       48.06           0.0575      1.9
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /backbone_2d/deblocks.0/deblocks.0.0/ConvTranspose       61.42           0.0735      2.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))        4.28           0.0051      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))        4.37           0.0052      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            PWN((Unnamed Layer* 29) [ElementWise], PWN(PWN((Unnamed Layer* 26) [Constant] + (Unnamed Layer* 27) [ElementWise], (Unnamed Layer* 28) [Unary]), (Unnamed Layer* 30) [ElementWise]))       36.25           0.0434      1.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                           model.backbone_2d.deblocks.0.1.weight + (Unnamed Layer* 22) [Shuffle] + (Unnamed Layer* 31) [ElementWise] + model.backbone_2d.deblocks.0.1.bias + (Unnamed Layer* 23) [Shuffle] + /backbone_2d/deblocks.0/deblocks.0.1/BatchNormalization + /backbone_2d/deblocks.0/deblocks.0.2/Relu       30.09           0.0360      1.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /backbone_2d/blocks.1/blocks.1.0/Pad + /backbone_2d/blocks.1/blocks.1.1/Conv + /backbone_2d/blocks.1/blocks.1.3/Relu       30.16           0.0361      1.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /backbone_2d/blocks.1/blocks.1.4/Conv + /backbone_2d/blocks.1/blocks.1.6/Relu       45.15           0.0540      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /backbone_2d/blocks.1/blocks.1.7/Conv + /backbone_2d/blocks.1/blocks.1.9/Relu       43.99           0.0526      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.1/blocks.1.10/Conv + /backbone_2d/blocks.1/blocks.1.12/Relu       43.94           0.0526      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.1/blocks.1.13/Conv + /backbone_2d/blocks.1/blocks.1.15/Relu       43.73           0.0523      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /backbone_2d/blocks.1/blocks.1.16/Conv + /backbone_2d/blocks.1/blocks.1.18/Relu       43.88           0.0525      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /backbone_2d/deblocks.1/deblocks.1.0/ConvTranspose       61.37           0.0734      2.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     model.backbone_2d.deblocks.1.1.running_mean + (Unnamed Layer* 58) [Shuffle]        1.73           0.0021      0.1
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      model.backbone_2d.deblocks.1.1.running_var + (Unnamed Layer* 59) [Shuffle]        1.65           0.0020      0.1
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Reformatting CopyNode for Input Tensor 1 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))        4.44           0.0053      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Reformatting CopyNode for Input Tensor 2 to PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))        4.36           0.0052      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            PWN((Unnamed Layer* 63) [ElementWise], PWN(PWN((Unnamed Layer* 60) [Constant] + (Unnamed Layer* 61) [ElementWise], (Unnamed Layer* 62) [Unary]), (Unnamed Layer* 64) [ElementWise]))       36.25           0.0434      1.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                           model.backbone_2d.deblocks.1.1.weight + (Unnamed Layer* 56) [Shuffle] + (Unnamed Layer* 65) [ElementWise] + model.backbone_2d.deblocks.1.1.bias + (Unnamed Layer* 57) [Shuffle] + /backbone_2d/deblocks.1/deblocks.1.1/BatchNormalization + /backbone_2d/deblocks.1/deblocks.1.2/Relu       30.03           0.0359      1.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /shared_conv/shared_conv.0/Conv + /shared_conv/shared_conv.2/Relu       91.72           0.1097      3.7
[10/24/2023-13:05:09] [I]  /heads_list.0/center/center.0/center.0.0/Conv + /heads_list.0/center/center.0/center.0.2/Relu || /heads_list.0/center_z/center_z.0/center_z.0.0/Conv + /heads_list.0/center_z/center_z.0/center_z.0.2/Relu || /heads_list.0/dim/dim.0/dim.0.0/Conv + /heads_list.0/dim/dim.0/dim.0.2/Relu || /heads_list.0/rot/rot.0/rot.0.0/Conv + /heads_list.0/rot/rot.0/rot.0.2/Relu || /heads_list.0/vel/vel.0/vel.0.0/Conv + /heads_list.0/vel/vel.0/vel.0.2/Relu || /heads_list.0/hm/hm.0/hm.0.0/Conv + /heads_list.0/hm/hm.0/hm.0.2/Relu || /heads_list.1/center/center.0/center.0.0/Conv + /heads_list.1/center/center.0/center.0.2/Relu || /heads_list.1/center_z/center_z.0/center_z.0.0/Conv + /heads_list.1/center_z/center_z.0/center_z.0.2/Relu       86.56           0.1035      3.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.0/center/center.1/Conv       16.53           0.0198      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center/center.1/Conv        4.27           0.0051      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.0/center_z/center_z.1/Conv       16.33           0.0195      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.0/center_z/center_z.1/Conv        4.06           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.0/dim/dim.1/Conv       16.79           0.0201      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.0/dim/dim.1/Conv        4.12           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.0/rot/rot.1/Conv       16.74           0.0200      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.0/rot/rot.1/Conv        4.11           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.0/vel/vel.1/Conv       16.76           0.0200      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.0/vel/vel.1/Conv        4.11           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.0/hm/hm.1/Conv       16.92           0.0202      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.0/hm/hm.1/Conv        3.98           0.0048      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.1/center/center.1/Conv       16.77           0.0201      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center/center.1/Conv        3.96           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.1/center_z/center_z.1/Conv       17.06           0.0204      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.1/center_z/center_z.1/Conv        3.93           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                  /heads_list.1/dim/dim.0/dim.0.0/Conv + /heads_list.1/dim/dim.0/dim.0.2/Relu || /heads_list.1/rot/rot.0/rot.0.0/Conv + /heads_list.1/rot/rot.0/rot.0.2/Relu || /heads_list.1/vel/vel.0/vel.0.0/Conv + /heads_list.1/vel/vel.0/vel.0.2/Relu || /heads_list.1/hm/hm.0/hm.0.0/Conv + /heads_list.1/hm/hm.0/hm.0.2/Relu || /heads_list.2/center/center.0/center.0.0/Conv + /heads_list.2/center/center.0/center.0.2/Relu || /heads_list.2/center_z/center_z.0/center_z.0.0/Conv + /heads_list.2/center_z/center_z.0/center_z.0.2/Relu || /heads_list.2/dim/dim.0/dim.0.0/Conv + /heads_list.2/dim/dim.0/dim.0.2/Relu || /heads_list.2/rot/rot.0/rot.0.0/Conv + /heads_list.2/rot/rot.0/rot.0.2/Relu       86.28           0.1032      3.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.1/dim/dim.1/Conv       16.01           0.0192      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.1/dim/dim.1/Conv        4.23           0.0051      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.1/rot/rot.1/Conv       16.02           0.0192      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.1/rot/rot.1/Conv        4.10           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.1/vel/vel.1/Conv       16.49           0.0197      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.1/vel/vel.1/Conv        4.12           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.1/hm/hm.1/Conv       16.80           0.0201      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.1/hm/hm.1/Conv        4.16           0.0050      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.2/center/center.1/Conv       17.01           0.0203      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center/center.1/Conv        4.13           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.2/center_z/center_z.1/Conv       16.66           0.0199      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.2/center_z/center_z.1/Conv        3.95           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.2/dim/dim.1/Conv       16.78           0.0201      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.2/dim/dim.1/Conv      115.55           0.1382      4.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.2/rot/rot.1/Conv       17.13           0.0205      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.2/rot/rot.1/Conv        3.99           0.0048      0.2
[10/24/2023-13:05:09] [I]                                                        /heads_list.2/vel/vel.0/vel.0.0/Conv + /heads_list.2/vel/vel.0/vel.0.2/Relu || /heads_list.2/hm/hm.0/hm.0.0/Conv + /heads_list.2/hm/hm.0/hm.0.2/Relu || /heads_list.3/center/center.0/center.0.0/Conv + /heads_list.3/center/center.0/center.0.2/Relu || /heads_list.3/center_z/center_z.0/center_z.0.0/Conv + /heads_list.3/center_z/center_z.0/center_z.0.2/Relu || /heads_list.3/dim/dim.0/dim.0.0/Conv + /heads_list.3/dim/dim.0/dim.0.2/Relu || /heads_list.3/rot/rot.0/rot.0.0/Conv + /heads_list.3/rot/rot.0/rot.0.2/Relu || /heads_list.3/vel/vel.0/vel.0.0/Conv + /heads_list.3/vel/vel.0/vel.0.2/Relu || /heads_list.3/hm/hm.0/hm.0.0/Conv + /heads_list.3/hm/hm.0/hm.0.2/Relu       86.18           0.1031      3.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.2/vel/vel.1/Conv       16.10           0.0193      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.2/vel/vel.1/Conv       41.92           0.0501      1.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.2/hm/hm.1/Conv       16.94           0.0203      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.2/hm/hm.1/Conv        4.15           0.0050      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.3/center/center.1/Conv       16.37           0.0196      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center/center.1/Conv        4.10           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.3/center_z/center_z.1/Conv       16.58           0.0198      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.3/center_z/center_z.1/Conv        4.09           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.3/dim/dim.1/Conv       17.69           0.0212      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.3/dim/dim.1/Conv       44.82           0.0536      1.8
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.3/rot/rot.1/Conv      130.00           0.1555      5.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.3/rot/rot.1/Conv       61.67           0.0738      2.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.3/vel/vel.1/Conv       16.98           0.0203      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.3/vel/vel.1/Conv        3.98           0.0048      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.3/hm/hm.1/Conv       16.58           0.0198      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.3/hm/hm.1/Conv        3.97           0.0048      0.2
[10/24/2023-13:05:09] [I]  /heads_list.4/center/center.0/center.0.0/Conv + /heads_list.4/center/center.0/center.0.2/Relu || /heads_list.4/center_z/center_z.0/center_z.0.0/Conv + /heads_list.4/center_z/center_z.0/center_z.0.2/Relu || /heads_list.4/dim/dim.0/dim.0.0/Conv + /heads_list.4/dim/dim.0/dim.0.2/Relu || /heads_list.4/rot/rot.0/rot.0.0/Conv + /heads_list.4/rot/rot.0/rot.0.2/Relu || /heads_list.4/vel/vel.0/vel.0.0/Conv + /heads_list.4/vel/vel.0/vel.0.2/Relu || /heads_list.4/hm/hm.0/hm.0.0/Conv + /heads_list.4/hm/hm.0/hm.0.2/Relu || /heads_list.5/center/center.0/center.0.0/Conv + /heads_list.5/center/center.0/center.0.2/Relu || /heads_list.5/center_z/center_z.0/center_z.0.0/Conv + /heads_list.5/center_z/center_z.0/center_z.0.2/Relu       86.47           0.1034      3.5
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.4/center/center.1/Conv       16.07           0.0192      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center/center.1/Conv        4.35           0.0052      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.4/center_z/center_z.1/Conv       16.74           0.0200      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.4/center_z/center_z.1/Conv        4.11           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.4/dim/dim.1/Conv       16.45           0.0197      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.4/dim/dim.1/Conv        4.11           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.4/rot/rot.1/Conv       17.07           0.0204      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.4/rot/rot.1/Conv        4.10           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.4/vel/vel.1/Conv       16.72           0.0200      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.4/vel/vel.1/Conv        4.09           0.0049      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.4/hm/hm.1/Conv       16.85           0.0202      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.4/hm/hm.1/Conv        3.94           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.5/center/center.1/Conv       16.95           0.0203      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center/center.1/Conv        3.94           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /heads_list.5/center_z/center_z.1/Conv       16.80           0.0201      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reformatting CopyNode for Output Tensor 0 to /heads_list.5/center_z/center_z.1/Conv        3.94           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                              /heads_list.5/dim/dim.0/dim.0.0/Conv + /heads_list.5/dim/dim.0/dim.0.2/Relu || /heads_list.5/rot/rot.0/rot.0.0/Conv + /heads_list.5/rot/rot.0/rot.0.2/Relu || /heads_list.5/vel/vel.0/vel.0.0/Conv + /heads_list.5/vel/vel.0/vel.0.2/Relu || /heads_list.5/hm/hm.0/hm.0.0/Conv + /heads_list.5/hm/hm.0/hm.0.2/Relu       52.99           0.0634      2.1
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.5/dim/dim.1/Conv       15.86           0.0190      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.5/dim/dim.1/Conv        4.23           0.0051      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.5/rot/rot.1/Conv       15.34           0.0183      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.5/rot/rot.1/Conv        3.94           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /heads_list.5/vel/vel.1/Conv       15.77           0.0189      0.6
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Reformatting CopyNode for Output Tensor 0 to /heads_list.5/vel/vel.1/Conv        3.97           0.0048      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /heads_list.5/hm/hm.1/Conv       16.88           0.0202      0.7
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Reformatting CopyNode for Output Tensor 0 to /heads_list.5/hm/hm.1/Conv        3.92           0.0047      0.2
[10/24/2023-13:05:09] [I]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Total     2487.65           2.9757    100.0
[10/24/2023-13:05:09] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8200] # trtexec --onnx=model/centerpoint_rpn.onnx --saveEngine=model/centerpoint_rpn.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
